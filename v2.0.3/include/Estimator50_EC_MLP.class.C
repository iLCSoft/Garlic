// Class: ReadMLP
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : MLP::MLP
TMVA Release   : 3.9.6         [198918]
ROOT Release   : 5.16/00       [331776]
Creator        : reinhard
Date           : Thu Jul 16 12:10:06 2009
Host           : Linux polui02.in2p3.fr 2.6.9-67.0.4.ELsmp #1 SMP Thu Jan 31 16:30:09 CST 2008 i686 i686 i386 GNU/Linux
Dir            : /grid_mnt/data2__polgrid/llr/ilc/reinhard/ILCSoft/TMVA/macros
Training events: 22990


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
Normalise: "True" [Normalise input variables]
V: "False" [Verbose mode]
H: "True" [Print classifier-specific help message]
NCycles: "500" [Number of training cycles]
HiddenLayers: "N+1,N" [Specification of hidden layer architecture (N stands for number of variables; any integers may also be used)]
NeuronType: "tanh" [Neuron activation function type]
TestRate: "5" [Test for overtraining performed at each #th epochs]
# Default:
D: "False" [Use-decorrelated-variables flag (depreciated)]
VarTransform: "None" [Variable transformation method]
VarTransformType: "Signal" [Use signal or background events to derive for variable transformation (the transformation is applied on both types of, course)]
NbinsMVAPdf: "60" [Number of bins used for the PDFs of classifier outputs]
NsmoothMVAPdf: "2" [Number of smoothing iterations for classifier PDFs]
VerboseLevel: "Default" [Verbosity level]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
TxtWeightFilesOnly: "True" [If True: write all training results (weights) as text files (False: some are written in ROOT format)]
NeuronInputType: "sum" [Neuron input function type]
TrainingMethod: "BP" [Train with Back-Propagation (BP - default) or Genetic Algorithm (GA - slower and worse)]
LearningRate: "0.02" [ANN learning rate parameter]
DecayRate: "0.01" [Decay rate for learning parameter]
BPMode: "sequential" [Back-propagation learning mode: sequential or batch]
BatchSize: "-1" [Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 14
ClusterParameters.start       ClusterParameters.start           'F'    [0,9.57353115082]
ClusterParameters.end         ClusterParameters.end             'F'    [14.4296979904,39.0216751099]
ClusterParameters.depth       ClusterParameters.depth           'F'    [0,23.6316795349]
ClusterParameters.E1C/ClusterParameters.Etot_g   ClusterParameters.E1C_D_ClusterParameters.Etot_g     'F'    [0,0.493858575821]
ClusterParameters.E4C/ClusterParameters.Etot_g   ClusterParameters.E4C_D_ClusterParameters.Etot_g     'F'    [0.0255026500672,0.869191586971]
ClusterParameters.E9C/ClusterParameters.Etot_g   ClusterParameters.E9C_D_ClusterParameters.Etot_g     'F'    [0.308708399534,0.967696547508]
ClusterParameters.dirErr      ClusterParameters.dirErr          'F'    [0.97022998333,1]
ClusterParameters.seedDirErr  ClusterParameters.seedDirErr      'F'    [-0.000168240978383,0.999999582767]
ClusterParameters.Es3/ClusterParameters.Etot_g   ClusterParameters.Es3_D_ClusterParameters.Etot_g     'F'    [0,0.794267058372]
ClusterParameters.Width       ClusterParameters.Width           'F'    [5.82454156876,17.8204269409]
ClusterParameters.Eccentricity ClusterParameters.Eccentricity     'F'    [0.125430628657,0.632232129574]
ClusterParameters.nHits       ClusterParameters.nHits           'F'    [199,951]
ClusterParameters.Volume      ClusterParameters.Volume          'F'    [6324.80078125,321944.375]
ClusterParameters.depth-ClusterParameters.start   ClusterParameters.depth_M_ClusterParameters.start     'F'    [-0.764826416969,20.1120700836]


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;
};

#endif

class ReadMLP : public IClassifierReader {

 public:

   // constructor
   ReadMLP( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadMLP" ),
        fStatusIsClean( true ),
        fNvars( 14 ),
        fIsNormalised( true )
   {      
      // the training input variables
      const char* inputVars[] = { "ClusterParameters.start", "ClusterParameters.end", "ClusterParameters.depth", "ClusterParameters.E1C/ClusterParameters.Etot_g", "ClusterParameters.E4C/ClusterParameters.Etot_g", "ClusterParameters.E9C/ClusterParameters.Etot_g", "ClusterParameters.dirErr", "ClusterParameters.seedDirErr", "ClusterParameters.Es3/ClusterParameters.Etot_g", "ClusterParameters.Width", "ClusterParameters.Eccentricity", "ClusterParameters.nHits", "ClusterParameters.Volume", "ClusterParameters.depth-ClusterParameters.start" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 9.57353115081787;
      fVmin[1] = 14.4296979904175;
      fVmax[1] = 39.0216751098633;
      fVmin[2] = 0;
      fVmax[2] = 23.6316795349121;
      fVmin[3] = 0;
      fVmax[3] = 0.493858575820923;
      fVmin[4] = 0.0255026500672102;
      fVmax[4] = 0.869191586971283;
      fVmin[5] = 0.308708399534225;
      fVmax[5] = 0.96769654750824;
      fVmin[6] = 0.970229983329773;
      fVmax[6] = 1;
      fVmin[7] = -0.000168240978382528;
      fVmax[7] = 0.999999582767487;
      fVmin[8] = 0;
      fVmax[8] = 0.794267058372498;
      fVmin[9] = 5.8245415687561;
      fVmax[9] = 17.820426940918;
      fVmin[10] = 0.125430628657341;
      fVmax[10] = 0.632232129573822;
      fVmin[11] = 199;
      fVmax[11] = 951;
      fVmin[12] = 6324.80078125;
      fVmax[12] = 321944.375;
      fVmin[13] = -0.764826416969299;
      fVmax[13] = 20.1120700836182;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';
      fType[10] = 'F';
      fType[11] = 'F';
      fType[12] = 'F';
      fType[13] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadMLP() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;
   bool fStatusIsClean;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[14];
   double fVmax[14];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[14];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)

   double ActivationFnc(double x) const;

   int fLayers;
   int fLayerSize[4];
   double fWeightMatrix0to1[16][15];   // weight matrix from layer 0 to 1
   double fWeightMatrix1to2[15][16];   // weight matrix from layer 1 to 2
   double fWeightMatrix2to3[1][15];   // weight matrix from layer 2 to 3

   double * fWeights[4];
};

inline void ReadMLP::Initialize()
{
   // build network structure
   fLayers = 4;
   fLayerSize[0] = 15; fWeights[0] = new double[15]; 
   fLayerSize[1] = 16; fWeights[1] = new double[16]; 
   fLayerSize[2] = 15; fWeights[2] = new double[15]; 
   fLayerSize[3] = 1; fWeights[3] = new double[1]; 
   // weight matrix from layer 0 to 1
   fWeightMatrix0to1[0][0] = -0.304147790743787;
   fWeightMatrix0to1[1][0] = 2.01342394525753;
   fWeightMatrix0to1[2][0] = 0.949044376414423;
   fWeightMatrix0to1[3][0] = 1.71685547167263;
   fWeightMatrix0to1[4][0] = -1.92369364285771;
   fWeightMatrix0to1[5][0] = -1.5095755536688;
   fWeightMatrix0to1[6][0] = -0.612719839759263;
   fWeightMatrix0to1[7][0] = 1.95086080146464;
   fWeightMatrix0to1[8][0] = -1.54319055780207;
   fWeightMatrix0to1[9][0] = -1.09644337606232;
   fWeightMatrix0to1[10][0] = -1.79465856285909;
   fWeightMatrix0to1[11][0] = -0.374149975635319;
   fWeightMatrix0to1[12][0] = -1.04177447502556;
   fWeightMatrix0to1[13][0] = -0.254332218046053;
   fWeightMatrix0to1[14][0] = -0.749286985207042;
   fWeightMatrix0to1[0][1] = 0.669261446919502;
   fWeightMatrix0to1[1][1] = -0.463041463677828;
   fWeightMatrix0to1[2][1] = 1.79864530050806;
   fWeightMatrix0to1[3][1] = 0.154786241334474;
   fWeightMatrix0to1[4][1] = 1.31659476714024;
   fWeightMatrix0to1[5][1] = -0.353851008769996;
   fWeightMatrix0to1[6][1] = -0.419313762697184;
   fWeightMatrix0to1[7][1] = 0.820800739336066;
   fWeightMatrix0to1[8][1] = 0.0567125593840412;
   fWeightMatrix0to1[9][1] = -1.14590617629275;
   fWeightMatrix0to1[10][1] = -0.23628642081082;
   fWeightMatrix0to1[11][1] = 1.47428848609097;
   fWeightMatrix0to1[12][1] = -1.02559661908426;
   fWeightMatrix0to1[13][1] = -1.95691478395835;
   fWeightMatrix0to1[14][1] = 0.385199329191176;
   fWeightMatrix0to1[0][2] = 0.71422098791661;
   fWeightMatrix0to1[1][2] = 1.63704309204684;
   fWeightMatrix0to1[2][2] = -0.341231391651381;
   fWeightMatrix0to1[3][2] = -0.177555158276537;
   fWeightMatrix0to1[4][2] = -0.00961340934667196;
   fWeightMatrix0to1[5][2] = -0.19054274971315;
   fWeightMatrix0to1[6][2] = -1.34150742306729;
   fWeightMatrix0to1[7][2] = 1.41449171481178;
   fWeightMatrix0to1[8][2] = -0.882192792896051;
   fWeightMatrix0to1[9][2] = 0.731111064168389;
   fWeightMatrix0to1[10][2] = 1.07655168698039;
   fWeightMatrix0to1[11][2] = 0.957032398044803;
   fWeightMatrix0to1[12][2] = 1.81704637040372;
   fWeightMatrix0to1[13][2] = 1.26134764602747;
   fWeightMatrix0to1[14][2] = -1.08769002637437;
   fWeightMatrix0to1[0][3] = -1.5915800926162;
   fWeightMatrix0to1[1][3] = 0.605656253223857;
   fWeightMatrix0to1[2][3] = 0.245562781037508;
   fWeightMatrix0to1[3][3] = 1.40876337986738;
   fWeightMatrix0to1[4][3] = 1.39525244433477;
   fWeightMatrix0to1[5][3] = 1.33261520687948;
   fWeightMatrix0to1[6][3] = 1.74056212781396;
   fWeightMatrix0to1[7][3] = -0.824122795733956;
   fWeightMatrix0to1[8][3] = 0.592318644291567;
   fWeightMatrix0to1[9][3] = -1.12600132203449;
   fWeightMatrix0to1[10][3] = -0.65974416025984;
   fWeightMatrix0to1[11][3] = -1.39844380284688;
   fWeightMatrix0to1[12][3] = -1.44862767864657;
   fWeightMatrix0to1[13][3] = 1.27623523760324;
   fWeightMatrix0to1[14][3] = 1.38881121337498;
   fWeightMatrix0to1[0][4] = -1.53764369378691;
   fWeightMatrix0to1[1][4] = 0.307531751555459;
   fWeightMatrix0to1[2][4] = -0.196896292917831;
   fWeightMatrix0to1[3][4] = 0.573926359934846;
   fWeightMatrix0to1[4][4] = 1.73286950038234;
   fWeightMatrix0to1[5][4] = -0.606771595112545;
   fWeightMatrix0to1[6][4] = 0.946804919678358;
   fWeightMatrix0to1[7][4] = -0.622597214624938;
   fWeightMatrix0to1[8][4] = 0.297017404179974;
   fWeightMatrix0to1[9][4] = -0.545082177725835;
   fWeightMatrix0to1[10][4] = -0.664783289179736;
   fWeightMatrix0to1[11][4] = -1.50103234246489;
   fWeightMatrix0to1[12][4] = 1.09074825332771;
   fWeightMatrix0to1[13][4] = 0.87649815156328;
   fWeightMatrix0to1[14][4] = 2.16676928145474;
   fWeightMatrix0to1[0][5] = -0.260848744085496;
   fWeightMatrix0to1[1][5] = -1.71186450571817;
   fWeightMatrix0to1[2][5] = -1.80745166932501;
   fWeightMatrix0to1[3][5] = 0.913719821319113;
   fWeightMatrix0to1[4][5] = 0.733210912609217;
   fWeightMatrix0to1[5][5] = 1.87446242265178;
   fWeightMatrix0to1[6][5] = 1.13153816791633;
   fWeightMatrix0to1[7][5] = 1.10623764112843;
   fWeightMatrix0to1[8][5] = -0.787289546985901;
   fWeightMatrix0to1[9][5] = -0.97059733505873;
   fWeightMatrix0to1[10][5] = -0.183836691039541;
   fWeightMatrix0to1[11][5] = 1.15049183281267;
   fWeightMatrix0to1[12][5] = -0.964780528645349;
   fWeightMatrix0to1[13][5] = -1.59037872844922;
   fWeightMatrix0to1[14][5] = -1.20220289848902;
   fWeightMatrix0to1[0][6] = -0.0994609995067827;
   fWeightMatrix0to1[1][6] = -0.0167006930440399;
   fWeightMatrix0to1[2][6] = 1.46017682771588;
   fWeightMatrix0to1[3][6] = -1.78645878148772;
   fWeightMatrix0to1[4][6] = -0.582030948104772;
   fWeightMatrix0to1[5][6] = 1.73557353158131;
   fWeightMatrix0to1[6][6] = -0.783448348880794;
   fWeightMatrix0to1[7][6] = -2.10840702528165;
   fWeightMatrix0to1[8][6] = -0.835176436840133;
   fWeightMatrix0to1[9][6] = -0.428467252323381;
   fWeightMatrix0to1[10][6] = -2.06330023520436;
   fWeightMatrix0to1[11][6] = -1.70086763223218;
   fWeightMatrix0to1[12][6] = 0.259055137915692;
   fWeightMatrix0to1[13][6] = 2.05140392042738;
   fWeightMatrix0to1[14][6] = -1.11524460948258;
   fWeightMatrix0to1[0][7] = 1.54961959835242;
   fWeightMatrix0to1[1][7] = -1.11436857659994;
   fWeightMatrix0to1[2][7] = -0.758027875344266;
   fWeightMatrix0to1[3][7] = 0.0505936643520338;
   fWeightMatrix0to1[4][7] = 0.265778024227866;
   fWeightMatrix0to1[5][7] = -1.6060773958646;
   fWeightMatrix0to1[6][7] = 0.159559316815692;
   fWeightMatrix0to1[7][7] = 0.0865069712113938;
   fWeightMatrix0to1[8][7] = 0.725877338834813;
   fWeightMatrix0to1[9][7] = -1.26247914250844;
   fWeightMatrix0to1[10][7] = 1.90736501998667;
   fWeightMatrix0to1[11][7] = 0.288170700441946;
   fWeightMatrix0to1[12][7] = -1.2057986988466;
   fWeightMatrix0to1[13][7] = 0.626923559352938;
   fWeightMatrix0to1[14][7] = -0.644954731203801;
   fWeightMatrix0to1[0][8] = -1.66252282899405;
   fWeightMatrix0to1[1][8] = 0.00635555247079368;
   fWeightMatrix0to1[2][8] = -0.192640849554285;
   fWeightMatrix0to1[3][8] = 1.85592098849693;
   fWeightMatrix0to1[4][8] = 0.299497981605398;
   fWeightMatrix0to1[5][8] = -0.164858996626386;
   fWeightMatrix0to1[6][8] = -0.417755023960752;
   fWeightMatrix0to1[7][8] = 0.51838979741261;
   fWeightMatrix0to1[8][8] = -2.12544350696813;
   fWeightMatrix0to1[9][8] = 1.16497610643573;
   fWeightMatrix0to1[10][8] = 0.347000463811927;
   fWeightMatrix0to1[11][8] = -1.75825236083789;
   fWeightMatrix0to1[12][8] = 0.789252941538782;
   fWeightMatrix0to1[13][8] = -1.65140981311705;
   fWeightMatrix0to1[14][8] = -0.238669142680782;
   fWeightMatrix0to1[0][9] = 1.10114228016927;
   fWeightMatrix0to1[1][9] = 1.67910343868187;
   fWeightMatrix0to1[2][9] = -2.02529279443241;
   fWeightMatrix0to1[3][9] = 0.430955550463676;
   fWeightMatrix0to1[4][9] = 1.50448420070835;
   fWeightMatrix0to1[5][9] = 1.75977121300195;
   fWeightMatrix0to1[6][9] = -0.468716680337266;
   fWeightMatrix0to1[7][9] = -1.87729601946411;
   fWeightMatrix0to1[8][9] = 0.0744526171447863;
   fWeightMatrix0to1[9][9] = -1.63267787671582;
   fWeightMatrix0to1[10][9] = 1.46146266472881;
   fWeightMatrix0to1[11][9] = 1.25071349793831;
   fWeightMatrix0to1[12][9] = -0.84279926939053;
   fWeightMatrix0to1[13][9] = -0.263227030789796;
   fWeightMatrix0to1[14][9] = -0.571498805023639;
   fWeightMatrix0to1[0][10] = -1.36089985774346;
   fWeightMatrix0to1[1][10] = 0.569922303901038;
   fWeightMatrix0to1[2][10] = 1.62529118296591;
   fWeightMatrix0to1[3][10] = -0.508974417906074;
   fWeightMatrix0to1[4][10] = -0.4883789704915;
   fWeightMatrix0to1[5][10] = 0.307251201241817;
   fWeightMatrix0to1[6][10] = 0.634282217141817;
   fWeightMatrix0to1[7][10] = 0.486745565510838;
   fWeightMatrix0to1[8][10] = 0.848170378624264;
   fWeightMatrix0to1[9][10] = -1.45904742739219;
   fWeightMatrix0to1[10][10] = 1.3126532062096;
   fWeightMatrix0to1[11][10] = 0.73070410335852;
   fWeightMatrix0to1[12][10] = 0.322589976406741;
   fWeightMatrix0to1[13][10] = 0.684031328538746;
   fWeightMatrix0to1[14][10] = 0.544474347564043;
   fWeightMatrix0to1[0][11] = -0.650181171379361;
   fWeightMatrix0to1[1][11] = -0.631307196202798;
   fWeightMatrix0to1[2][11] = 1.0283797425629;
   fWeightMatrix0to1[3][11] = -0.901523630448486;
   fWeightMatrix0to1[4][11] = -0.395737143528218;
   fWeightMatrix0to1[5][11] = 1.47497367390601;
   fWeightMatrix0to1[6][11] = 0.880684307789021;
   fWeightMatrix0to1[7][11] = -0.108364651967919;
   fWeightMatrix0to1[8][11] = 1.33459652953667;
   fWeightMatrix0to1[9][11] = 2.07373134993084;
   fWeightMatrix0to1[10][11] = -1.78430125585555;
   fWeightMatrix0to1[11][11] = 0.565617834513864;
   fWeightMatrix0to1[12][11] = 0.00342030654464575;
   fWeightMatrix0to1[13][11] = 0.466330509683973;
   fWeightMatrix0to1[14][11] = -1.51096479930046;
   fWeightMatrix0to1[0][12] = -1.63711169523407;
   fWeightMatrix0to1[1][12] = 1.04146096234153;
   fWeightMatrix0to1[2][12] = 1.90502239423911;
   fWeightMatrix0to1[3][12] = -1.69109041341104;
   fWeightMatrix0to1[4][12] = -0.353476106513773;
   fWeightMatrix0to1[5][12] = -0.661004339943627;
   fWeightMatrix0to1[6][12] = 0.296522579667815;
   fWeightMatrix0to1[7][12] = 2.13385922108652;
   fWeightMatrix0to1[8][12] = -0.686511329288802;
   fWeightMatrix0to1[9][12] = -0.0865510415092828;
   fWeightMatrix0to1[10][12] = -0.790064969634083;
   fWeightMatrix0to1[11][12] = 1.0219690390773;
   fWeightMatrix0to1[12][12] = 1.63167319524105;
   fWeightMatrix0to1[13][12] = 0.965406350595664;
   fWeightMatrix0to1[14][12] = 0.36531588472547;
   fWeightMatrix0to1[0][13] = -0.797081586318156;
   fWeightMatrix0to1[1][13] = -2.05123871115875;
   fWeightMatrix0to1[2][13] = 1.08873934008599;
   fWeightMatrix0to1[3][13] = 0.479272392167409;
   fWeightMatrix0to1[4][13] = -1.70208572916913;
   fWeightMatrix0to1[5][13] = -0.655668981467492;
   fWeightMatrix0to1[6][13] = 0.346333294589853;
   fWeightMatrix0to1[7][13] = -0.0399766865330097;
   fWeightMatrix0to1[8][13] = -1.73878792935781;
   fWeightMatrix0to1[9][13] = 1.32019563224701;
   fWeightMatrix0to1[10][13] = 0.835979868919573;
   fWeightMatrix0to1[11][13] = -0.498139435280811;
   fWeightMatrix0to1[12][13] = -0.197946517405293;
   fWeightMatrix0to1[13][13] = 1.54541645402235;
   fWeightMatrix0to1[14][13] = 0.785038774925298;
   fWeightMatrix0to1[0][14] = 0.597690914765241;
   fWeightMatrix0to1[1][14] = -0.0115647347460985;
   fWeightMatrix0to1[2][14] = -2.09728099973796;
   fWeightMatrix0to1[3][14] = -0.970474908283266;
   fWeightMatrix0to1[4][14] = 1.72723932141017;
   fWeightMatrix0to1[5][14] = 1.60492361903565;
   fWeightMatrix0to1[6][14] = 0.749128838479749;
   fWeightMatrix0to1[7][14] = -0.655840902698269;
   fWeightMatrix0to1[8][14] = 2.79005718924602;
   fWeightMatrix0to1[9][14] = -2.47211653071131;
   fWeightMatrix0to1[10][14] = -1.57788932064566;
   fWeightMatrix0to1[11][14] = -0.0527302977958082;
   fWeightMatrix0to1[12][14] = -1.76975503946441;
   fWeightMatrix0to1[13][14] = 1.19489197283423;
   fWeightMatrix0to1[14][14] = 1.52202416787429;
   // weight matrix from layer 1 to 2
   fWeightMatrix1to2[0][0] = -1.00459601673573;
   fWeightMatrix1to2[1][0] = 0.720816002840878;
   fWeightMatrix1to2[2][0] = -0.0592547120326877;
   fWeightMatrix1to2[3][0] = -1.72878189027609;
   fWeightMatrix1to2[4][0] = -0.961309443373564;
   fWeightMatrix1to2[5][0] = 1.02321226197748;
   fWeightMatrix1to2[6][0] = -0.135616461336557;
   fWeightMatrix1to2[7][0] = 1.33669482515193;
   fWeightMatrix1to2[8][0] = -1.67792875037136;
   fWeightMatrix1to2[9][0] = 1.24441707054989;
   fWeightMatrix1to2[10][0] = -1.40595278390955;
   fWeightMatrix1to2[11][0] = 0.861439042979813;
   fWeightMatrix1to2[12][0] = 0.0689226110022662;
   fWeightMatrix1to2[13][0] = -1.49697389558984;
   fWeightMatrix1to2[0][1] = -1.47564713780709;
   fWeightMatrix1to2[1][1] = -1.68462978624185;
   fWeightMatrix1to2[2][1] = -0.370138728589439;
   fWeightMatrix1to2[3][1] = -1.82088735383163;
   fWeightMatrix1to2[4][1] = -1.36003462814712;
   fWeightMatrix1to2[5][1] = -1.76506918115295;
   fWeightMatrix1to2[6][1] = -0.185560820507655;
   fWeightMatrix1to2[7][1] = -1.06299420192045;
   fWeightMatrix1to2[8][1] = -1.35581765785915;
   fWeightMatrix1to2[9][1] = 1.34225662504155;
   fWeightMatrix1to2[10][1] = -0.729578611680646;
   fWeightMatrix1to2[11][1] = 0.146740060066164;
   fWeightMatrix1to2[12][1] = -1.07506744249569;
   fWeightMatrix1to2[13][1] = 0.211517364835512;
   fWeightMatrix1to2[0][2] = 1.64932040588045;
   fWeightMatrix1to2[1][2] = 1.48932008420722;
   fWeightMatrix1to2[2][2] = -0.927635553772203;
   fWeightMatrix1to2[3][2] = -1.49785482922672;
   fWeightMatrix1to2[4][2] = -1.04636103254546;
   fWeightMatrix1to2[5][2] = -0.939585927475419;
   fWeightMatrix1to2[6][2] = -1.54659403578653;
   fWeightMatrix1to2[7][2] = 0.015272912592235;
   fWeightMatrix1to2[8][2] = 0.776156262653296;
   fWeightMatrix1to2[9][2] = 2.17407337287784;
   fWeightMatrix1to2[10][2] = -0.66981481688873;
   fWeightMatrix1to2[11][2] = 0.230366804839405;
   fWeightMatrix1to2[12][2] = -0.52552965117737;
   fWeightMatrix1to2[13][2] = -1.92913648127415;
   fWeightMatrix1to2[0][3] = 0.976774692698178;
   fWeightMatrix1to2[1][3] = 1.28486841664564;
   fWeightMatrix1to2[2][3] = -0.985691260636186;
   fWeightMatrix1to2[3][3] = -1.06747064453776;
   fWeightMatrix1to2[4][3] = 0.950805392132818;
   fWeightMatrix1to2[5][3] = 1.21726786597305;
   fWeightMatrix1to2[6][3] = 0.746878278063901;
   fWeightMatrix1to2[7][3] = -0.75931949267201;
   fWeightMatrix1to2[8][3] = 0.22230158761276;
   fWeightMatrix1to2[9][3] = 1.90119005005411;
   fWeightMatrix1to2[10][3] = 0.651862934317028;
   fWeightMatrix1to2[11][3] = 1.00280168269433;
   fWeightMatrix1to2[12][3] = -0.285466153596591;
   fWeightMatrix1to2[13][3] = 0.21746989553084;
   fWeightMatrix1to2[0][4] = -0.248210675843047;
   fWeightMatrix1to2[1][4] = -0.860567812723602;
   fWeightMatrix1to2[2][4] = -0.700397135222529;
   fWeightMatrix1to2[3][4] = -1.72487649286913;
   fWeightMatrix1to2[4][4] = -1.4050544936132;
   fWeightMatrix1to2[5][4] = -1.53951256446378;
   fWeightMatrix1to2[6][4] = 1.93065488663773;
   fWeightMatrix1to2[7][4] = -1.83009997315919;
   fWeightMatrix1to2[8][4] = 1.45745054964531;
   fWeightMatrix1to2[9][4] = -1.21608995876422;
   fWeightMatrix1to2[10][4] = 1.01032587223699;
   fWeightMatrix1to2[11][4] = -1.10035324696598;
   fWeightMatrix1to2[12][4] = 0.473097625923824;
   fWeightMatrix1to2[13][4] = 0.852954828304694;
   fWeightMatrix1to2[0][5] = -1.5549820201537;
   fWeightMatrix1to2[1][5] = 0.17234455216311;
   fWeightMatrix1to2[2][5] = 0.802279242434094;
   fWeightMatrix1to2[3][5] = -1.93977752492696;
   fWeightMatrix1to2[4][5] = -1.71957627638116;
   fWeightMatrix1to2[5][5] = -1.75374671129745;
   fWeightMatrix1to2[6][5] = -1.07853110472157;
   fWeightMatrix1to2[7][5] = 1.90159208660909;
   fWeightMatrix1to2[8][5] = -0.898385304106788;
   fWeightMatrix1to2[9][5] = -0.149968901514241;
   fWeightMatrix1to2[10][5] = -0.636577346032776;
   fWeightMatrix1to2[11][5] = -1.20163535418357;
   fWeightMatrix1to2[12][5] = -1.70791607851163;
   fWeightMatrix1to2[13][5] = -0.993813512791991;
   fWeightMatrix1to2[0][6] = -1.18582951045252;
   fWeightMatrix1to2[1][6] = 1.63522170911028;
   fWeightMatrix1to2[2][6] = -1.35431696236709;
   fWeightMatrix1to2[3][6] = -1.21728123308578;
   fWeightMatrix1to2[4][6] = 1.57584259734274;
   fWeightMatrix1to2[5][6] = -0.165682992000004;
   fWeightMatrix1to2[6][6] = -0.337525411026092;
   fWeightMatrix1to2[7][6] = 1.55550279614667;
   fWeightMatrix1to2[8][6] = -1.19894751415596;
   fWeightMatrix1to2[9][6] = 1.72327680864732;
   fWeightMatrix1to2[10][6] = 0.572591812564366;
   fWeightMatrix1to2[11][6] = -1.0870279243264;
   fWeightMatrix1to2[12][6] = -0.77960621262971;
   fWeightMatrix1to2[13][6] = -0.0532996338316695;
   fWeightMatrix1to2[0][7] = -1.47419402006338;
   fWeightMatrix1to2[1][7] = 0.774650848869939;
   fWeightMatrix1to2[2][7] = 1.77879748516223;
   fWeightMatrix1to2[3][7] = 1.36817027765698;
   fWeightMatrix1to2[4][7] = 1.91405764065974;
   fWeightMatrix1to2[5][7] = -1.33098464320978;
   fWeightMatrix1to2[6][7] = 1.0739069065774;
   fWeightMatrix1to2[7][7] = -2.07837839839771;
   fWeightMatrix1to2[8][7] = 1.02609191346929;
   fWeightMatrix1to2[9][7] = -1.23724608402317;
   fWeightMatrix1to2[10][7] = -1.86923868757511;
   fWeightMatrix1to2[11][7] = -0.0362896121692022;
   fWeightMatrix1to2[12][7] = 1.26103611160434;
   fWeightMatrix1to2[13][7] = 0.423230912345479;
   fWeightMatrix1to2[0][8] = 1.43162108673531;
   fWeightMatrix1to2[1][8] = 0.0772204193689305;
   fWeightMatrix1to2[2][8] = -0.00174815955034638;
   fWeightMatrix1to2[3][8] = -0.811496121339628;
   fWeightMatrix1to2[4][8] = -0.254547528300495;
   fWeightMatrix1to2[5][8] = 1.85132825434027;
   fWeightMatrix1to2[6][8] = -1.33128706490105;
   fWeightMatrix1to2[7][8] = 0.388332884103492;
   fWeightMatrix1to2[8][8] = -1.48073396331024;
   fWeightMatrix1to2[9][8] = -0.820933259710522;
   fWeightMatrix1to2[10][8] = 0.074380798904011;
   fWeightMatrix1to2[11][8] = 0.171245081101594;
   fWeightMatrix1to2[12][8] = -1.13747535329192;
   fWeightMatrix1to2[13][8] = 0.982513854500761;
   fWeightMatrix1to2[0][9] = 1.35732096381623;
   fWeightMatrix1to2[1][9] = 0.693709206874531;
   fWeightMatrix1to2[2][9] = -0.308095851113294;
   fWeightMatrix1to2[3][9] = -0.916918845936314;
   fWeightMatrix1to2[4][9] = -1.26550919608838;
   fWeightMatrix1to2[5][9] = -1.59756420033227;
   fWeightMatrix1to2[6][9] = 1.07626475905483;
   fWeightMatrix1to2[7][9] = -0.835740846372284;
   fWeightMatrix1to2[8][9] = -0.810944806249912;
   fWeightMatrix1to2[9][9] = 0.947979686895768;
   fWeightMatrix1to2[10][9] = -1.95058682098093;
   fWeightMatrix1to2[11][9] = -1.14936423608712;
   fWeightMatrix1to2[12][9] = -1.61276532618582;
   fWeightMatrix1to2[13][9] = 1.00935896490877;
   fWeightMatrix1to2[0][10] = -1.35267736466228;
   fWeightMatrix1to2[1][10] = -1.81273549007708;
   fWeightMatrix1to2[2][10] = -0.500332239506616;
   fWeightMatrix1to2[3][10] = -0.990306594625617;
   fWeightMatrix1to2[4][10] = -1.41374593639827;
   fWeightMatrix1to2[5][10] = 1.32642522784152;
   fWeightMatrix1to2[6][10] = -1.2545607852904;
   fWeightMatrix1to2[7][10] = -1.12184576698617;
   fWeightMatrix1to2[8][10] = 1.38847064680221;
   fWeightMatrix1to2[9][10] = 0.585418628064967;
   fWeightMatrix1to2[10][10] = 0.356918478907673;
   fWeightMatrix1to2[11][10] = 0.1063619847131;
   fWeightMatrix1to2[12][10] = 1.35991789881228;
   fWeightMatrix1to2[13][10] = 1.70484892720965;
   fWeightMatrix1to2[0][11] = 0.473137691183888;
   fWeightMatrix1to2[1][11] = -1.15082941964197;
   fWeightMatrix1to2[2][11] = -0.491845866718282;
   fWeightMatrix1to2[3][11] = -1.79394023219944;
   fWeightMatrix1to2[4][11] = 0.957928804222052;
   fWeightMatrix1to2[5][11] = 1.19186735019254;
   fWeightMatrix1to2[6][11] = -0.0262211883264007;
   fWeightMatrix1to2[7][11] = 1.28385397407265;
   fWeightMatrix1to2[8][11] = 0.659434922430192;
   fWeightMatrix1to2[9][11] = 1.21244231833522;
   fWeightMatrix1to2[10][11] = -1.02936525106574;
   fWeightMatrix1to2[11][11] = 1.69080699637068;
   fWeightMatrix1to2[12][11] = 0.734327557365725;
   fWeightMatrix1to2[13][11] = -1.9357433421033;
   fWeightMatrix1to2[0][12] = -0.583758683737984;
   fWeightMatrix1to2[1][12] = -1.06700847844697;
   fWeightMatrix1to2[2][12] = 0.765305098538343;
   fWeightMatrix1to2[3][12] = 0.487745806054141;
   fWeightMatrix1to2[4][12] = 1.12019929558341;
   fWeightMatrix1to2[5][12] = 1.93195168351948;
   fWeightMatrix1to2[6][12] = -0.380638088202875;
   fWeightMatrix1to2[7][12] = 1.48365130191066;
   fWeightMatrix1to2[8][12] = 1.83360826864423;
   fWeightMatrix1to2[9][12] = 0.554307785709692;
   fWeightMatrix1to2[10][12] = -1.30316269638157;
   fWeightMatrix1to2[11][12] = 1.67137237945345;
   fWeightMatrix1to2[12][12] = -1.96401810401132;
   fWeightMatrix1to2[13][12] = 0.564886474962957;
   fWeightMatrix1to2[0][13] = 1.94945661075382;
   fWeightMatrix1to2[1][13] = -0.640036677254037;
   fWeightMatrix1to2[2][13] = -0.713621549726274;
   fWeightMatrix1to2[3][13] = -0.0771480272341044;
   fWeightMatrix1to2[4][13] = -1.62777510634391;
   fWeightMatrix1to2[5][13] = 0.377852647105214;
   fWeightMatrix1to2[6][13] = -1.87736147096087;
   fWeightMatrix1to2[7][13] = 0.441343036705363;
   fWeightMatrix1to2[8][13] = -0.662742336056043;
   fWeightMatrix1to2[9][13] = 1.28425405401139;
   fWeightMatrix1to2[10][13] = 1.4643977332837;
   fWeightMatrix1to2[11][13] = 1.66343236449969;
   fWeightMatrix1to2[12][13] = -0.531968037640543;
   fWeightMatrix1to2[13][13] = -0.418073149269508;
   fWeightMatrix1to2[0][14] = 0.293099336041814;
   fWeightMatrix1to2[1][14] = 2.03480188001301;
   fWeightMatrix1to2[2][14] = -2.02423768056733;
   fWeightMatrix1to2[3][14] = -1.29241390522537;
   fWeightMatrix1to2[4][14] = -0.447531588553586;
   fWeightMatrix1to2[5][14] = -1.52626610772312;
   fWeightMatrix1to2[6][14] = -1.58451732345658;
   fWeightMatrix1to2[7][14] = -1.51526472337414;
   fWeightMatrix1to2[8][14] = 0.978999480487527;
   fWeightMatrix1to2[9][14] = 0.420594819414353;
   fWeightMatrix1to2[10][14] = -2.0752267026594;
   fWeightMatrix1to2[11][14] = -1.90699789189021;
   fWeightMatrix1to2[12][14] = -0.165005348996102;
   fWeightMatrix1to2[13][14] = 1.78127971906036;
   fWeightMatrix1to2[0][15] = 2.07376766269735;
   fWeightMatrix1to2[1][15] = 1.24207879863712;
   fWeightMatrix1to2[2][15] = -0.580514684431955;
   fWeightMatrix1to2[3][15] = -1.92772700560721;
   fWeightMatrix1to2[4][15] = -0.0846765313712925;
   fWeightMatrix1to2[5][15] = -1.29840000785306;
   fWeightMatrix1to2[6][15] = -1.74683749261461;
   fWeightMatrix1to2[7][15] = -0.278585634937266;
   fWeightMatrix1to2[8][15] = -0.51165889885756;
   fWeightMatrix1to2[9][15] = -1.92391856494718;
   fWeightMatrix1to2[10][15] = 1.94031178132538;
   fWeightMatrix1to2[11][15] = 1.25379509485973;
   fWeightMatrix1to2[12][15] = 0.133090125928145;
   fWeightMatrix1to2[13][15] = -0.617228076379634;
   // weight matrix from layer 2 to 3
   fWeightMatrix2to3[0][0] = -0.000514951300118163;
   fWeightMatrix2to3[0][1] = 1.27576577580397;
   fWeightMatrix2to3[0][2] = -0.00446077723449418;
   fWeightMatrix2to3[0][3] = -0.00451371297840236;
   fWeightMatrix2to3[0][4] = 1.36795430482244;
   fWeightMatrix2to3[0][5] = 0.00251149538498686;
   fWeightMatrix2to3[0][6] = -0.797035951657449;
   fWeightMatrix2to3[0][7] = 0.568478594790139;
   fWeightMatrix2to3[0][8] = -0.341525744342242;
   fWeightMatrix2to3[0][9] = 0.934265310732723;
   fWeightMatrix2to3[0][10] = 0.969903150027137;
   fWeightMatrix2to3[0][11] = 0.277175378889762;
   fWeightMatrix2to3[0][12] = 0.00049013686284972;
   fWeightMatrix2to3[0][13] = 0.000506226165511656;
   fWeightMatrix2to3[0][14] = -0.378842209789042;
}

inline double ReadMLP::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   if (inputValues.size() != (unsigned int)fLayerSize[0]-1) {
      std::cout << "Input vector needs to be of size " << fLayerSize[0]-1 << std::endl;
      return 0;
   }

   for (int l=0; l<fLayers; l++)
      for (int i=0; i<fLayerSize[l]; i++) fWeights[l][i]=0;

   for (int l=0; l<fLayers-1; l++)
      fWeights[l][fLayerSize[l]-1]=1;

   for (int i=0; i<fLayerSize[0]-1; i++)
      fWeights[0][i]=inputValues[i];

   // layer 0 to 1
   for (int o=0; o<fLayerSize[1]-1; o++) {
      for (int i=0; i<fLayerSize[0]; i++) {
         double inputVal = fWeightMatrix0to1[o][i] * fWeights[0][i];
         fWeights[1][o] += inputVal;
      }
      fWeights[1][o] = ActivationFnc(fWeights[1][o]);
   }
   // layer 1 to 2
   for (int o=0; o<fLayerSize[2]-1; o++) {
      for (int i=0; i<fLayerSize[1]; i++) {
         double inputVal = fWeightMatrix1to2[o][i] * fWeights[1][i];
         fWeights[2][o] += inputVal;
      }
      fWeights[2][o] = ActivationFnc(fWeights[2][o]);
   }
   // layer 2 to 3
   for (int o=0; o<fLayerSize[3]; o++) {
      for (int i=0; i<fLayerSize[2]; i++) {
         double inputVal = fWeightMatrix2to3[o][i] * fWeights[2][i];
         fWeights[3][o] += inputVal;
      }
   }

   return fWeights[3][0];
}

double ReadMLP::ActivationFnc(double x) const
{
   // hyperbolic tan
   return tanh(x);
}
 
   
// Clean up
inline void ReadMLP::Clear() 
{
   // nothing to clear
}
inline double ReadMLP::GetMvaValue( const std::vector<double>& inputValues ) const
{
   // classifier response value
   double retval = 0;

   // classifier response, sanity check first
   if (!fStatusIsClean) {
      std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
      retval = 0;
   }
   else {
      if (IsNormalised()) {
         // normalise variables
         std::vector<double> iV;
         int ivar = 0;
         for (std::vector<double>::const_iterator varIt = inputValues.begin();
              varIt != inputValues.end(); varIt++, ivar++) {
            iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
         }
         retval = GetMvaValue__( iV );
      }
      else {
         retval = GetMvaValue__( inputValues );
      }
   }

   return retval;
}

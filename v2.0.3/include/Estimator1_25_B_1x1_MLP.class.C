// Class: ReadMLP1_25_B_1x1
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : MLP::MLP
TMVA Release   : 3.9.6         [198918]
ROOT Release   : 5.16/00       [331776]
Creator        : reinhard
Date           : Mon Aug 10 12:07:51 2009
Host           : Linux polui02.in2p3.fr 2.6.9-67.0.4.ELsmp #1 SMP Thu Jan 31 16:30:09 CST 2008 i686 i686 i386 GNU/Linux
Dir            : /grid_mnt/data2__polgrid/llr/ilc/reinhard/ILCSoft/TMVA/macros
Training events: 6746


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
Normalise: "True" [Normalise input variables]
V: "False" [Verbose mode]
H: "True" [Print classifier-specific help message]
NCycles: "500" [Number of training cycles]
HiddenLayers: "N+1,N" [Specification of hidden layer architecture (N stands for number of variables; any integers may also be used)]
NeuronType: "tanh" [Neuron activation function type]
TestRate: "5" [Test for overtraining performed at each #th epochs]
# Default:
D: "False" [Use-decorrelated-variables flag (depreciated)]
VarTransform: "None" [Variable transformation method]
VarTransformType: "Signal" [Use signal or background events to derive for variable transformation (the transformation is applied on both types of, course)]
NbinsMVAPdf: "60" [Number of bins used for the PDFs of classifier outputs]
NsmoothMVAPdf: "2" [Number of smoothing iterations for classifier PDFs]
VerboseLevel: "Default" [Verbosity level]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
TxtWeightFilesOnly: "True" [If True: write all training results (weights) as text files (False: some are written in ROOT format)]
NeuronInputType: "sum" [Neuron input function type]
TrainingMethod: "BP" [Train with Back-Propagation (BP - default) or Genetic Algorithm (GA - slower and worse)]
LearningRate: "0.02" [ANN learning rate parameter]
DecayRate: "0.01" [Decay rate for learning parameter]
BPMode: "sequential" [Back-propagation learning mode: sequential or batch]
BatchSize: "-1" [Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 13
ClusterParameters.start       ClusterParameters.start           'F'    [0,11.9270019531]
ClusterParameters.end         ClusterParameters.end             'F'    [2.74471616745,33.4141159058]
ClusterParameters.depth       ClusterParameters.depth           'F'    [0,25.1790618896]
ClusterParameters.E1C/ClusterParameters.Etot_g   ClusterParameters.E1C_D_ClusterParameters.Etot_g     'F'    [0,0.972485542297]
ClusterParameters.E4C/ClusterParameters.Etot_g   ClusterParameters.E4C_D_ClusterParameters.Etot_g     'F'    [0.0779080465436,1]
ClusterParameters.E9C/ClusterParameters.Etot_g   ClusterParameters.E9C_D_ClusterParameters.Etot_g     'F'    [0.569036602974,1]
ClusterParameters.dirErr      ClusterParameters.dirErr          'F'    [0.00193390471395,0.999999701977]
ClusterParameters.seedDirErr  ClusterParameters.seedDirErr      'F'    [0,0.999981760979]
ClusterParameters.Width       ClusterParameters.Width           'F'    [1.92015755177,44.1041069031]
ClusterParameters.Eccentricity ClusterParameters.Eccentricity     'F'    [0.0803745761514,0.902505576611]
ClusterParameters.nHits       ClusterParameters.nHits           'F'    [6,66]
ClusterParameters.Volume      ClusterParameters.Volume          'F'    [107.996833801,2929788.25]
ClusterParameters.depth-ClusterParameters.start   ClusterParameters.depth_M_ClusterParameters.start     'F'    [-4.92442703247,25.0946331024]


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;
};

#endif

class ReadMLP1_25_B_1x1 : public IClassifierReader {

 public:

   // constructor
   ReadMLP1_25_B_1x1( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadMLP1_25_B_1x1" ),
        fStatusIsClean( true ),
        fNvars( 13 ),
        fIsNormalised( true )
   {      
      // the training input variables
      const char* inputVars[] = { "ClusterParameters.start", "ClusterParameters.end", "ClusterParameters.depth", "ClusterParameters.E1C/ClusterParameters.Etot_g", "ClusterParameters.E4C/ClusterParameters.Etot_g", "ClusterParameters.E9C/ClusterParameters.Etot_g", "ClusterParameters.dirErr", "ClusterParameters.seedDirErr", "ClusterParameters.Width", "ClusterParameters.Eccentricity", "ClusterParameters.nHits", "ClusterParameters.Volume", "ClusterParameters.depth-ClusterParameters.start" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 11.927001953125;
      fVmin[1] = 2.74471616744995;
      fVmax[1] = 33.4141159057617;
      fVmin[2] = 0;
      fVmax[2] = 25.1790618896484;
      fVmin[3] = 0;
      fVmax[3] = 0.972485542297363;
      fVmin[4] = 0.0779080465435982;
      fVmax[4] = 1;
      fVmin[5] = 0.569036602973938;
      fVmax[5] = 1;
      fVmin[6] = 0.00193390471395105;
      fVmax[6] = 0.999999701976776;
      fVmin[7] = 0;
      fVmax[7] = 0.999981760978699;
      fVmin[8] = 1.92015755176544;
      fVmax[8] = 44.1041069030762;
      fVmin[9] = 0.080374576151371;
      fVmax[9] = 0.902505576610565;
      fVmin[10] = 6;
      fVmax[10] = 66;
      fVmin[11] = 107.99683380127;
      fVmax[11] = 2929788.25;
      fVmin[12] = -4.9244270324707;
      fVmax[12] = 25.094633102417;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';
      fType[10] = 'F';
      fType[11] = 'F';
      fType[12] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadMLP1_25_B_1x1() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;
   bool fStatusIsClean;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[13];
   double fVmax[13];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[13];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)

   double ActivationFnc(double x) const;

   int fLayers;
   int fLayerSize[4];
   double fWeightMatrix0to1[15][14];   // weight matrix from layer 0 to 1
   double fWeightMatrix1to2[14][15];   // weight matrix from layer 1 to 2
   double fWeightMatrix2to3[1][14];   // weight matrix from layer 2 to 3

   double * fWeights[4];
};

inline void ReadMLP1_25_B_1x1::Initialize()
{
   // build network structure
   fLayers = 4;
   fLayerSize[0] = 14; fWeights[0] = new double[14]; 
   fLayerSize[1] = 15; fWeights[1] = new double[15]; 
   fLayerSize[2] = 14; fWeights[2] = new double[14]; 
   fLayerSize[3] = 1; fWeights[3] = new double[1]; 
   // weight matrix from layer 0 to 1
   fWeightMatrix0to1[0][0] = 0.0981423323861354;
   fWeightMatrix0to1[1][0] = 1.95662742833099;
   fWeightMatrix0to1[2][0] = 0.756191547870197;
   fWeightMatrix0to1[3][0] = 2.18388786834201;
   fWeightMatrix0to1[4][0] = -1.48128575355182;
   fWeightMatrix0to1[5][0] = -1.90802168984039;
   fWeightMatrix0to1[6][0] = -0.509657688950576;
   fWeightMatrix0to1[7][0] = 1.86999698916437;
   fWeightMatrix0to1[8][0] = -0.835119832963205;
   fWeightMatrix0to1[9][0] = -0.202545133681392;
   fWeightMatrix0to1[10][0] = -1.47548196106395;
   fWeightMatrix0to1[11][0] = 0.143310404142844;
   fWeightMatrix0to1[12][0] = -1.14895004125215;
   fWeightMatrix0to1[13][0] = -0.997905792375222;
   fWeightMatrix0to1[0][1] = -0.185089044055592;
   fWeightMatrix0to1[1][1] = 0.62502856660204;
   fWeightMatrix0to1[2][1] = -0.962687432676847;
   fWeightMatrix0to1[3][1] = 1.91771123507674;
   fWeightMatrix0to1[4][1] = 0.396157282978013;
   fWeightMatrix0to1[5][1] = 1.30135192306396;
   fWeightMatrix0to1[6][1] = -0.449702301197183;
   fWeightMatrix0to1[7][1] = -0.880150232243161;
   fWeightMatrix0to1[8][1] = 0.412411106045166;
   fWeightMatrix0to1[9][1] = -0.269862697152977;
   fWeightMatrix0to1[10][1] = -0.995721954948493;
   fWeightMatrix0to1[11][1] = -0.806653759847396;
   fWeightMatrix0to1[12][1] = 2.57849899785832;
   fWeightMatrix0to1[13][1] = -0.824681303777392;
   fWeightMatrix0to1[0][2] = -1.51836783728451;
   fWeightMatrix0to1[1][2] = 0.0770650167127415;
   fWeightMatrix0to1[2][2] = 0.375752858162066;
   fWeightMatrix0to1[3][2] = 1.61190490729463;
   fWeightMatrix0to1[4][2] = -0.0536981817414331;
   fWeightMatrix0to1[5][2] = 0.0813589674333458;
   fWeightMatrix0to1[6][2] = 0.176461782827855;
   fWeightMatrix0to1[7][2] = -0.180051547479774;
   fWeightMatrix0to1[8][2] = -1.72265716673787;
   fWeightMatrix0to1[9][2] = 2.05058318547914;
   fWeightMatrix0to1[10][2] = -1.18302661079963;
   fWeightMatrix0to1[11][2] = 1.80439967631012;
   fWeightMatrix0to1[12][2] = 1.55734197912463;
   fWeightMatrix0to1[13][2] = 1.10720379116454;
   fWeightMatrix0to1[0][3] = 1.57518481902982;
   fWeightMatrix0to1[1][3] = 1.33099929292753;
   fWeightMatrix0to1[2][3] = -0.109339870707287;
   fWeightMatrix0to1[3][3] = -1.20244403521513;
   fWeightMatrix0to1[4][3] = 1.13371084903718;
   fWeightMatrix0to1[5][3] = -0.0322128998858885;
   fWeightMatrix0to1[6][3] = 1.81617543196386;
   fWeightMatrix0to1[7][3] = 1.51026768058011;
   fWeightMatrix0to1[8][3] = 0.435326831924636;
   fWeightMatrix0to1[9][3] = -0.533971508015503;
   fWeightMatrix0to1[10][3] = -1.85241185378975;
   fWeightMatrix0to1[11][3] = 0.760851462981666;
   fWeightMatrix0to1[12][3] = -2.20932021747323;
   fWeightMatrix0to1[13][3] = -1.84602005577462;
   fWeightMatrix0to1[0][4] = -1.9893059758373;
   fWeightMatrix0to1[1][4] = -1.68592073994097;
   fWeightMatrix0to1[2][4] = 1.85372721959347;
   fWeightMatrix0to1[3][4] = 0.492716958752544;
   fWeightMatrix0to1[4][4] = -1.54069925164802;
   fWeightMatrix0to1[5][4] = -0.0669044007932943;
   fWeightMatrix0to1[6][4] = -0.0863824580742252;
   fWeightMatrix0to1[7][4] = 0.347740000699013;
   fWeightMatrix0to1[8][4] = 1.69531527141336;
   fWeightMatrix0to1[9][4] = -1.34608255873389;
   fWeightMatrix0to1[10][4] = 0.350645138741515;
   fWeightMatrix0to1[11][4] = -1.26795253551442;
   fWeightMatrix0to1[12][4] = -0.238470021901295;
   fWeightMatrix0to1[13][4] = -1.25607447057754;
   fWeightMatrix0to1[0][5] = -1.02847187285467;
   fWeightMatrix0to1[1][5] = -1.41242048901383;
   fWeightMatrix0to1[2][5] = 1.01356373316909;
   fWeightMatrix0to1[3][5] = 0.762880108117419;
   fWeightMatrix0to1[4][5] = 0.871503863118434;
   fWeightMatrix0to1[5][5] = -0.336641753985933;
   fWeightMatrix0to1[6][5] = -1.82379596836841;
   fWeightMatrix0to1[7][5] = -2.36032988594951;
   fWeightMatrix0to1[8][5] = 0.16813266428811;
   fWeightMatrix0to1[9][5] = 0.066414867737309;
   fWeightMatrix0to1[10][5] = 2.2277516331;
   fWeightMatrix0to1[11][5] = 0.34370539491108;
   fWeightMatrix0to1[12][5] = 0.782539993219958;
   fWeightMatrix0to1[13][5] = -0.442708894865159;
   fWeightMatrix0to1[0][6] = -1.23210537151025;
   fWeightMatrix0to1[1][6] = -0.26412103420626;
   fWeightMatrix0to1[2][6] = 1.31174702202718;
   fWeightMatrix0to1[3][6] = -1.19865088207372;
   fWeightMatrix0to1[4][6] = -1.31789691701334;
   fWeightMatrix0to1[5][6] = -1.2647354875105;
   fWeightMatrix0to1[6][6] = -0.403734350813079;
   fWeightMatrix0to1[7][6] = -0.668836046072694;
   fWeightMatrix0to1[8][6] = 1.47821484622957;
   fWeightMatrix0to1[9][6] = -1.97538270223504;
   fWeightMatrix0to1[10][6] = -0.482524735954347;
   fWeightMatrix0to1[11][6] = 1.63440309560014;
   fWeightMatrix0to1[12][6] = -2.3358274275406;
   fWeightMatrix0to1[13][6] = -0.840497672873838;
   fWeightMatrix0to1[0][7] = -1.59077754970975;
   fWeightMatrix0to1[1][7] = 0.0789702643953415;
   fWeightMatrix0to1[2][7] = -1.78002269522083;
   fWeightMatrix0to1[3][7] = -1.39632519718435;
   fWeightMatrix0to1[4][7] = 0.868818400659639;
   fWeightMatrix0to1[5][7] = 2.43243417057575;
   fWeightMatrix0to1[6][7] = -1.12237163978525;
   fWeightMatrix0to1[7][7] = 1.28195264313251;
   fWeightMatrix0to1[8][7] = 0.0387441272103323;
   fWeightMatrix0to1[9][7] = 0.0503081592970967;
   fWeightMatrix0to1[10][7] = 0.0976946371532425;
   fWeightMatrix0to1[11][7] = 0.579118521838259;
   fWeightMatrix0to1[12][7] = -1.13149616310384;
   fWeightMatrix0to1[13][7] = -0.593886128142892;
   fWeightMatrix0to1[0][8] = 0.662658061104149;
   fWeightMatrix0to1[1][8] = 0.40883339950893;
   fWeightMatrix0to1[2][8] = -1.67068568076837;
   fWeightMatrix0to1[3][8] = 1.81905661966245;
   fWeightMatrix0to1[4][8] = 0.253831688926229;
   fWeightMatrix0to1[5][8] = -0.455751368840942;
   fWeightMatrix0to1[6][8] = 0.566450724962594;
   fWeightMatrix0to1[7][8] = -0.98176919333897;
   fWeightMatrix0to1[8][8] = -1.43416946024657;
   fWeightMatrix0to1[9][8] = -0.275425604089824;
   fWeightMatrix0to1[10][8] = -0.467520257837861;
   fWeightMatrix0to1[11][8] = 1.58198923972127;
   fWeightMatrix0to1[12][8] = 0.814910600099088;
   fWeightMatrix0to1[13][8] = 0.321041618398667;
   fWeightMatrix0to1[0][9] = -0.769607302891971;
   fWeightMatrix0to1[1][9] = 0.172690845594021;
   fWeightMatrix0to1[2][9] = -1.28093001195517;
   fWeightMatrix0to1[3][9] = 0.723348514612237;
   fWeightMatrix0to1[4][9] = -0.703438761306123;
   fWeightMatrix0to1[5][9] = -1.42141810495474;
   fWeightMatrix0to1[6][9] = 0.566463111555527;
   fWeightMatrix0to1[7][9] = -1.41507050101802;
   fWeightMatrix0to1[8][9] = 0.203603763629363;
   fWeightMatrix0to1[9][9] = -0.163550452317743;
   fWeightMatrix0to1[10][9] = 1.57392694614308;
   fWeightMatrix0to1[11][9] = -2.37193816996633;
   fWeightMatrix0to1[12][9] = 0.531075836485665;
   fWeightMatrix0to1[13][9] = 1.13622492188249;
   fWeightMatrix0to1[0][10] = 1.6915466677604;
   fWeightMatrix0to1[1][10] = 0.119751649464295;
   fWeightMatrix0to1[2][10] = -1.64553595645994;
   fWeightMatrix0to1[3][10] = 0.0484703329161208;
   fWeightMatrix0to1[4][10] = -1.68573025922418;
   fWeightMatrix0to1[5][10] = 1.44476567410937;
   fWeightMatrix0to1[6][10] = 1.11731822576523;
   fWeightMatrix0to1[7][10] = -0.549289088972762;
   fWeightMatrix0to1[8][10] = 0.966937143379564;
   fWeightMatrix0to1[9][10] = -3.72416713600636;
   fWeightMatrix0to1[10][10] = -1.37965818496095;
   fWeightMatrix0to1[11][10] = -0.047804209875171;
   fWeightMatrix0to1[12][10] = 0.71398590496916;
   fWeightMatrix0to1[13][10] = -0.320115676320169;
   fWeightMatrix0to1[0][11] = -0.278126186292056;
   fWeightMatrix0to1[1][11] = 0.334120089431264;
   fWeightMatrix0to1[2][11] = 0.891411216686863;
   fWeightMatrix0to1[3][11] = 0.837630781831031;
   fWeightMatrix0to1[4][11] = 1.48177920421342;
   fWeightMatrix0to1[5][11] = -1.52356280483887;
   fWeightMatrix0to1[6][11] = 1.61849056285859;
   fWeightMatrix0to1[7][11] = 1.25532877607877;
   fWeightMatrix0to1[8][11] = 1.38543839534872;
   fWeightMatrix0to1[9][11] = 0.520746334667449;
   fWeightMatrix0to1[10][11] = 0.672743057229997;
   fWeightMatrix0to1[11][11] = -0.78090742055991;
   fWeightMatrix0to1[12][11] = -0.994481733347307;
   fWeightMatrix0to1[13][11] = 0.77463746761985;
   fWeightMatrix0to1[0][12] = -0.68885057999823;
   fWeightMatrix0to1[1][12] = -0.582094983137789;
   fWeightMatrix0to1[2][12] = 1.35504627857466;
   fWeightMatrix0to1[3][12] = 0.895616040985853;
   fWeightMatrix0to1[4][12] = -0.0940214698117537;
   fWeightMatrix0to1[5][12] = 1.87664186739518;
   fWeightMatrix0to1[6][12] = 1.77797259527689;
   fWeightMatrix0to1[7][12] = -1.63652025836199;
   fWeightMatrix0to1[8][12] = 0.442006194088929;
   fWeightMatrix0to1[9][12] = -0.169521703281564;
   fWeightMatrix0to1[10][12] = 0.354603787285905;
   fWeightMatrix0to1[11][12] = -1.3959973704445;
   fWeightMatrix0to1[12][12] = -1.35017057504976;
   fWeightMatrix0to1[13][12] = 1.42817678169557;
   fWeightMatrix0to1[0][13] = 1.40650316466556;
   fWeightMatrix0to1[1][13] = -1.87321696468416;
   fWeightMatrix0to1[2][13] = -0.107304187849763;
   fWeightMatrix0to1[3][13] = -1.01947062873158;
   fWeightMatrix0to1[4][13] = -0.411588473247733;
   fWeightMatrix0to1[5][13] = 1.88722364591486;
   fWeightMatrix0to1[6][13] = -0.710944967859322;
   fWeightMatrix0to1[7][13] = -1.28434093932784;
   fWeightMatrix0to1[8][13] = -2.16364674348871;
   fWeightMatrix0to1[9][13] = 1.35398400406987;
   fWeightMatrix0to1[10][13] = 2.00897666336298;
   fWeightMatrix0to1[11][13] = 1.30040541296622;
   fWeightMatrix0to1[12][13] = 0.573575545127003;
   fWeightMatrix0to1[13][13] = -0.178119205807048;
   // weight matrix from layer 1 to 2
   fWeightMatrix1to2[0][0] = -1.66127552104648;
   fWeightMatrix1to2[1][0] = 0.973874278461301;
   fWeightMatrix1to2[2][0] = 0.426284034688898;
   fWeightMatrix1to2[3][0] = -1.23264273695163;
   fWeightMatrix1to2[4][0] = -0.734646393231423;
   fWeightMatrix1to2[5][0] = 0.254077687611187;
   fWeightMatrix1to2[6][0] = -0.125418222111035;
   fWeightMatrix1to2[7][0] = -1.97938503179353;
   fWeightMatrix1to2[8][0] = 1.42189896024781;
   fWeightMatrix1to2[9][0] = 0.770405146101599;
   fWeightMatrix1to2[10][0] = -0.434607226028662;
   fWeightMatrix1to2[11][0] = -0.13496173770312;
   fWeightMatrix1to2[12][0] = 1.49939105104;
   fWeightMatrix1to2[0][1] = 1.12025548287882;
   fWeightMatrix1to2[1][1] = 0.355586701453297;
   fWeightMatrix1to2[2][1] = 0.0299494139870524;
   fWeightMatrix1to2[3][1] = -2.09070374883355;
   fWeightMatrix1to2[4][1] = -0.992902328306452;
   fWeightMatrix1to2[5][1] = 1.75457571747496;
   fWeightMatrix1to2[6][1] = 1.7498883732402;
   fWeightMatrix1to2[7][1] = 0.484203826744521;
   fWeightMatrix1to2[8][1] = 0.0625921587441042;
   fWeightMatrix1to2[9][1] = 1.52109206175619;
   fWeightMatrix1to2[10][1] = -2.04256954717013;
   fWeightMatrix1to2[11][1] = -1.31465763893517;
   fWeightMatrix1to2[12][1] = -0.257182297927742;
   fWeightMatrix1to2[0][2] = -1.45426087731463;
   fWeightMatrix1to2[1][2] = 0.867374185435348;
   fWeightMatrix1to2[2][2] = 1.55234911567396;
   fWeightMatrix1to2[3][2] = -1.16077428136604;
   fWeightMatrix1to2[4][2] = 0.577235642527657;
   fWeightMatrix1to2[5][2] = -0.171630587237672;
   fWeightMatrix1to2[6][2] = -1.58519639732011;
   fWeightMatrix1to2[7][2] = -0.869049879392307;
   fWeightMatrix1to2[8][2] = 1.0521868579976;
   fWeightMatrix1to2[9][2] = 0.417158400546195;
   fWeightMatrix1to2[10][2] = 0.746982937180271;
   fWeightMatrix1to2[11][2] = -1.16274213372989;
   fWeightMatrix1to2[12][2] = 1.62970492697544;
   fWeightMatrix1to2[0][3] = -1.64079114235686;
   fWeightMatrix1to2[1][3] = 0.626861738083959;
   fWeightMatrix1to2[2][3] = 0.234412069679059;
   fWeightMatrix1to2[3][3] = -1.45003624706882;
   fWeightMatrix1to2[4][3] = -1.51454039102461;
   fWeightMatrix1to2[5][3] = -1.83614614133999;
   fWeightMatrix1to2[6][3] = -0.0905901970446118;
   fWeightMatrix1to2[7][3] = -2.1157069501531;
   fWeightMatrix1to2[8][3] = -1.73487502654726;
   fWeightMatrix1to2[9][3] = -1.71825882852707;
   fWeightMatrix1to2[10][3] = 0.10602525231704;
   fWeightMatrix1to2[11][3] = -1.00376757576855;
   fWeightMatrix1to2[12][3] = -1.74808876876365;
   fWeightMatrix1to2[0][4] = 1.54678359233453;
   fWeightMatrix1to2[1][4] = -0.938144418960526;
   fWeightMatrix1to2[2][4] = 0.53891660662525;
   fWeightMatrix1to2[3][4] = -1.16582820036724;
   fWeightMatrix1to2[4][4] = -0.680767842778094;
   fWeightMatrix1to2[5][4] = 1.82142997818001;
   fWeightMatrix1to2[6][4] = 0.824340607272661;
   fWeightMatrix1to2[7][4] = -1.08060290583913;
   fWeightMatrix1to2[8][4] = -1.48168866927856;
   fWeightMatrix1to2[9][4] = -1.36267265872612;
   fWeightMatrix1to2[10][4] = -0.864142815770657;
   fWeightMatrix1to2[11][4] = -1.65160560056596;
   fWeightMatrix1to2[12][4] = 0.24544475216867;
   fWeightMatrix1to2[0][5] = 0.0972802340544639;
   fWeightMatrix1to2[1][5] = 1.9126890112738;
   fWeightMatrix1to2[2][5] = -0.398245899815527;
   fWeightMatrix1to2[3][5] = 0.339187686947459;
   fWeightMatrix1to2[4][5] = -1.54197361654601;
   fWeightMatrix1to2[5][5] = -1.85928980925863;
   fWeightMatrix1to2[6][5] = 0.868827784935302;
   fWeightMatrix1to2[7][5] = 1.34910161323033;
   fWeightMatrix1to2[8][5] = -0.700856566920056;
   fWeightMatrix1to2[9][5] = -0.919484138788671;
   fWeightMatrix1to2[10][5] = 0.960463582878277;
   fWeightMatrix1to2[11][5] = 1.21595665171686;
   fWeightMatrix1to2[12][5] = 0.590499006828902;
   fWeightMatrix1to2[0][6] = -0.373289796163663;
   fWeightMatrix1to2[1][6] = -0.680905672197981;
   fWeightMatrix1to2[2][6] = 1.61446142937799;
   fWeightMatrix1to2[3][6] = 0.84434249521722;
   fWeightMatrix1to2[4][6] = 0.945448613176144;
   fWeightMatrix1to2[5][6] = -0.270926575920354;
   fWeightMatrix1to2[6][6] = 0.730380729357109;
   fWeightMatrix1to2[7][6] = -0.518137500130114;
   fWeightMatrix1to2[8][6] = -1.59140732343409;
   fWeightMatrix1to2[9][6] = -0.925764199191043;
   fWeightMatrix1to2[10][6] = -1.71090290634772;
   fWeightMatrix1to2[11][6] = -1.38939374454992;
   fWeightMatrix1to2[12][6] = -1.66586134076545;
   fWeightMatrix1to2[0][7] = 1.81245574932327;
   fWeightMatrix1to2[1][7] = -1.88665931493272;
   fWeightMatrix1to2[2][7] = 2.00287062373177;
   fWeightMatrix1to2[3][7] = -1.72672777538492;
   fWeightMatrix1to2[4][7] = 0.497303773222882;
   fWeightMatrix1to2[5][7] = -1.05422928811949;
   fWeightMatrix1to2[6][7] = 0.903615476270798;
   fWeightMatrix1to2[7][7] = 0.576314452673577;
   fWeightMatrix1to2[8][7] = -2.00200040530884;
   fWeightMatrix1to2[9][7] = -0.224445474660014;
   fWeightMatrix1to2[10][7] = 0.276579177398822;
   fWeightMatrix1to2[11][7] = -1.95536851098887;
   fWeightMatrix1to2[12][7] = -1.49749628651226;
   fWeightMatrix1to2[0][8] = -1.80364406085963;
   fWeightMatrix1to2[1][8] = -0.87602117244367;
   fWeightMatrix1to2[2][8] = 1.7629775571417;
   fWeightMatrix1to2[3][8] = -0.708235843469674;
   fWeightMatrix1to2[4][8] = 1.34271602339019;
   fWeightMatrix1to2[5][8] = -1.04882465173808;
   fWeightMatrix1to2[6][8] = -1.13953868305106;
   fWeightMatrix1to2[7][8] = -1.43849390800373;
   fWeightMatrix1to2[8][8] = -0.920389738730747;
   fWeightMatrix1to2[9][8] = -1.03928461094494;
   fWeightMatrix1to2[10][8] = 0.631168994521837;
   fWeightMatrix1to2[11][8] = -1.34530157160766;
   fWeightMatrix1to2[12][8] = -1.07400832368593;
   fWeightMatrix1to2[0][9] = 1.95938749578105;
   fWeightMatrix1to2[1][9] = 0.198535814032973;
   fWeightMatrix1to2[2][9] = -0.372532939163419;
   fWeightMatrix1to2[3][9] = 1.98264436191495;
   fWeightMatrix1to2[4][9] = -4.05414702368511;
   fWeightMatrix1to2[5][9] = 1.35262534245876;
   fWeightMatrix1to2[6][9] = 1.03497922712815;
   fWeightMatrix1to2[7][9] = -1.13997470055772;
   fWeightMatrix1to2[8][9] = -0.679978861721643;
   fWeightMatrix1to2[9][9] = -0.156315133257926;
   fWeightMatrix1to2[10][9] = -1.07400557107062;
   fWeightMatrix1to2[11][9] = 0.466485545105436;
   fWeightMatrix1to2[12][9] = 1.77424923189242;
   fWeightMatrix1to2[0][10] = 1.23775885379516;
   fWeightMatrix1to2[1][10] = 1.68476240424419;
   fWeightMatrix1to2[2][10] = -1.50221727762776;
   fWeightMatrix1to2[3][10] = 1.19848472761643;
   fWeightMatrix1to2[4][10] = -1.59439534647658;
   fWeightMatrix1to2[5][10] = 0.570995546260065;
   fWeightMatrix1to2[6][10] = -1.87504520092352;
   fWeightMatrix1to2[7][10] = -1.57885082246373;
   fWeightMatrix1to2[8][10] = 0.0740474628745369;
   fWeightMatrix1to2[9][10] = 1.7751289707761;
   fWeightMatrix1to2[10][10] = 0.728142198635624;
   fWeightMatrix1to2[11][10] = 1.05364650360281;
   fWeightMatrix1to2[12][10] = 0.421446529917676;
   fWeightMatrix1to2[0][11] = -0.278944020340852;
   fWeightMatrix1to2[1][11] = -0.594057642994541;
   fWeightMatrix1to2[2][11] = -0.0114991845361094;
   fWeightMatrix1to2[3][11] = 1.89029639448861;
   fWeightMatrix1to2[4][11] = -2.1013500038618;
   fWeightMatrix1to2[5][11] = 0.323248809600586;
   fWeightMatrix1to2[6][11] = -1.59029880954982;
   fWeightMatrix1to2[7][11] = -0.248603636082459;
   fWeightMatrix1to2[8][11] = 0.176404437165716;
   fWeightMatrix1to2[9][11] = 0.586264465827587;
   fWeightMatrix1to2[10][11] = -0.832456074167833;
   fWeightMatrix1to2[11][11] = 0.995986329336962;
   fWeightMatrix1to2[12][11] = 1.80377041593339;
   fWeightMatrix1to2[0][12] = 1.00583586487234;
   fWeightMatrix1to2[1][12] = -0.135660343301201;
   fWeightMatrix1to2[2][12] = -0.828817816412363;
   fWeightMatrix1to2[3][12] = -1.32771517821511;
   fWeightMatrix1to2[4][12] = -2.42299910389973;
   fWeightMatrix1to2[5][12] = 1.10884985360881;
   fWeightMatrix1to2[6][12] = -0.970783761495042;
   fWeightMatrix1to2[7][12] = -1.14772603959877;
   fWeightMatrix1to2[8][12] = 0.385522644952909;
   fWeightMatrix1to2[9][12] = -1.42347154216942;
   fWeightMatrix1to2[10][12] = -0.820247768415906;
   fWeightMatrix1to2[11][12] = -1.60667174295706;
   fWeightMatrix1to2[12][12] = 0.862919398257264;
   fWeightMatrix1to2[0][13] = -1.27850315464957;
   fWeightMatrix1to2[1][13] = -1.67082974857596;
   fWeightMatrix1to2[2][13] = -0.417374722822906;
   fWeightMatrix1to2[3][13] = -0.86416827365118;
   fWeightMatrix1to2[4][13] = -2.15136187075641;
   fWeightMatrix1to2[5][13] = 1.33209253403835;
   fWeightMatrix1to2[6][13] = -1.81024569101925;
   fWeightMatrix1to2[7][13] = -1.44726202810431;
   fWeightMatrix1to2[8][13] = 1.59737760582022;
   fWeightMatrix1to2[9][13] = 0.234504093981298;
   fWeightMatrix1to2[10][13] = 0.526978264904412;
   fWeightMatrix1to2[11][13] = 0.0950958200129346;
   fWeightMatrix1to2[12][13] = 1.2101772444608;
   fWeightMatrix1to2[0][14] = 1.63775213338402;
   fWeightMatrix1to2[1][14] = 0.640694741429423;
   fWeightMatrix1to2[2][14] = -1.10719393636547;
   fWeightMatrix1to2[3][14] = -0.543319830961279;
   fWeightMatrix1to2[4][14] = -1.69692577938135;
   fWeightMatrix1to2[5][14] = 0.875956407472751;
   fWeightMatrix1to2[6][14] = 0.489912924875863;
   fWeightMatrix1to2[7][14] = 0.37243399732315;
   fWeightMatrix1to2[8][14] = 1.23160287429807;
   fWeightMatrix1to2[9][14] = 1.39760715064399;
   fWeightMatrix1to2[10][14] = 1.97003676375837;
   fWeightMatrix1to2[11][14] = -1.3342746865885;
   fWeightMatrix1to2[12][14] = 1.87538794371741;
   // weight matrix from layer 2 to 3
   fWeightMatrix2to3[0][0] = 0.0323707961644869;
   fWeightMatrix2to3[0][1] = -1.66697998957229;
   fWeightMatrix2to3[0][2] = -0.780724303588175;
   fWeightMatrix2to3[0][3] = -0.845862587340718;
   fWeightMatrix2to3[0][4] = 1.02944168850774;
   fWeightMatrix2to3[0][5] = 0.00224339967923133;
   fWeightMatrix2to3[0][6] = 1.2224721813887;
   fWeightMatrix2to3[0][7] = 0.00519606069031982;
   fWeightMatrix2to3[0][8] = 0.548681362835129;
   fWeightMatrix2to3[0][9] = 0.115718429270324;
   fWeightMatrix2to3[0][10] = 1.13492306074351;
   fWeightMatrix2to3[0][11] = 0.298102337704457;
   fWeightMatrix2to3[0][12] = -0.89479215687483;
   fWeightMatrix2to3[0][13] = 1.75299490267379;
}

inline double ReadMLP1_25_B_1x1::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   if (inputValues.size() != (unsigned int)fLayerSize[0]-1) {
      std::cout << "Input vector needs to be of size " << fLayerSize[0]-1 << std::endl;
      return 0;
   }

   for (int l=0; l<fLayers; l++)
      for (int i=0; i<fLayerSize[l]; i++) fWeights[l][i]=0;

   for (int l=0; l<fLayers-1; l++)
      fWeights[l][fLayerSize[l]-1]=1;

   for (int i=0; i<fLayerSize[0]-1; i++)
      fWeights[0][i]=inputValues[i];

   // layer 0 to 1
   for (int o=0; o<fLayerSize[1]-1; o++) {
      for (int i=0; i<fLayerSize[0]; i++) {
         double inputVal = fWeightMatrix0to1[o][i] * fWeights[0][i];
         fWeights[1][o] += inputVal;
      }
      fWeights[1][o] = ActivationFnc(fWeights[1][o]);
   }
   // layer 1 to 2
   for (int o=0; o<fLayerSize[2]-1; o++) {
      for (int i=0; i<fLayerSize[1]; i++) {
         double inputVal = fWeightMatrix1to2[o][i] * fWeights[1][i];
         fWeights[2][o] += inputVal;
      }
      fWeights[2][o] = ActivationFnc(fWeights[2][o]);
   }
   // layer 2 to 3
   for (int o=0; o<fLayerSize[3]; o++) {
      for (int i=0; i<fLayerSize[2]; i++) {
         double inputVal = fWeightMatrix2to3[o][i] * fWeights[2][i];
         fWeights[3][o] += inputVal;
      }
   }

   return fWeights[3][0];
}

double ReadMLP1_25_B_1x1::ActivationFnc(double x) const
{
   // hyperbolic tan
   return tanh(x);
}
 
   
// Clean up
inline void ReadMLP1_25_B_1x1::Clear() 
{
   // nothing to clear
}
inline double ReadMLP1_25_B_1x1::GetMvaValue( const std::vector<double>& inputValues ) const
{
   // classifier response value
   double retval = 0;

   // classifier response, sanity check first
   if (!fStatusIsClean) {
      std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
      retval = 0;
   }
   else {
      if (IsNormalised()) {
         // normalise variables
         std::vector<double> iV;
         int ivar = 0;
         for (std::vector<double>::const_iterator varIt = inputValues.begin();
              varIt != inputValues.end(); varIt++, ivar++) {
            iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
         }
         retval = GetMvaValue__( iV );
      }
      else {
         retval = GetMvaValue__( inputValues );
      }
   }

   return retval;
}

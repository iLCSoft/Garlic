// Class: ReadMLP20_EC
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : MLP::MLP
TMVA Release   : 3.9.6         [198918]
ROOT Release   : 5.16/00       [331776]
Creator        : reinhard
Date           : Sat Aug  8 11:56:20 2009
Host           : Linux polui02.in2p3.fr 2.6.9-67.0.4.ELsmp #1 SMP Thu Jan 31 16:30:09 CST 2008 i686 i686 i386 GNU/Linux
Dir            : /grid_mnt/data2__polgrid/llr/ilc/reinhard/ILCSoft/TMVA/macros
Training events: 19894


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
Normalise: "True" [Normalise input variables]
V: "False" [Verbose mode]
H: "True" [Print classifier-specific help message]
NCycles: "500" [Number of training cycles]
HiddenLayers: "N+1,N" [Specification of hidden layer architecture (N stands for number of variables; any integers may also be used)]
NeuronType: "tanh" [Neuron activation function type]
TestRate: "5" [Test for overtraining performed at each #th epochs]
# Default:
D: "False" [Use-decorrelated-variables flag (depreciated)]
VarTransform: "None" [Variable transformation method]
VarTransformType: "Signal" [Use signal or background events to derive for variable transformation (the transformation is applied on both types of, course)]
NbinsMVAPdf: "60" [Number of bins used for the PDFs of classifier outputs]
NsmoothMVAPdf: "2" [Number of smoothing iterations for classifier PDFs]
VerboseLevel: "Default" [Verbosity level]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
TxtWeightFilesOnly: "True" [If True: write all training results (weights) as text files (False: some are written in ROOT format)]
NeuronInputType: "sum" [Neuron input function type]
TrainingMethod: "BP" [Train with Back-Propagation (BP - default) or Genetic Algorithm (GA - slower and worse)]
LearningRate: "0.02" [ANN learning rate parameter]
DecayRate: "0.01" [Decay rate for learning parameter]
BPMode: "sequential" [Back-propagation learning mode: sequential or batch]
BatchSize: "-1" [Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 14
ClusterParameters.start       ClusterParameters.start           'F'    [0,9.89420700073]
ClusterParameters.end         ClusterParameters.end             'F'    [11.4898405075,39.0738525391]
ClusterParameters.depth       ClusterParameters.depth           'F'    [0,25.3973350525]
ClusterParameters.E1C/ClusterParameters.Etot_g   ClusterParameters.E1C_D_ClusterParameters.Etot_g     'F'    [0,0.647727549076]
ClusterParameters.E4C/ClusterParameters.Etot_g   ClusterParameters.E4C_D_ClusterParameters.Etot_g     'F'    [0.00689294794574,0.878475010395]
ClusterParameters.E9C/ClusterParameters.Etot_g   ClusterParameters.E9C_D_ClusterParameters.Etot_g     'F'    [0.225980043411,0.982463896275]
ClusterParameters.dirErr      ClusterParameters.dirErr          'F'    [0.923966705799,1]
ClusterParameters.seedDirErr  ClusterParameters.seedDirErr      'F'    [-0.000139657757245,0.999999880791]
ClusterParameters.Es3/ClusterParameters.Etot_g   ClusterParameters.Es3_D_ClusterParameters.Etot_g     'F'    [0,0.865082919598]
ClusterParameters.Width       ClusterParameters.Width           'F'    [4.85537672043,20.0779495239]
ClusterParameters.Eccentricity ClusterParameters.Eccentricity     'F'    [0.117384552956,0.672489464283]
ClusterParameters.nHits       ClusterParameters.nHits           'F'    [83,632]
ClusterParameters.Volume      ClusterParameters.Volume          'F'    [3743.04541016,618100.75]
ClusterParameters.depth-ClusterParameters.start   ClusterParameters.depth_M_ClusterParameters.start     'F'    [-1.06279778481,23.6541996002]


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;
};

#endif

class ReadMLP20_EC : public IClassifierReader {

 public:

   // constructor
   ReadMLP20_EC( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadMLP20_EC" ),
        fStatusIsClean( true ),
        fNvars( 14 ),
        fIsNormalised( true )
   {      
      // the training input variables
      const char* inputVars[] = { "ClusterParameters.start", "ClusterParameters.end", "ClusterParameters.depth", "ClusterParameters.E1C/ClusterParameters.Etot_g", "ClusterParameters.E4C/ClusterParameters.Etot_g", "ClusterParameters.E9C/ClusterParameters.Etot_g", "ClusterParameters.dirErr", "ClusterParameters.seedDirErr", "ClusterParameters.Es3/ClusterParameters.Etot_g", "ClusterParameters.Width", "ClusterParameters.Eccentricity", "ClusterParameters.nHits", "ClusterParameters.Volume", "ClusterParameters.depth-ClusterParameters.start" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 9.89420700073242;
      fVmin[1] = 11.4898405075073;
      fVmax[1] = 39.0738525390625;
      fVmin[2] = 0;
      fVmax[2] = 25.3973350524902;
      fVmin[3] = 0;
      fVmax[3] = 0.64772754907608;
      fVmin[4] = 0.0068929479457438;
      fVmax[4] = 0.87847501039505;
      fVmin[5] = 0.225980043411255;
      fVmax[5] = 0.982463896274567;
      fVmin[6] = 0.923966705799103;
      fVmax[6] = 1;
      fVmin[7] = -0.000139657757245004;
      fVmax[7] = 0.99999988079071;
      fVmin[8] = 0;
      fVmax[8] = 0.865082919597626;
      fVmin[9] = 4.85537672042847;
      fVmax[9] = 20.0779495239258;
      fVmin[10] = 0.117384552955627;
      fVmax[10] = 0.67248946428299;
      fVmin[11] = 83;
      fVmax[11] = 632;
      fVmin[12] = 3743.04541015625;
      fVmax[12] = 618100.75;
      fVmin[13] = -1.0627977848053;
      fVmax[13] = 23.6541996002197;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';
      fType[10] = 'F';
      fType[11] = 'F';
      fType[12] = 'F';
      fType[13] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadMLP20_EC() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;
   bool fStatusIsClean;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[14];
   double fVmax[14];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[14];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)

   double ActivationFnc(double x) const;

   int fLayers;
   int fLayerSize[4];
   double fWeightMatrix0to1[16][15];   // weight matrix from layer 0 to 1
   double fWeightMatrix1to2[15][16];   // weight matrix from layer 1 to 2
   double fWeightMatrix2to3[1][15];   // weight matrix from layer 2 to 3

   double * fWeights[4];
};

inline void ReadMLP20_EC::Initialize()
{
   // build network structure
   fLayers = 4;
   fLayerSize[0] = 15; fWeights[0] = new double[15]; 
   fLayerSize[1] = 16; fWeights[1] = new double[16]; 
   fLayerSize[2] = 15; fWeights[2] = new double[15]; 
   fLayerSize[3] = 1; fWeights[3] = new double[1]; 
   // weight matrix from layer 0 to 1
   fWeightMatrix0to1[0][0] = -0.0743512708569904;
   fWeightMatrix0to1[1][0] = 1.67420367371901;
   fWeightMatrix0to1[2][0] = 0.681648504380261;
   fWeightMatrix0to1[3][0] = 1.72189278725047;
   fWeightMatrix0to1[4][0] = -1.93210481659621;
   fWeightMatrix0to1[5][0] = -1.69997750500696;
   fWeightMatrix0to1[6][0] = -0.739493036096636;
   fWeightMatrix0to1[7][0] = 1.761906013739;
   fWeightMatrix0to1[8][0] = -1.12041653468455;
   fWeightMatrix0to1[9][0] = -1.05418588846816;
   fWeightMatrix0to1[10][0] = -1.23451182024109;
   fWeightMatrix0to1[11][0] = 0.134383011301654;
   fWeightMatrix0to1[12][0] = -1.18432723095433;
   fWeightMatrix0to1[13][0] = -0.215659589451298;
   fWeightMatrix0to1[14][0] = -0.808389868917698;
   fWeightMatrix0to1[0][1] = 0.682957747157198;
   fWeightMatrix0to1[1][1] = -0.474568159139525;
   fWeightMatrix0to1[2][1] = 1.69029499839973;
   fWeightMatrix0to1[3][1] = 0.264486439269685;
   fWeightMatrix0to1[4][1] = 1.35753331142477;
   fWeightMatrix0to1[5][1] = -0.319053476894219;
   fWeightMatrix0to1[6][1] = -0.739420387742132;
   fWeightMatrix0to1[7][1] = 0.590170397746144;
   fWeightMatrix0to1[8][1] = 0.284084517171619;
   fWeightMatrix0to1[9][1] = -1.21287033089857;
   fWeightMatrix0to1[10][1] = -0.904833519629807;
   fWeightMatrix0to1[11][1] = 1.63259253583164;
   fWeightMatrix0to1[12][1] = -1.04882822164926;
   fWeightMatrix0to1[13][1] = -1.84965784329571;
   fWeightMatrix0to1[14][1] = 0.231154425808089;
   fWeightMatrix0to1[0][2] = 0.535265053484256;
   fWeightMatrix0to1[1][2] = 1.41893167767724;
   fWeightMatrix0to1[2][2] = -0.472247067764231;
   fWeightMatrix0to1[3][2] = -0.157802604958308;
   fWeightMatrix0to1[4][2] = -0.308222868466904;
   fWeightMatrix0to1[5][2] = -0.436000000745859;
   fWeightMatrix0to1[6][2] = -1.17189991171086;
   fWeightMatrix0to1[7][2] = 1.20346130284611;
   fWeightMatrix0to1[8][2] = -1.05984526794662;
   fWeightMatrix0to1[9][2] = 0.700919157568131;
   fWeightMatrix0to1[10][2] = 1.24384190281543;
   fWeightMatrix0to1[11][2] = 0.859257255207213;
   fWeightMatrix0to1[12][2] = 1.94969151767064;
   fWeightMatrix0to1[13][2] = 1.48633843414769;
   fWeightMatrix0to1[14][2] = -0.758264118634764;
   fWeightMatrix0to1[0][3] = -2.08541078658444;
   fWeightMatrix0to1[1][3] = 1.22335434628783;
   fWeightMatrix0to1[2][3] = 0.397952244876732;
   fWeightMatrix0to1[3][3] = 1.2695485420573;
   fWeightMatrix0to1[4][3] = 0.941640492797199;
   fWeightMatrix0to1[5][3] = 1.67367746556439;
   fWeightMatrix0to1[6][3] = 0.182229750894506;
   fWeightMatrix0to1[7][3] = -0.680738561005951;
   fWeightMatrix0to1[8][3] = 1.7792733992997;
   fWeightMatrix0to1[9][3] = -1.04099921477404;
   fWeightMatrix0to1[10][3] = -0.883770964035221;
   fWeightMatrix0to1[11][3] = -0.383374186576394;
   fWeightMatrix0to1[12][3] = -1.70923777370121;
   fWeightMatrix0to1[13][3] = 0.991144119054505;
   fWeightMatrix0to1[14][3] = 1.13246608827833;
   fWeightMatrix0to1[0][4] = -1.49091661668956;
   fWeightMatrix0to1[1][4] = 0.610079479118316;
   fWeightMatrix0to1[2][4] = -0.0488598658482925;
   fWeightMatrix0to1[3][4] = 0.689123904119845;
   fWeightMatrix0to1[4][4] = 0.960963654096269;
   fWeightMatrix0to1[5][4] = -0.219003002864926;
   fWeightMatrix0to1[6][4] = 1.53959369481643;
   fWeightMatrix0to1[7][4] = -0.665001151513468;
   fWeightMatrix0to1[8][4] = 1.33052857294907;
   fWeightMatrix0to1[9][4] = -0.470064847119282;
   fWeightMatrix0to1[10][4] = -1.50928898773437;
   fWeightMatrix0to1[11][4] = -2.0441725230284;
   fWeightMatrix0to1[12][4] = 0.894540712738421;
   fWeightMatrix0to1[13][4] = 0.840365529836797;
   fWeightMatrix0to1[14][4] = 1.36254783442129;
   fWeightMatrix0to1[0][5] = -0.25473180740473;
   fWeightMatrix0to1[1][5] = -1.92463927949517;
   fWeightMatrix0to1[2][5] = -1.74927264325435;
   fWeightMatrix0to1[3][5] = 0.767504791479036;
   fWeightMatrix0to1[4][5] = 0.00906327920329659;
   fWeightMatrix0to1[5][5] = 2.00179309998837;
   fWeightMatrix0to1[6][5] = 1.41966796843577;
   fWeightMatrix0to1[7][5] = 1.02996882152304;
   fWeightMatrix0to1[8][5] = -0.388318321888896;
   fWeightMatrix0to1[9][5] = -1.19887292677201;
   fWeightMatrix0to1[10][5] = -0.356146272709772;
   fWeightMatrix0to1[11][5] = 0.923640033064524;
   fWeightMatrix0to1[12][5] = -1.01974939650866;
   fWeightMatrix0to1[13][5] = -1.47577806452862;
   fWeightMatrix0to1[14][5] = -1.67352694518724;
   fWeightMatrix0to1[0][6] = -0.165166336743384;
   fWeightMatrix0to1[1][6] = -0.56502401669696;
   fWeightMatrix0to1[2][6] = 1.35964345873998;
   fWeightMatrix0to1[3][6] = -1.91850468971022;
   fWeightMatrix0to1[4][6] = -0.888949920671379;
   fWeightMatrix0to1[5][6] = 1.68721575600319;
   fWeightMatrix0to1[6][6] = -1.16910154088955;
   fWeightMatrix0to1[7][6] = -2.08109635704159;
   fWeightMatrix0to1[8][6] = -1.21560030832221;
   fWeightMatrix0to1[9][6] = -0.509453758508699;
   fWeightMatrix0to1[10][6] = -1.05125888189749;
   fWeightMatrix0to1[11][6] = -1.33767349608942;
   fWeightMatrix0to1[12][6] = 0.682455651795518;
   fWeightMatrix0to1[13][6] = 1.97239050660111;
   fWeightMatrix0to1[14][6] = -1.28521244932708;
   fWeightMatrix0to1[0][7] = 1.08244098764543;
   fWeightMatrix0to1[1][7] = -0.55371328879884;
   fWeightMatrix0to1[2][7] = -0.549407232846792;
   fWeightMatrix0to1[3][7] = -0.319092539140883;
   fWeightMatrix0to1[4][7] = 0.246519329365448;
   fWeightMatrix0to1[5][7] = -1.440318945055;
   fWeightMatrix0to1[6][7] = 0.609712158716342;
   fWeightMatrix0to1[7][7] = 0.380601758347604;
   fWeightMatrix0to1[8][7] = 0.514112001150564;
   fWeightMatrix0to1[9][7] = -1.44957162582715;
   fWeightMatrix0to1[10][7] = 0.418789964886563;
   fWeightMatrix0to1[11][7] = -1.05578246843983;
   fWeightMatrix0to1[12][7] = -1.02089056178037;
   fWeightMatrix0to1[13][7] = 0.591148877180641;
   fWeightMatrix0to1[14][7] = -1.31029928155794;
   fWeightMatrix0to1[0][8] = -1.65422079945859;
   fWeightMatrix0to1[1][8] = 0.459033126494413;
   fWeightMatrix0to1[2][8] = -0.139822347205665;
   fWeightMatrix0to1[3][8] = 2.09784108658736;
   fWeightMatrix0to1[4][8] = 0.615262299217902;
   fWeightMatrix0to1[5][8] = -0.25048551527956;
   fWeightMatrix0to1[6][8] = -0.491000249394581;
   fWeightMatrix0to1[7][8] = 0.507257643472704;
   fWeightMatrix0to1[8][8] = -1.79405399443342;
   fWeightMatrix0to1[9][8] = 1.27502341783909;
   fWeightMatrix0to1[10][8] = -0.364234685077364;
   fWeightMatrix0to1[11][8] = -1.62357529508382;
   fWeightMatrix0to1[12][8] = 0.845713938066506;
   fWeightMatrix0to1[13][8] = -1.69463473990498;
   fWeightMatrix0to1[14][8] = -0.066867203411549;
   fWeightMatrix0to1[0][9] = 1.05233852447072;
   fWeightMatrix0to1[1][9] = 1.67736329350941;
   fWeightMatrix0to1[2][9] = -2.06700665432917;
   fWeightMatrix0to1[3][9] = 0.442680521068607;
   fWeightMatrix0to1[4][9] = 2.0770493561371;
   fWeightMatrix0to1[5][9] = 1.49020051677125;
   fWeightMatrix0to1[6][9] = -1.13361982517064;
   fWeightMatrix0to1[7][9] = -1.6398051681815;
   fWeightMatrix0to1[8][9] = -0.622820300500907;
   fWeightMatrix0to1[9][9] = -1.38823820254474;
   fWeightMatrix0to1[10][9] = 2.44055605575261;
   fWeightMatrix0to1[11][9] = 1.50200722726928;
   fWeightMatrix0to1[12][9] = -0.603688947655533;
   fWeightMatrix0to1[13][9] = -0.390910993547016;
   fWeightMatrix0to1[14][9] = 0.158488313521864;
   fWeightMatrix0to1[0][10] = -1.42736605010625;
   fWeightMatrix0to1[1][10] = 0.517719851589504;
   fWeightMatrix0to1[2][10] = 1.56151949699865;
   fWeightMatrix0to1[3][10] = -0.645156626237117;
   fWeightMatrix0to1[4][10] = -0.257500169687334;
   fWeightMatrix0to1[5][10] = 0.0640307258263142;
   fWeightMatrix0to1[6][10] = 1.37602007796731;
   fWeightMatrix0to1[7][10] = 0.486229988508696;
   fWeightMatrix0to1[8][10] = 0.401472516441305;
   fWeightMatrix0to1[9][10] = -1.3431278220548;
   fWeightMatrix0to1[10][10] = 2.77078872166244;
   fWeightMatrix0to1[11][10] = 0.431851736917258;
   fWeightMatrix0to1[12][10] = 0.388942352725976;
   fWeightMatrix0to1[13][10] = 0.648403233604284;
   fWeightMatrix0to1[14][10] = 0.907855175529918;
   fWeightMatrix0to1[0][11] = -0.521915811814797;
   fWeightMatrix0to1[1][11] = -0.419351821086856;
   fWeightMatrix0to1[2][11] = 1.07376869733708;
   fWeightMatrix0to1[3][11] = -0.691958556491284;
   fWeightMatrix0to1[4][11] = -0.805795869170176;
   fWeightMatrix0to1[5][11] = 1.588828207173;
   fWeightMatrix0to1[6][11] = 0.809753456828172;
   fWeightMatrix0to1[7][11] = 0.0676103927193761;
   fWeightMatrix0to1[8][11] = 1.72869208406071;
   fWeightMatrix0to1[9][11] = 2.08866724539532;
   fWeightMatrix0to1[10][11] = -1.7832658228241;
   fWeightMatrix0to1[11][11] = 0.378088459725493;
   fWeightMatrix0to1[12][11] = -0.276800564609257;
   fWeightMatrix0to1[13][11] = 0.228292133758878;
   fWeightMatrix0to1[14][11] = -1.73194538542185;
   fWeightMatrix0to1[0][12] = -1.5748825914754;
   fWeightMatrix0to1[1][12] = 1.62759867118943;
   fWeightMatrix0to1[2][12] = 2.05177693517258;
   fWeightMatrix0to1[3][12] = -1.41776352347665;
   fWeightMatrix0to1[4][12] = -0.364809236097003;
   fWeightMatrix0to1[5][12] = -0.566411994550893;
   fWeightMatrix0to1[6][12] = 1.20958283165742;
   fWeightMatrix0to1[7][12] = 2.52617748564145;
   fWeightMatrix0to1[8][12] = -0.316436358518745;
   fWeightMatrix0to1[9][12] = 0.176482517068414;
   fWeightMatrix0to1[10][12] = -2.53177029827568;
   fWeightMatrix0to1[11][12] = 0.866361839894678;
   fWeightMatrix0to1[12][12] = 1.67056620182974;
   fWeightMatrix0to1[13][12] = 0.619600172810248;
   fWeightMatrix0to1[14][12] = 0.465900226159494;
   fWeightMatrix0to1[0][13] = -1.0557353237198;
   fWeightMatrix0to1[1][13] = -1.93780008138602;
   fWeightMatrix0to1[2][13] = 1.12042829922342;
   fWeightMatrix0to1[3][13] = 0.581646039534203;
   fWeightMatrix0to1[4][13] = -2.02834366134838;
   fWeightMatrix0to1[5][13] = -0.787084220483192;
   fWeightMatrix0to1[6][13] = 0.916626358873245;
   fWeightMatrix0to1[7][13] = -0.0704502137478987;
   fWeightMatrix0to1[8][13] = -1.92611633045731;
   fWeightMatrix0to1[9][13] = 1.35424164828065;
   fWeightMatrix0to1[10][13] = 0.314300986862796;
   fWeightMatrix0to1[11][13] = -0.884099811371764;
   fWeightMatrix0to1[12][13] = -0.0713809307293598;
   fWeightMatrix0to1[13][13] = 1.66500873092508;
   fWeightMatrix0to1[14][13] = 1.19616359420908;
   fWeightMatrix0to1[0][14] = 0.519368361460331;
   fWeightMatrix0to1[1][14] = -0.71711335564707;
   fWeightMatrix0to1[2][14] = -2.26767663364477;
   fWeightMatrix0to1[3][14] = -1.25869031971472;
   fWeightMatrix0to1[4][14] = 1.91002256263251;
   fWeightMatrix0to1[5][14] = 1.3810024171625;
   fWeightMatrix0to1[6][14] = -0.452292138196886;
   fWeightMatrix0to1[7][14] = -0.826223323019953;
   fWeightMatrix0to1[8][14] = 1.97831547310287;
   fWeightMatrix0to1[9][14] = -2.53930879322153;
   fWeightMatrix0to1[10][14] = 0.102601202099662;
   fWeightMatrix0to1[11][14] = 0.200379173360495;
   fWeightMatrix0to1[12][14] = -1.43602681277638;
   fWeightMatrix0to1[13][14] = 1.52504128018778;
   fWeightMatrix0to1[14][14] = 1.47313272707087;
   // weight matrix from layer 1 to 2
   fWeightMatrix1to2[0][0] = -1.49263697019861;
   fWeightMatrix1to2[1][0] = 0.304240996552837;
   fWeightMatrix1to2[2][0] = -0.0484879006488992;
   fWeightMatrix1to2[3][0] = -1.72463288410999;
   fWeightMatrix1to2[4][0] = -1.16829637618464;
   fWeightMatrix1to2[5][0] = 1.50611027171337;
   fWeightMatrix1to2[6][0] = -0.106116289744512;
   fWeightMatrix1to2[7][0] = 1.31858585313136;
   fWeightMatrix1to2[8][0] = -0.704213309969361;
   fWeightMatrix1to2[9][0] = 1.1925166982509;
   fWeightMatrix1to2[10][0] = -1.14350396349204;
   fWeightMatrix1to2[11][0] = 0.725616983785173;
   fWeightMatrix1to2[12][0] = -0.0358773187005444;
   fWeightMatrix1to2[13][0] = -1.52598698778868;
   fWeightMatrix1to2[0][1] = -1.09965464772421;
   fWeightMatrix1to2[1][1] = -1.64416270090069;
   fWeightMatrix1to2[2][1] = -0.470425469134892;
   fWeightMatrix1to2[3][1] = -1.89585358244051;
   fWeightMatrix1to2[4][1] = -1.50261554484104;
   fWeightMatrix1to2[5][1] = -2.05309856172844;
   fWeightMatrix1to2[6][1] = 0.104755048743345;
   fWeightMatrix1to2[7][1] = -1.31618596484898;
   fWeightMatrix1to2[8][1] = -1.42694869950074;
   fWeightMatrix1to2[9][1] = 1.32952777364751;
   fWeightMatrix1to2[10][1] = -1.01023484016557;
   fWeightMatrix1to2[11][1] = 0.25631311351999;
   fWeightMatrix1to2[12][1] = -0.942142156304377;
   fWeightMatrix1to2[13][1] = 0.396586146493107;
   fWeightMatrix1to2[0][2] = 2.06342265913754;
   fWeightMatrix1to2[1][2] = 1.67126705938907;
   fWeightMatrix1to2[2][2] = -0.969024979929953;
   fWeightMatrix1to2[3][2] = -1.51558527861543;
   fWeightMatrix1to2[4][2] = -0.950037852707464;
   fWeightMatrix1to2[5][2] = -1.21648871945624;
   fWeightMatrix1to2[6][2] = -1.50459793240179;
   fWeightMatrix1to2[7][2] = -0.120178802512915;
   fWeightMatrix1to2[8][2] = 0.150389437021702;
   fWeightMatrix1to2[9][2] = 2.29572253964734;
   fWeightMatrix1to2[10][2] = -0.95238946278103;
   fWeightMatrix1to2[11][2] = 0.346576324746218;
   fWeightMatrix1to2[12][2] = -0.466556451090226;
   fWeightMatrix1to2[13][2] = -1.86956287423748;
   fWeightMatrix1to2[0][3] = 1.55519040244975;
   fWeightMatrix1to2[1][3] = 1.67674985195268;
   fWeightMatrix1to2[2][3] = -0.938457615468163;
   fWeightMatrix1to2[3][3] = -1.04579994482603;
   fWeightMatrix1to2[4][3] = 0.911446287400777;
   fWeightMatrix1to2[5][3] = 0.469639165204231;
   fWeightMatrix1to2[6][3] = 0.531285406263682;
   fWeightMatrix1to2[7][3] = -0.686593434262344;
   fWeightMatrix1to2[8][3] = -1.03534617932372;
   fWeightMatrix1to2[9][3] = 1.91484138735741;
   fWeightMatrix1to2[10][3] = 0.443106681119299;
   fWeightMatrix1to2[11][3] = 1.05390910079199;
   fWeightMatrix1to2[12][3] = -0.21827984694049;
   fWeightMatrix1to2[13][3] = 0.102038060549807;
   fWeightMatrix1to2[0][4] = -0.478017451520568;
   fWeightMatrix1to2[1][4] = -1.38693938202361;
   fWeightMatrix1to2[2][4] = -0.483671245600877;
   fWeightMatrix1to2[3][4] = -1.66675378037187;
   fWeightMatrix1to2[4][4] = -1.34457030975562;
   fWeightMatrix1to2[5][4] = -1.53075182317187;
   fWeightMatrix1to2[6][4] = 1.59117476726411;
   fWeightMatrix1to2[7][4] = -1.68453999361764;
   fWeightMatrix1to2[8][4] = 1.68850594004485;
   fWeightMatrix1to2[9][4] = -1.16241429541549;
   fWeightMatrix1to2[10][4] = 0.851212967754439;
   fWeightMatrix1to2[11][4] = -1.04221312298743;
   fWeightMatrix1to2[12][4] = 0.400596648356535;
   fWeightMatrix1to2[13][4] = 0.713943100015394;
   fWeightMatrix1to2[0][5] = -1.76337138487997;
   fWeightMatrix1to2[1][5] = -0.0488419536808677;
   fWeightMatrix1to2[2][5] = 0.704114345323141;
   fWeightMatrix1to2[3][5] = -1.93128720273109;
   fWeightMatrix1to2[4][5] = -1.57069526200162;
   fWeightMatrix1to2[5][5] = -1.57290328003001;
   fWeightMatrix1to2[6][5] = -0.857732425980798;
   fWeightMatrix1to2[7][5] = 1.94657131508037;
   fWeightMatrix1to2[8][5] = -0.533171816867311;
   fWeightMatrix1to2[9][5] = -0.0564371731882756;
   fWeightMatrix1to2[10][5] = -0.830675791532011;
   fWeightMatrix1to2[11][5] = -1.27249170740213;
   fWeightMatrix1to2[12][5] = -1.82072527189732;
   fWeightMatrix1to2[13][5] = -1.12290066660349;
   fWeightMatrix1to2[0][6] = -0.934808113105366;
   fWeightMatrix1to2[1][6] = 0.68057859371905;
   fWeightMatrix1to2[2][6] = -1.27465060871585;
   fWeightMatrix1to2[3][6] = -1.18907789670367;
   fWeightMatrix1to2[4][6] = 1.7401242026906;
   fWeightMatrix1to2[5][6] = -0.107413269832624;
   fWeightMatrix1to2[6][6] = -0.351136574483101;
   fWeightMatrix1to2[7][6] = 1.4240770418511;
   fWeightMatrix1to2[8][6] = -2.86089715544414;
   fWeightMatrix1to2[9][6] = 1.85793418422328;
   fWeightMatrix1to2[10][6] = 0.309404023909466;
   fWeightMatrix1to2[11][6] = -1.14980518792224;
   fWeightMatrix1to2[12][6] = -0.919295438134238;
   fWeightMatrix1to2[13][6] = -0.119026954692178;
   fWeightMatrix1to2[0][7] = -1.03120396260099;
   fWeightMatrix1to2[1][7] = 0.670973330591882;
   fWeightMatrix1to2[2][7] = 1.83864319500666;
   fWeightMatrix1to2[3][7] = 1.32051030185086;
   fWeightMatrix1to2[4][7] = 1.91940032658909;
   fWeightMatrix1to2[5][7] = -1.42180440977448;
   fWeightMatrix1to2[6][7] = 1.1425885276927;
   fWeightMatrix1to2[7][7] = -2.11994271377333;
   fWeightMatrix1to2[8][7] = 0.51071886286217;
   fWeightMatrix1to2[9][7] = -1.27748203688562;
   fWeightMatrix1to2[10][7] = -1.60920006757029;
   fWeightMatrix1to2[11][7] = 0.0484880410730552;
   fWeightMatrix1to2[12][7] = 1.36437253498906;
   fWeightMatrix1to2[13][7] = 0.525551919016139;
   fWeightMatrix1to2[0][8] = 1.07105588928546;
   fWeightMatrix1to2[1][8] = -0.141532567247132;
   fWeightMatrix1to2[2][8] = -0.0770763590254889;
   fWeightMatrix1to2[3][8] = -0.664025624983432;
   fWeightMatrix1to2[4][8] = 0.104027929479722;
   fWeightMatrix1to2[5][8] = 1.65893057548937;
   fWeightMatrix1to2[6][8] = -1.50325879342823;
   fWeightMatrix1to2[7][8] = 0.0877964127846429;
   fWeightMatrix1to2[8][8] = -1.47658771642203;
   fWeightMatrix1to2[9][8] = -0.194724178869065;
   fWeightMatrix1to2[10][8] = -0.545168034377769;
   fWeightMatrix1to2[11][8] = -0.0502269425435282;
   fWeightMatrix1to2[12][8] = -1.30810834185161;
   fWeightMatrix1to2[13][8] = 0.925022577413885;
   fWeightMatrix1to2[0][9] = 1.76562644233603;
   fWeightMatrix1to2[1][9] = 1.03629479910954;
   fWeightMatrix1to2[2][9] = -0.240817975296111;
   fWeightMatrix1to2[3][9] = -0.9482395535305;
   fWeightMatrix1to2[4][9] = -1.11482662534664;
   fWeightMatrix1to2[5][9] = -1.79188127038605;
   fWeightMatrix1to2[6][9] = 1.1620357193539;
   fWeightMatrix1to2[7][9] = -0.865638608636691;
   fWeightMatrix1to2[8][9] = -1.32526218783201;
   fWeightMatrix1to2[9][9] = 0.98757308542235;
   fWeightMatrix1to2[10][9] = -1.83685797062876;
   fWeightMatrix1to2[11][9] = -1.05437531215964;
   fWeightMatrix1to2[12][9] = -1.44754043894793;
   fWeightMatrix1to2[13][9] = 1.07081565057247;
   fWeightMatrix1to2[0][10] = -1.55250498579529;
   fWeightMatrix1to2[1][10] = -1.57459674555814;
   fWeightMatrix1to2[2][10] = -0.583450430868568;
   fWeightMatrix1to2[3][10] = -1.03691693532018;
   fWeightMatrix1to2[4][10] = -1.4767635290561;
   fWeightMatrix1to2[5][10] = 1.41254574818251;
   fWeightMatrix1to2[6][10] = -1.44935825786796;
   fWeightMatrix1to2[7][10] = -1.04745155357721;
   fWeightMatrix1to2[8][10] = 2.4030968287721;
   fWeightMatrix1to2[9][10] = 0.140070388251764;
   fWeightMatrix1to2[10][10] = 0.811871739762591;
   fWeightMatrix1to2[11][10] = 0.484778113513426;
   fWeightMatrix1to2[12][10] = 1.44856026538131;
   fWeightMatrix1to2[13][10] = 1.82425522316861;
   fWeightMatrix1to2[0][11] = 0.446618170540826;
   fWeightMatrix1to2[1][11] = -0.93448417695973;
   fWeightMatrix1to2[2][11] = -0.712253997725815;
   fWeightMatrix1to2[3][11] = -1.82162477046012;
   fWeightMatrix1to2[4][11] = 0.928617492188598;
   fWeightMatrix1to2[5][11] = 0.837116345519404;
   fWeightMatrix1to2[6][11] = 0.174005997199709;
   fWeightMatrix1to2[7][11] = 1.12228171828139;
   fWeightMatrix1to2[8][11] = 1.44834073155735;
   fWeightMatrix1to2[9][11] = 1.23886261270257;
   fWeightMatrix1to2[10][11] = -1.0694282494992;
   fWeightMatrix1to2[11][11] = 1.78029931608602;
   fWeightMatrix1to2[12][11] = 0.899631798793704;
   fWeightMatrix1to2[13][11] = -1.72821329779712;
   fWeightMatrix1to2[0][12] = -0.210227881472594;
   fWeightMatrix1to2[1][12] = -0.77311794676865;
   fWeightMatrix1to2[2][12] = 0.82832374306596;
   fWeightMatrix1to2[3][12] = 0.448864733655952;
   fWeightMatrix1to2[4][12] = 1.11916565398581;
   fWeightMatrix1to2[5][12] = 1.69452564697029;
   fWeightMatrix1to2[6][12] = -0.317965322100628;
   fWeightMatrix1to2[7][12] = 1.41424200144611;
   fWeightMatrix1to2[8][12] = 1.578952755006;
   fWeightMatrix1to2[9][12] = 0.468116713951042;
   fWeightMatrix1to2[10][12] = -1.37250181037011;
   fWeightMatrix1to2[11][12] = 1.78260522868256;
   fWeightMatrix1to2[12][12] = -1.80793852195615;
   fWeightMatrix1to2[13][12] = 0.567848029542886;
   fWeightMatrix1to2[0][13] = 1.49988667491544;
   fWeightMatrix1to2[1][13] = -0.661965518989448;
   fWeightMatrix1to2[2][13] = -0.729458964811719;
   fWeightMatrix1to2[3][13] = -0.0690342399647182;
   fWeightMatrix1to2[4][13] = -1.51762896113138;
   fWeightMatrix1to2[5][13] = 0.556750365255322;
   fWeightMatrix1to2[6][13] = -2.02940837460407;
   fWeightMatrix1to2[7][13] = 0.49870049117852;
   fWeightMatrix1to2[8][13] = -0.165680301730977;
   fWeightMatrix1to2[9][13] = 1.2610992465751;
   fWeightMatrix1to2[10][13] = 1.39686483860514;
   fWeightMatrix1to2[11][13] = 1.57223476043062;
   fWeightMatrix1to2[12][13] = -0.654555310891126;
   fWeightMatrix1to2[13][13] = -0.496647990338319;
   fWeightMatrix1to2[0][14] = 0.75450240742174;
   fWeightMatrix1to2[1][14] = 2.15258594145493;
   fWeightMatrix1to2[2][14] = -1.93788152976349;
   fWeightMatrix1to2[3][14] = -1.30631247949595;
   fWeightMatrix1to2[4][14] = -0.455737705068719;
   fWeightMatrix1to2[5][14] = -1.97850586178169;
   fWeightMatrix1to2[6][14] = -1.57618668582643;
   fWeightMatrix1to2[7][14] = -1.79238945452253;
   fWeightMatrix1to2[8][14] = 1.19320645358672;
   fWeightMatrix1to2[9][14] = 0.48114177671394;
   fWeightMatrix1to2[10][14] = -2.1989236983237;
   fWeightMatrix1to2[11][14] = -1.88489497784488;
   fWeightMatrix1to2[12][14] = -0.0447035624267453;
   fWeightMatrix1to2[13][14] = 1.81366748356912;
   fWeightMatrix1to2[0][15] = 1.62944346710127;
   fWeightMatrix1to2[1][15] = 1.00520657499368;
   fWeightMatrix1to2[2][15] = -0.576424157914056;
   fWeightMatrix1to2[3][15] = -1.92659264154039;
   fWeightMatrix1to2[4][15] = -0.231743186488939;
   fWeightMatrix1to2[5][15] = -0.979493674239555;
   fWeightMatrix1to2[6][15] = -1.71562324834449;
   fWeightMatrix1to2[7][15] = -0.207130210226792;
   fWeightMatrix1to2[8][15] = 0.196127462043881;
   fWeightMatrix1to2[9][15] = -1.97696004343066;
   fWeightMatrix1to2[10][15] = 2.20225229454103;
   fWeightMatrix1to2[11][15] = 1.13564042229765;
   fWeightMatrix1to2[12][15] = 0.0146117749700417;
   fWeightMatrix1to2[13][15] = -0.675310509041461;
   // weight matrix from layer 2 to 3
   fWeightMatrix2to3[0][0] = -0.0833724618113305;
   fWeightMatrix2to3[0][1] = 0.181749179407517;
   fWeightMatrix2to3[0][2] = 0.00165295890321308;
   fWeightMatrix2to3[0][3] = -0.00373497613132351;
   fWeightMatrix2to3[0][4] = 1.0175149174238;
   fWeightMatrix2to3[0][5] = 0.93908872601785;
   fWeightMatrix2to3[0][6] = 0.0477000031682684;
   fWeightMatrix2to3[0][7] = 0.0134810287317648;
   fWeightMatrix2to3[0][8] = -1.11394362696088;
   fWeightMatrix2to3[0][9] = 0.862454288791132;
   fWeightMatrix2to3[0][10] = 1.60583648765535;
   fWeightMatrix2to3[0][11] = 0.107914492760924;
   fWeightMatrix2to3[0][12] = 0.00865763621187797;
   fWeightMatrix2to3[0][13] = 0.0614326495040386;
   fWeightMatrix2to3[0][14] = -0.474188445326112;
}

inline double ReadMLP20_EC::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   if (inputValues.size() != (unsigned int)fLayerSize[0]-1) {
      std::cout << "Input vector needs to be of size " << fLayerSize[0]-1 << std::endl;
      return 0;
   }

   for (int l=0; l<fLayers; l++)
      for (int i=0; i<fLayerSize[l]; i++) fWeights[l][i]=0;

   for (int l=0; l<fLayers-1; l++)
      fWeights[l][fLayerSize[l]-1]=1;

   for (int i=0; i<fLayerSize[0]-1; i++)
      fWeights[0][i]=inputValues[i];

   // layer 0 to 1
   for (int o=0; o<fLayerSize[1]-1; o++) {
      for (int i=0; i<fLayerSize[0]; i++) {
         double inputVal = fWeightMatrix0to1[o][i] * fWeights[0][i];
         fWeights[1][o] += inputVal;
      }
      fWeights[1][o] = ActivationFnc(fWeights[1][o]);
   }
   // layer 1 to 2
   for (int o=0; o<fLayerSize[2]-1; o++) {
      for (int i=0; i<fLayerSize[1]; i++) {
         double inputVal = fWeightMatrix1to2[o][i] * fWeights[1][i];
         fWeights[2][o] += inputVal;
      }
      fWeights[2][o] = ActivationFnc(fWeights[2][o]);
   }
   // layer 2 to 3
   for (int o=0; o<fLayerSize[3]; o++) {
      for (int i=0; i<fLayerSize[2]; i++) {
         double inputVal = fWeightMatrix2to3[o][i] * fWeights[2][i];
         fWeights[3][o] += inputVal;
      }
   }

   return fWeights[3][0];
}

double ReadMLP20_EC::ActivationFnc(double x) const
{
   // hyperbolic tan
   return tanh(x);
}
 
   
// Clean up
inline void ReadMLP20_EC::Clear() 
{
   // nothing to clear
}
inline double ReadMLP20_EC::GetMvaValue( const std::vector<double>& inputValues ) const
{
   // classifier response value
   double retval = 0;

   // classifier response, sanity check first
   if (!fStatusIsClean) {
      std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
      retval = 0;
   }
   else {
      if (IsNormalised()) {
         // normalise variables
         std::vector<double> iV;
         int ivar = 0;
         for (std::vector<double>::const_iterator varIt = inputValues.begin();
              varIt != inputValues.end(); varIt++, ivar++) {
            iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
         }
         retval = GetMvaValue__( iV );
      }
      else {
         retval = GetMvaValue__( inputValues );
      }
   }

   return retval;
}

// Class: ReadMLP0_5_EC_10x10
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : MLP::MLP
TMVA Release   : 3.9.6         [198918]
ROOT Release   : 5.16/00       [331776]
Creator        : reinhard
Date           : Tue Sep 22 14:09:46 2009
Host           : Linux polui02.in2p3.fr 2.6.9-67.0.4.ELsmp #1 SMP Thu Jan 31 16:30:09 CST 2008 i686 i686 i386 GNU/Linux
Dir            : /grid_mnt/data2__polgrid/llr/ilc/reinhard/ILCSoft/TMVA/macros
Training events: 4959


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
Normalise: "True" [Normalise input variables]
V: "False" [Verbose mode]
H: "True" [Print classifier-specific help message]
NCycles: "500" [Number of training cycles]
HiddenLayers: "N+1,N" [Specification of hidden layer architecture (N stands for number of variables; any integers may also be used)]
NeuronType: "tanh" [Neuron activation function type]
TestRate: "5" [Test for overtraining performed at each #th epochs]
# Default:
D: "False" [Use-decorrelated-variables flag (depreciated)]
VarTransform: "None" [Variable transformation method]
VarTransformType: "Signal" [Use signal or background events to derive for variable transformation (the transformation is applied on both types of, course)]
NbinsMVAPdf: "60" [Number of bins used for the PDFs of classifier outputs]
NsmoothMVAPdf: "2" [Number of smoothing iterations for classifier PDFs]
VerboseLevel: "Default" [Verbosity level]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
TxtWeightFilesOnly: "True" [If True: write all training results (weights) as text files (False: some are written in ROOT format)]
NeuronInputType: "sum" [Neuron input function type]
TrainingMethod: "BP" [Train with Back-Propagation (BP - default) or Genetic Algorithm (GA - slower and worse)]
LearningRate: "0.02" [ANN learning rate parameter]
DecayRate: "0.01" [Decay rate for learning parameter]
BPMode: "sequential" [Back-propagation learning mode: sequential or batch]
BatchSize: "-1" [Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 13
ClusterParameters.start       ClusterParameters.start           'F'    [0,14.6304521561]
ClusterParameters.end         ClusterParameters.end             'F'    [1.92527413368,29.1208152771]
ClusterParameters.depth       ClusterParameters.depth           'F'    [0,20.7237930298]
ClusterParameters.E1C/ClusterParameters.Etot_g   ClusterParameters.E1C_D_ClusterParameters.Etot_g     'F'    [0,1]
ClusterParameters.E4C/ClusterParameters.Etot_g   ClusterParameters.E4C_D_ClusterParameters.Etot_g     'F'    [0.0660886988044,1]
ClusterParameters.E9C/ClusterParameters.Etot_g   ClusterParameters.E9C_D_ClusterParameters.Etot_g     'F'    [0.438558012247,1]
ClusterParameters.dirErr      ClusterParameters.dirErr          'F'    [0.00513035198674,0.999999403954]
ClusterParameters.seedDirErr  ClusterParameters.seedDirErr      'F'    [0,0.999997735023]
ClusterParameters.Width       ClusterParameters.Width           'F'    [0.418875783682,24.1973285675]
ClusterParameters.Eccentricity ClusterParameters.Eccentricity     'F'    [0.0484772063792,0.914461433887]
ClusterParameters.nHits       ClusterParameters.nHits           'F'    [5,45]
ClusterParameters.Volume      ClusterParameters.Volume          'F'    [62.3514022827,426465.4375]
ClusterParameters.depth-ClusterParameters.start   ClusterParameters.depth_M_ClusterParameters.start     'F'    [-1.06614875793,18.3781757355]


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;
};

#endif

class ReadMLP0_5_EC_10x10 : public IClassifierReader {

 public:

   // constructor
   ReadMLP0_5_EC_10x10( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadMLP0_5_EC_10x10" ),
        fStatusIsClean( true ),
        fNvars( 13 ),
        fIsNormalised( true )
   {      
      // the training input variables
      const char* inputVars[] = { "ClusterParameters.start", "ClusterParameters.end", "ClusterParameters.depth", "ClusterParameters.E1C/ClusterParameters.Etot_g", "ClusterParameters.E4C/ClusterParameters.Etot_g", "ClusterParameters.E9C/ClusterParameters.Etot_g", "ClusterParameters.dirErr", "ClusterParameters.seedDirErr", "ClusterParameters.Width", "ClusterParameters.Eccentricity", "ClusterParameters.nHits", "ClusterParameters.Volume", "ClusterParameters.depth-ClusterParameters.start" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 14.6304521560669;
      fVmin[1] = 1.92527413368225;
      fVmax[1] = 29.1208152770996;
      fVmin[2] = 0;
      fVmax[2] = 20.7237930297852;
      fVmin[3] = 0;
      fVmax[3] = 1;
      fVmin[4] = 0.0660886988043785;
      fVmax[4] = 1;
      fVmin[5] = 0.438558012247086;
      fVmax[5] = 1;
      fVmin[6] = 0.00513035198673606;
      fVmax[6] = 0.999999403953552;
      fVmin[7] = 0;
      fVmax[7] = 0.999997735023499;
      fVmin[8] = 0.41887578368187;
      fVmax[8] = 24.1973285675049;
      fVmin[9] = 0.0484772063791752;
      fVmax[9] = 0.914461433887482;
      fVmin[10] = 5;
      fVmax[10] = 45;
      fVmin[11] = 62.3514022827148;
      fVmax[11] = 426465.4375;
      fVmin[12] = -1.06614875793457;
      fVmax[12] = 18.3781757354736;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';
      fType[10] = 'F';
      fType[11] = 'F';
      fType[12] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadMLP0_5_EC_10x10() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;
   bool fStatusIsClean;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[13];
   double fVmax[13];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[13];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)

   double ActivationFnc(double x) const;

   int fLayers;
   int fLayerSize[4];
   double fWeightMatrix0to1[15][14];   // weight matrix from layer 0 to 1
   double fWeightMatrix1to2[14][15];   // weight matrix from layer 1 to 2
   double fWeightMatrix2to3[1][14];   // weight matrix from layer 2 to 3

   double * fWeights[4];
};

inline void ReadMLP0_5_EC_10x10::Initialize()
{
   // build network structure
   fLayers = 4;
   fLayerSize[0] = 14; fWeights[0] = new double[14]; 
   fLayerSize[1] = 15; fWeights[1] = new double[15]; 
   fLayerSize[2] = 14; fWeights[2] = new double[14]; 
   fLayerSize[3] = 1; fWeights[3] = new double[1]; 
   // weight matrix from layer 0 to 1
   fWeightMatrix0to1[0][0] = 0.497063571259462;
   fWeightMatrix0to1[1][0] = 1.99027653186743;
   fWeightMatrix0to1[2][0] = -0.131880192220029;
   fWeightMatrix0to1[3][0] = 1.81270862983944;
   fWeightMatrix0to1[4][0] = -2.35769921978948;
   fWeightMatrix0to1[5][0] = -2.28839499423434;
   fWeightMatrix0to1[6][0] = -0.628712171864294;
   fWeightMatrix0to1[7][0] = 2.29640766114234;
   fWeightMatrix0to1[8][0] = -1.7396438091516;
   fWeightMatrix0to1[9][0] = 0.325163721457501;
   fWeightMatrix0to1[10][0] = -1.73821446171681;
   fWeightMatrix0to1[11][0] = -0.0245155774203266;
   fWeightMatrix0to1[12][0] = -2.3271845548773;
   fWeightMatrix0to1[13][0] = -1.18403222675981;
   fWeightMatrix0to1[0][1] = -0.0527911560291613;
   fWeightMatrix0to1[1][1] = 0.669234550923711;
   fWeightMatrix0to1[2][1] = -1.34405933254943;
   fWeightMatrix0to1[3][1] = 1.50935711226057;
   fWeightMatrix0to1[4][1] = 0.660306132079746;
   fWeightMatrix0to1[5][1] = 1.16822184817515;
   fWeightMatrix0to1[6][1] = -0.227698842247927;
   fWeightMatrix0to1[7][1] = -0.378428187847838;
   fWeightMatrix0to1[8][1] = 0.621575205178313;
   fWeightMatrix0to1[9][1] = 0.789993603865449;
   fWeightMatrix0to1[10][1] = -0.851191489674474;
   fWeightMatrix0to1[11][1] = 1.04403290347854;
   fWeightMatrix0to1[12][1] = 0.213700298750309;
   fWeightMatrix0to1[13][1] = -0.178336156261892;
   fWeightMatrix0to1[0][2] = -1.49865829616318;
   fWeightMatrix0to1[1][2] = 0.0701509825018181;
   fWeightMatrix0to1[2][2] = 0.619288748142417;
   fWeightMatrix0to1[3][2] = 1.45978667623663;
   fWeightMatrix0to1[4][2] = 0.603172558370544;
   fWeightMatrix0to1[5][2] = -0.170115945108904;
   fWeightMatrix0to1[6][2] = 0.237187929587599;
   fWeightMatrix0to1[7][2] = -0.111549372645523;
   fWeightMatrix0to1[8][2] = -1.58888445786939;
   fWeightMatrix0to1[9][2] = 1.84293803394815;
   fWeightMatrix0to1[10][2] = -1.03919486626783;
   fWeightMatrix0to1[11][2] = 1.29208069647228;
   fWeightMatrix0to1[12][2] = 1.85562012826795;
   fWeightMatrix0to1[13][2] = 0.583950422167348;
   fWeightMatrix0to1[0][3] = 3.03455591928215;
   fWeightMatrix0to1[1][3] = 1.45592642559201;
   fWeightMatrix0to1[2][3] = -0.554701345099961;
   fWeightMatrix0to1[3][3] = -1.26133761141756;
   fWeightMatrix0to1[4][3] = -0.199064616301223;
   fWeightMatrix0to1[5][3] = 1.23290144195076;
   fWeightMatrix0to1[6][3] = 1.67526742672886;
   fWeightMatrix0to1[7][3] = 1.41434586045032;
   fWeightMatrix0to1[8][3] = 1.10896495234986;
   fWeightMatrix0to1[9][3] = 0.0317306923457913;
   fWeightMatrix0to1[10][3] = -1.94144661929866;
   fWeightMatrix0to1[11][3] = 0.861020084901585;
   fWeightMatrix0to1[12][3] = -0.589426654703574;
   fWeightMatrix0to1[13][3] = -1.24775985117604;
   fWeightMatrix0to1[0][4] = -1.75806603905052;
   fWeightMatrix0to1[1][4] = -1.54509809432164;
   fWeightMatrix0to1[2][4] = -0.106476883704834;
   fWeightMatrix0to1[3][4] = 0.368126861629991;
   fWeightMatrix0to1[4][4] = -2.33692876200137;
   fWeightMatrix0to1[5][4] = 0.143120111179546;
   fWeightMatrix0to1[6][4] = -0.199876657593938;
   fWeightMatrix0to1[7][4] = 0.485579999955535;
   fWeightMatrix0to1[8][4] = 1.76751657205113;
   fWeightMatrix0to1[9][4] = 0.543716034676326;
   fWeightMatrix0to1[10][4] = -0.0863999486528363;
   fWeightMatrix0to1[11][4] = -0.782779137818753;
   fWeightMatrix0to1[12][4] = -0.863249589633687;
   fWeightMatrix0to1[13][4] = 0.0920823561592513;
   fWeightMatrix0to1[0][5] = -1.36137737904677;
   fWeightMatrix0to1[1][5] = -1.19280733213018;
   fWeightMatrix0to1[2][5] = -0.0432798335308235;
   fWeightMatrix0to1[3][5] = 0.57715049606109;
   fWeightMatrix0to1[4][5] = 1.98845739608605;
   fWeightMatrix0to1[5][5] = -0.156640845887667;
   fWeightMatrix0to1[6][5] = -1.89446358496411;
   fWeightMatrix0to1[7][5] = -2.17270450327545;
   fWeightMatrix0to1[8][5] = 1.34548333940883;
   fWeightMatrix0to1[9][5] = -0.857264167064283;
   fWeightMatrix0to1[10][5] = 1.79316645787856;
   fWeightMatrix0to1[11][5] = 0.343344526162588;
   fWeightMatrix0to1[12][5] = 0.262141805492775;
   fWeightMatrix0to1[13][5] = -0.736150120274629;
   fWeightMatrix0to1[0][6] = -0.835089948346106;
   fWeightMatrix0to1[1][6] = -0.348460454744206;
   fWeightMatrix0to1[2][6] = -1.77310994498491;
   fWeightMatrix0to1[3][6] = -1.54903587787247;
   fWeightMatrix0to1[4][6] = -2.84562893915909;
   fWeightMatrix0to1[5][6] = -1.83209687796476;
   fWeightMatrix0to1[6][6] = -0.192229631589762;
   fWeightMatrix0to1[7][6] = -0.570376608165016;
   fWeightMatrix0to1[8][6] = 1.90769703474649;
   fWeightMatrix0to1[9][6] = -4.25025885627814;
   fWeightMatrix0to1[10][6] = -0.683178891316403;
   fWeightMatrix0to1[11][6] = 1.62229620913304;
   fWeightMatrix0to1[12][6] = -3.07303413948231;
   fWeightMatrix0to1[13][6] = -0.380895187122636;
   fWeightMatrix0to1[0][7] = -0.781356698776773;
   fWeightMatrix0to1[1][7] = -0.0674480433385184;
   fWeightMatrix0to1[2][7] = -3.91822899879243;
   fWeightMatrix0to1[3][7] = -1.14221165458588;
   fWeightMatrix0to1[4][7] = 1.28464176238942;
   fWeightMatrix0to1[5][7] = 0.159607866320248;
   fWeightMatrix0to1[6][7] = -0.994343858707895;
   fWeightMatrix0to1[7][7] = 1.01315923443814;
   fWeightMatrix0to1[8][7] = -0.478931060559403;
   fWeightMatrix0to1[9][7] = 0.381882466540921;
   fWeightMatrix0to1[10][7] = -0.040357770575339;
   fWeightMatrix0to1[11][7] = -0.319578622751878;
   fWeightMatrix0to1[12][7] = -0.818660498079893;
   fWeightMatrix0to1[13][7] = 0.908014223850982;
   fWeightMatrix0to1[0][8] = 0.371830474242328;
   fWeightMatrix0to1[1][8] = 0.456024327224757;
   fWeightMatrix0to1[2][8] = -4.60086889362208;
   fWeightMatrix0to1[3][8] = 1.8937088192258;
   fWeightMatrix0to1[4][8] = -0.0180809801595971;
   fWeightMatrix0to1[5][8] = -1.99656813847263;
   fWeightMatrix0to1[6][8] = 0.692504723815355;
   fWeightMatrix0to1[7][8] = -0.552322284391769;
   fWeightMatrix0to1[8][8] = -1.67215113377404;
   fWeightMatrix0to1[9][8] = 2.21857979144657;
   fWeightMatrix0to1[10][8] = -0.295829735210587;
   fWeightMatrix0to1[11][8] = 2.27827803056989;
   fWeightMatrix0to1[12][8] = 1.6481665840624;
   fWeightMatrix0to1[13][8] = 1.95591381355828;
   fWeightMatrix0to1[0][9] = -0.160289736671929;
   fWeightMatrix0to1[1][9] = 0.276983958507777;
   fWeightMatrix0to1[2][9] = -1.8092862665968;
   fWeightMatrix0to1[3][9] = 1.20996405356265;
   fWeightMatrix0to1[4][9] = 0.522401486170381;
   fWeightMatrix0to1[5][9] = -1.22454544482963;
   fWeightMatrix0to1[6][9] = 0.596187028219491;
   fWeightMatrix0to1[7][9] = -1.08860111806385;
   fWeightMatrix0to1[8][9] = -0.018370931350419;
   fWeightMatrix0to1[9][9] = -0.22452013920193;
   fWeightMatrix0to1[10][9] = 1.62457683747606;
   fWeightMatrix0to1[11][9] = -2.11799397997325;
   fWeightMatrix0to1[12][9] = -1.73063176799799;
   fWeightMatrix0to1[13][9] = 1.23430043252332;
   fWeightMatrix0to1[0][10] = 0.49933518792911;
   fWeightMatrix0to1[1][10] = 0.252057254197865;
   fWeightMatrix0to1[2][10] = 0.522868068899182;
   fWeightMatrix0to1[3][10] = -0.0424392436329551;
   fWeightMatrix0to1[4][10] = -1.23192870080148;
   fWeightMatrix0to1[5][10] = 1.64052522377786;
   fWeightMatrix0to1[6][10] = 1.19937725132124;
   fWeightMatrix0to1[7][10] = 0.0821328968475736;
   fWeightMatrix0to1[8][10] = -0.639834309790138;
   fWeightMatrix0to1[9][10] = -4.04390364176757;
   fWeightMatrix0to1[10][10] = -1.19366766534931;
   fWeightMatrix0to1[11][10] = 0.566877274391319;
   fWeightMatrix0to1[12][10] = 2.03900363585729;
   fWeightMatrix0to1[13][10] = 0.133031304119243;
   fWeightMatrix0to1[0][11] = -0.214887697059414;
   fWeightMatrix0to1[1][11] = 0.411469891269138;
   fWeightMatrix0to1[2][11] = -1.67582277934265;
   fWeightMatrix0to1[3][11] = 0.956184928844688;
   fWeightMatrix0to1[4][11] = -0.447990209962583;
   fWeightMatrix0to1[5][11] = -1.39104024752882;
   fWeightMatrix0to1[6][11] = 1.66605580695473;
   fWeightMatrix0to1[7][11] = 1.55216056697733;
   fWeightMatrix0to1[8][11] = -0.00307221140047492;
   fWeightMatrix0to1[9][11] = -0.598649041261475;
   fWeightMatrix0to1[10][11] = 0.911173188274623;
   fWeightMatrix0to1[11][11] = -0.378442352868997;
   fWeightMatrix0to1[12][11] = -0.897401955413373;
   fWeightMatrix0to1[13][11] = 1.25306888626196;
   fWeightMatrix0to1[0][12] = -1.03584761136695;
   fWeightMatrix0to1[1][12] = -0.504926220064769;
   fWeightMatrix0to1[2][12] = 2.19076224454846;
   fWeightMatrix0to1[3][12] = 1.08047142373378;
   fWeightMatrix0to1[4][12] = 0.333485797283239;
   fWeightMatrix0to1[5][12] = 1.90074541188508;
   fWeightMatrix0to1[6][12] = 1.86500526678574;
   fWeightMatrix0to1[7][12] = -1.54669085286086;
   fWeightMatrix0to1[8][12] = 0.405752913866083;
   fWeightMatrix0to1[9][12] = -1.61075787892584;
   fWeightMatrix0to1[10][12] = 0.586551371429942;
   fWeightMatrix0to1[11][12] = -1.74324267968868;
   fWeightMatrix0to1[12][12] = -0.837950450406155;
   fWeightMatrix0to1[13][12] = 1.05827727686078;
   fWeightMatrix0to1[0][13] = 1.64090507449626;
   fWeightMatrix0to1[1][13] = -1.98993330699127;
   fWeightMatrix0to1[2][13] = -0.0470906681548662;
   fWeightMatrix0to1[3][13] = -1.16863920934552;
   fWeightMatrix0to1[4][13] = 1.42935416156249;
   fWeightMatrix0to1[5][13] = 2.16316275062973;
   fWeightMatrix0to1[6][13] = -0.583961789611198;
   fWeightMatrix0to1[7][13] = -1.27111047868625;
   fWeightMatrix0to1[8][13] = -0.473908882562057;
   fWeightMatrix0to1[9][13] = 2.18927035871482;
   fWeightMatrix0to1[10][13] = 1.89195708676256;
   fWeightMatrix0to1[11][13] = 0.975221709430015;
   fWeightMatrix0to1[12][13] = 1.68005855886377;
   fWeightMatrix0to1[13][13] = -0.197087269497702;
   // weight matrix from layer 1 to 2
   fWeightMatrix1to2[0][0] = -1.94247702066516;
   fWeightMatrix1to2[1][0] = 0.541089359319514;
   fWeightMatrix1to2[2][0] = -0.142544415218608;
   fWeightMatrix1to2[3][0] = -1.33509883785037;
   fWeightMatrix1to2[4][0] = -0.971615601231095;
   fWeightMatrix1to2[5][0] = 0.604273807358841;
   fWeightMatrix1to2[6][0] = -0.0490131724880472;
   fWeightMatrix1to2[7][0] = -1.83799577371685;
   fWeightMatrix1to2[8][0] = 1.18720398955948;
   fWeightMatrix1to2[9][0] = 1.03268525111336;
   fWeightMatrix1to2[10][0] = -0.236947306609411;
   fWeightMatrix1to2[11][0] = -0.00851127805560628;
   fWeightMatrix1to2[12][0] = 1.33859834960256;
   fWeightMatrix1to2[0][1] = 0.789596542487523;
   fWeightMatrix1to2[1][1] = -0.210518886587158;
   fWeightMatrix1to2[2][1] = 0.0288552927578694;
   fWeightMatrix1to2[3][1] = -2.27937773708146;
   fWeightMatrix1to2[4][1] = -1.03882656562686;
   fWeightMatrix1to2[5][1] = 1.15642295887202;
   fWeightMatrix1to2[6][1] = 1.35727824948591;
   fWeightMatrix1to2[7][1] = 1.29615005799815;
   fWeightMatrix1to2[8][1] = 0.0780508831530799;
   fWeightMatrix1to2[9][1] = 2.6542066841995;
   fWeightMatrix1to2[10][1] = -2.05736005996177;
   fWeightMatrix1to2[11][1] = -1.17213681878718;
   fWeightMatrix1to2[12][1] = -0.445949432203501;
   fWeightMatrix1to2[0][2] = -1.23647485432039;
   fWeightMatrix1to2[1][2] = 0.522822227564034;
   fWeightMatrix1to2[2][2] = 1.38833345124053;
   fWeightMatrix1to2[3][2] = -1.08808897028637;
   fWeightMatrix1to2[4][2] = 0.386764565517107;
   fWeightMatrix1to2[5][2] = 1.87324852769902;
   fWeightMatrix1to2[6][2] = -1.55136533751083;
   fWeightMatrix1to2[7][2] = -2.01618951055498;
   fWeightMatrix1to2[8][2] = 0.633854941554581;
   fWeightMatrix1to2[9][2] = -0.0540223872820139;
   fWeightMatrix1to2[10][2] = 0.746777270365034;
   fWeightMatrix1to2[11][2] = -1.25919492210533;
   fWeightMatrix1to2[12][2] = 1.49689437485054;
   fWeightMatrix1to2[0][3] = -1.98934557445505;
   fWeightMatrix1to2[1][3] = 0.0886486518743148;
   fWeightMatrix1to2[2][3] = 0.260518530507649;
   fWeightMatrix1to2[3][3] = -1.5847319425514;
   fWeightMatrix1to2[4][3] = -1.42758330631241;
   fWeightMatrix1to2[5][3] = -1.58212224306007;
   fWeightMatrix1to2[6][3] = -0.416838510795987;
   fWeightMatrix1to2[7][3] = -1.47792247646643;
   fWeightMatrix1to2[8][3] = -1.54766196867626;
   fWeightMatrix1to2[9][3] = -1.0898249414493;
   fWeightMatrix1to2[10][3] = 0.277715540926039;
   fWeightMatrix1to2[11][3] = -0.927284680007639;
   fWeightMatrix1to2[12][3] = -1.92626434373903;
   fWeightMatrix1to2[0][4] = 1.36678639123035;
   fWeightMatrix1to2[1][4] = -0.399198954474106;
   fWeightMatrix1to2[2][4] = 0.608202012174955;
   fWeightMatrix1to2[3][4] = -0.738740027823698;
   fWeightMatrix1to2[4][4] = 0.259682620485379;
   fWeightMatrix1to2[5][4] = 2.68837538243333;
   fWeightMatrix1to2[6][4] = 1.37145047713852;
   fWeightMatrix1to2[7][4] = -2.56741035859725;
   fWeightMatrix1to2[8][4] = -1.3787087466995;
   fWeightMatrix1to2[9][4] = -0.986480876015833;
   fWeightMatrix1to2[10][4] = -0.608466277579969;
   fWeightMatrix1to2[11][4] = -1.78027341360932;
   fWeightMatrix1to2[12][4] = 0.498153512424074;
   fWeightMatrix1to2[0][5] = 0.327373331664404;
   fWeightMatrix1to2[1][5] = 1.90191347496879;
   fWeightMatrix1to2[2][5] = -0.375238078483911;
   fWeightMatrix1to2[3][5] = 0.713011618934094;
   fWeightMatrix1to2[4][5] = 0.183248826738469;
   fWeightMatrix1to2[5][5] = -1.53526400887427;
   fWeightMatrix1to2[6][5] = 1.36472929978495;
   fWeightMatrix1to2[7][5] = 2.33987335004472;
   fWeightMatrix1to2[8][5] = -0.909400196718733;
   fWeightMatrix1to2[9][5] = -1.34743128846518;
   fWeightMatrix1to2[10][5] = 0.667442244410203;
   fWeightMatrix1to2[11][5] = 1.03462225067353;
   fWeightMatrix1to2[12][5] = 0.758573935491473;
   fWeightMatrix1to2[0][6] = -0.708176106254075;
   fWeightMatrix1to2[1][6] = -1.07068065612168;
   fWeightMatrix1to2[2][6] = 1.61239772652408;
   fWeightMatrix1to2[3][6] = 0.563954311671767;
   fWeightMatrix1to2[4][6] = 0.873506031370224;
   fWeightMatrix1to2[5][6] = -0.846722482084757;
   fWeightMatrix1to2[6][6] = 0.288081957771421;
   fWeightMatrix1to2[7][6] = 0.245492696487551;
   fWeightMatrix1to2[8][6] = -1.58105945121702;
   fWeightMatrix1to2[9][6] = 0.186593117741545;
   fWeightMatrix1to2[10][6] = -1.94446726705235;
   fWeightMatrix1to2[11][6] = -1.24767577835724;
   fWeightMatrix1to2[12][6] = -1.85058826027243;
   fWeightMatrix1to2[0][7] = 1.47197116635868;
   fWeightMatrix1to2[1][7] = -2.0859875266967;
   fWeightMatrix1to2[2][7] = 2.03153001534242;
   fWeightMatrix1to2[3][7] = -1.83812950420368;
   fWeightMatrix1to2[4][7] = 0.795884927701682;
   fWeightMatrix1to2[5][7] = -1.55415705790942;
   fWeightMatrix1to2[6][7] = 0.371169700509357;
   fWeightMatrix1to2[7][7] = 0.921823815030749;
   fWeightMatrix1to2[8][7] = -1.9467293962587;
   fWeightMatrix1to2[9][7] = 0.493635947552717;
   fWeightMatrix1to2[10][7] = 0.262185037027437;
   fWeightMatrix1to2[11][7] = -1.83499139003343;
   fWeightMatrix1to2[12][7] = -1.49578823827331;
   fWeightMatrix1to2[0][8] = -1.47548051373535;
   fWeightMatrix1to2[1][8] = -0.347619697552372;
   fWeightMatrix1to2[2][8] = 1.70788444884883;
   fWeightMatrix1to2[3][8] = -0.655843321541655;
   fWeightMatrix1to2[4][8] = 0.403900064505438;
   fWeightMatrix1to2[5][8] = -0.416388903732782;
   fWeightMatrix1to2[6][8] = -0.674998267098313;
   fWeightMatrix1to2[7][8] = -1.40396041325211;
   fWeightMatrix1to2[8][8] = -0.948394631796075;
   fWeightMatrix1to2[9][8] = -1.57359251149265;
   fWeightMatrix1to2[10][8] = 0.741815863692491;
   fWeightMatrix1to2[11][8] = -1.44129640984766;
   fWeightMatrix1to2[12][8] = -0.882536678114092;
   fWeightMatrix1to2[0][9] = 1.79722091074315;
   fWeightMatrix1to2[1][9] = 0.546378422514794;
   fWeightMatrix1to2[2][9] = -1.18797266623455;
   fWeightMatrix1to2[3][9] = 2.01050678552156;
   fWeightMatrix1to2[4][9] = -2.3164216223656;
   fWeightMatrix1to2[5][9] = 2.25408981565362;
   fWeightMatrix1to2[6][9] = 0.50853836868683;
   fWeightMatrix1to2[7][9] = -2.5418596701357;
   fWeightMatrix1to2[8][9] = 0.0334043568978635;
   fWeightMatrix1to2[9][9] = -0.246602923142847;
   fWeightMatrix1to2[10][9] = -0.825470598432171;
   fWeightMatrix1to2[11][9] = 0.446674380087966;
   fWeightMatrix1to2[12][9] = 1.65982269693652;
   fWeightMatrix1to2[0][10] = 1.50224576981052;
   fWeightMatrix1to2[1][10] = 2.06798257898227;
   fWeightMatrix1to2[2][10] = -1.36051896377605;
   fWeightMatrix1to2[3][10] = 1.32528592939547;
   fWeightMatrix1to2[4][10] = -1.85101187296837;
   fWeightMatrix1to2[5][10] = 1.16528414919328;
   fWeightMatrix1to2[6][10] = -1.72661203538846;
   fWeightMatrix1to2[7][10] = -2.41100022419963;
   fWeightMatrix1to2[8][10] = 0.045455443646673;
   fWeightMatrix1to2[9][10] = 0.668370896260501;
   fWeightMatrix1to2[10][10] = 0.778001745373077;
   fWeightMatrix1to2[11][10] = 0.904927281960705;
   fWeightMatrix1to2[12][10] = 0.595440238374143;
   fWeightMatrix1to2[0][11] = 0.0622895531346509;
   fWeightMatrix1to2[1][11] = 0.00854277753221183;
   fWeightMatrix1to2[2][11] = 0.0799636167813925;
   fWeightMatrix1to2[3][11] = 1.87124062708912;
   fWeightMatrix1to2[4][11] = -1.59851147561628;
   fWeightMatrix1to2[5][11] = -0.608587530760373;
   fWeightMatrix1to2[6][11] = -1.19193620232961;
   fWeightMatrix1to2[7][11] = -1.65133862940646;
   fWeightMatrix1to2[8][11] = -0.000270124632805448;
   fWeightMatrix1to2[9][11] = -0.404863731881448;
   fWeightMatrix1to2[10][11] = -0.889698001587553;
   fWeightMatrix1to2[11][11] = 0.973107196943227;
   fWeightMatrix1to2[12][11] = 1.92907717192696;
   fWeightMatrix1to2[0][12] = 0.694197418899855;
   fWeightMatrix1to2[1][12] = 0.0870084418290397;
   fWeightMatrix1to2[2][12] = -0.615133277473614;
   fWeightMatrix1to2[3][12] = -1.07193582839332;
   fWeightMatrix1to2[4][12] = -1.68236683154459;
   fWeightMatrix1to2[5][12] = 2.03589059665317;
   fWeightMatrix1to2[6][12] = -0.766324847594481;
   fWeightMatrix1to2[7][12] = -2.14404045657933;
   fWeightMatrix1to2[8][12] = 0.99397615631186;
   fWeightMatrix1to2[9][12] = -1.47588049803794;
   fWeightMatrix1to2[10][12] = -0.813281998006186;
   fWeightMatrix1to2[11][12] = -1.7190316476873;
   fWeightMatrix1to2[12][12] = 0.695518527769587;
   fWeightMatrix1to2[0][13] = -1.58406938633206;
   fWeightMatrix1to2[1][13] = -1.73391360746358;
   fWeightMatrix1to2[2][13] = -0.446414965212347;
   fWeightMatrix1to2[3][13] = -0.806165491575652;
   fWeightMatrix1to2[4][13] = -1.65889831137299;
   fWeightMatrix1to2[5][13] = 1.2062789024612;
   fWeightMatrix1to2[6][13] = -1.43581778536386;
   fWeightMatrix1to2[7][13] = -1.94236956242284;
   fWeightMatrix1to2[8][13] = 1.69912735741301;
   fWeightMatrix1to2[9][13] = 0.861816617041088;
   fWeightMatrix1to2[10][13] = 0.259574718621427;
   fWeightMatrix1to2[11][13] = 0.184960029203378;
   fWeightMatrix1to2[12][13] = 1.05307540817668;
   fWeightMatrix1to2[0][14] = 1.96790798932429;
   fWeightMatrix1to2[1][14] = 1.2722799915051;
   fWeightMatrix1to2[2][14] = -1.10496982097997;
   fWeightMatrix1to2[3][14] = -0.256255939269224;
   fWeightMatrix1to2[4][14] = -1.62139133325674;
   fWeightMatrix1to2[5][14] = 1.47402181871152;
   fWeightMatrix1to2[6][14] = 0.908255744002903;
   fWeightMatrix1to2[7][14] = -0.445126670698575;
   fWeightMatrix1to2[8][14] = 1.21619965645123;
   fWeightMatrix1to2[9][14] = 0.256687043986437;
   fWeightMatrix1to2[10][14] = 1.9543848929165;
   fWeightMatrix1to2[11][14] = -1.47723227767746;
   fWeightMatrix1to2[12][14] = 2.06385404499953;
   // weight matrix from layer 2 to 3
   fWeightMatrix2to3[0][0] = 0.194329939057193;
   fWeightMatrix2to3[0][1] = -1.42676590028354;
   fWeightMatrix2to3[0][2] = -1.05695467886153;
   fWeightMatrix2to3[0][3] = -0.742101654102713;
   fWeightMatrix2to3[0][4] = 0.065174936116634;
   fWeightMatrix2to3[0][5] = -0.280646215401709;
   fWeightMatrix2to3[0][6] = 0.0576908593925897;
   fWeightMatrix2to3[0][7] = 0.689507802516847;
   fWeightMatrix2to3[0][8] = 0.090186769980339;
   fWeightMatrix2to3[0][9] = 0.277928132277608;
   fWeightMatrix2to3[0][10] = 0.911208430308157;
   fWeightMatrix2to3[0][11] = 0.0092781898414538;
   fWeightMatrix2to3[0][12] = -1.190169173054;
   fWeightMatrix2to3[0][13] = 1.46963560622964;
}

inline double ReadMLP0_5_EC_10x10::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   if (inputValues.size() != (unsigned int)fLayerSize[0]-1) {
      std::cout << "Input vector needs to be of size " << fLayerSize[0]-1 << std::endl;
      return 0;
   }

   for (int l=0; l<fLayers; l++)
      for (int i=0; i<fLayerSize[l]; i++) fWeights[l][i]=0;

   for (int l=0; l<fLayers-1; l++)
      fWeights[l][fLayerSize[l]-1]=1;

   for (int i=0; i<fLayerSize[0]-1; i++)
      fWeights[0][i]=inputValues[i];

   // layer 0 to 1
   for (int o=0; o<fLayerSize[1]-1; o++) {
      for (int i=0; i<fLayerSize[0]; i++) {
         double inputVal = fWeightMatrix0to1[o][i] * fWeights[0][i];
         fWeights[1][o] += inputVal;
      }
      fWeights[1][o] = ActivationFnc(fWeights[1][o]);
   }
   // layer 1 to 2
   for (int o=0; o<fLayerSize[2]-1; o++) {
      for (int i=0; i<fLayerSize[1]; i++) {
         double inputVal = fWeightMatrix1to2[o][i] * fWeights[1][i];
         fWeights[2][o] += inputVal;
      }
      fWeights[2][o] = ActivationFnc(fWeights[2][o]);
   }
   // layer 2 to 3
   for (int o=0; o<fLayerSize[3]; o++) {
      for (int i=0; i<fLayerSize[2]; i++) {
         double inputVal = fWeightMatrix2to3[o][i] * fWeights[2][i];
         fWeights[3][o] += inputVal;
      }
   }

   return fWeights[3][0];
}

double ReadMLP0_5_EC_10x10::ActivationFnc(double x) const
{
   // hyperbolic tan
   return tanh(x);
}
 
   
// Clean up
inline void ReadMLP0_5_EC_10x10::Clear() 
{
   // nothing to clear
}
inline double ReadMLP0_5_EC_10x10::GetMvaValue( const std::vector<double>& inputValues ) const
{
   // classifier response value
   double retval = 0;

   // classifier response, sanity check first
   if (!fStatusIsClean) {
      std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
      retval = 0;
   }
   else {
      if (IsNormalised()) {
         // normalise variables
         std::vector<double> iV;
         int ivar = 0;
         for (std::vector<double>::const_iterator varIt = inputValues.begin();
              varIt != inputValues.end(); varIt++, ivar++) {
            iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
         }
         retval = GetMvaValue__( iV );
      }
      else {
         retval = GetMvaValue__( inputValues );
      }
   }

   return retval;
}

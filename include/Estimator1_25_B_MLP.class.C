// Class: ReadMLP1_25_B
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : MLP::MLP
TMVA Release   : 3.9.6         [198918]
ROOT Release   : 5.16/00       [331776]
Creator        : reinhard
Date           : Fri Aug  7 10:08:25 2009
Host           : Linux polui02.in2p3.fr 2.6.9-67.0.4.ELsmp #1 SMP Thu Jan 31 16:30:09 CST 2008 i686 i686 i386 GNU/Linux
Dir            : /grid_mnt/data2__polgrid/llr/ilc/reinhard/ILCSoft/TMVA/macros
Training events: 12829


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
Normalise: "True" [Normalise input variables]
V: "False" [Verbose mode]
H: "True" [Print classifier-specific help message]
NCycles: "500" [Number of training cycles]
HiddenLayers: "N+1,N" [Specification of hidden layer architecture (N stands for number of variables; any integers may also be used)]
NeuronType: "tanh" [Neuron activation function type]
TestRate: "5" [Test for overtraining performed at each #th epochs]
# Default:
D: "False" [Use-decorrelated-variables flag (depreciated)]
VarTransform: "None" [Variable transformation method]
VarTransformType: "Signal" [Use signal or background events to derive for variable transformation (the transformation is applied on both types of, course)]
NbinsMVAPdf: "60" [Number of bins used for the PDFs of classifier outputs]
NsmoothMVAPdf: "2" [Number of smoothing iterations for classifier PDFs]
VerboseLevel: "Default" [Verbosity level]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
TxtWeightFilesOnly: "True" [If True: write all training results (weights) as text files (False: some are written in ROOT format)]
NeuronInputType: "sum" [Neuron input function type]
TrainingMethod: "BP" [Train with Back-Propagation (BP - default) or Genetic Algorithm (GA - slower and worse)]
LearningRate: "0.02" [ANN learning rate parameter]
DecayRate: "0.01" [Decay rate for learning parameter]
BPMode: "sequential" [Back-propagation learning mode: sequential or batch]
BatchSize: "-1" [Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 13
ClusterParameters.start       ClusterParameters.start           'F'    [0,12.5771694183]
ClusterParameters.end         ClusterParameters.end             'F'    [1.0847774744,36.0665206909]
ClusterParameters.depth       ClusterParameters.depth           'F'    [0,28.8013954163]
ClusterParameters.E1C/ClusterParameters.Etot_g   ClusterParameters.E1C_D_ClusterParameters.Etot_g     'F'    [0,0.953556537628]
ClusterParameters.E4C/ClusterParameters.Etot_g   ClusterParameters.E4C_D_ClusterParameters.Etot_g     'F'    [0,1]
ClusterParameters.E9C/ClusterParameters.Etot_g   ClusterParameters.E9C_D_ClusterParameters.Etot_g     'F'    [0.138135582209,1]
ClusterParameters.dirErr      ClusterParameters.dirErr          'F'    [0.0152952224016,1]
ClusterParameters.seedDirErr  ClusterParameters.seedDirErr      'F'    [-4.23517849413e-05,0.999999701977]
ClusterParameters.Width       ClusterParameters.Width           'F'    [0.627331137657,19.774772644]
ClusterParameters.Eccentricity ClusterParameters.Eccentricity     'F'    [0.0367119461298,0.915940582752]
ClusterParameters.nHits       ClusterParameters.nHits           'F'    [5,123]
ClusterParameters.Volume      ClusterParameters.Volume          'F'    [48.7870941162,1333763.625]
ClusterParameters.depth-ClusterParameters.start   ClusterParameters.depth_M_ClusterParameters.start     'F'    [-12.3176460266,26.8946495056]


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;
};

#endif

class ReadMLP1_25_B : public IClassifierReader {

 public:

   // constructor
   ReadMLP1_25_B( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadMLP1_25_B" ),
        fStatusIsClean( true ),
        fNvars( 13 ),
        fIsNormalised( true )
   {      
      // the training input variables
      const char* inputVars[] = { "ClusterParameters.start", "ClusterParameters.end", "ClusterParameters.depth", "ClusterParameters.E1C/ClusterParameters.Etot_g", "ClusterParameters.E4C/ClusterParameters.Etot_g", "ClusterParameters.E9C/ClusterParameters.Etot_g", "ClusterParameters.dirErr", "ClusterParameters.seedDirErr", "ClusterParameters.Width", "ClusterParameters.Eccentricity", "ClusterParameters.nHits", "ClusterParameters.Volume", "ClusterParameters.depth-ClusterParameters.start" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 12.577169418335;
      fVmin[1] = 1.08477747440338;
      fVmax[1] = 36.066520690918;
      fVmin[2] = 0;
      fVmax[2] = 28.8013954162598;
      fVmin[3] = 0;
      fVmax[3] = 0.953556537628174;
      fVmin[4] = 0;
      fVmax[4] = 1;
      fVmin[5] = 0.138135582208633;
      fVmax[5] = 1;
      fVmin[6] = 0.015295222401619;
      fVmax[6] = 1;
      fVmin[7] = -4.23517849412747e-05;
      fVmax[7] = 0.999999701976776;
      fVmin[8] = 0.627331137657166;
      fVmax[8] = 19.774772644043;
      fVmin[9] = 0.0367119461297989;
      fVmax[9] = 0.915940582752228;
      fVmin[10] = 5;
      fVmax[10] = 123;
      fVmin[11] = 48.7870941162109;
      fVmax[11] = 1333763.625;
      fVmin[12] = -12.3176460266113;
      fVmax[12] = 26.8946495056152;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';
      fType[10] = 'F';
      fType[11] = 'F';
      fType[12] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadMLP1_25_B() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;
   bool fStatusIsClean;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[13];
   double fVmax[13];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[13];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)

   double ActivationFnc(double x) const;

   int fLayers;
   int fLayerSize[4];
   double fWeightMatrix0to1[15][14];   // weight matrix from layer 0 to 1
   double fWeightMatrix1to2[14][15];   // weight matrix from layer 1 to 2
   double fWeightMatrix2to3[1][14];   // weight matrix from layer 2 to 3

   double * fWeights[4];
};

inline void ReadMLP1_25_B::Initialize()
{
   // build network structure
   fLayers = 4;
   fLayerSize[0] = 14; fWeights[0] = new double[14]; 
   fLayerSize[1] = 15; fWeights[1] = new double[15]; 
   fLayerSize[2] = 14; fWeights[2] = new double[14]; 
   fLayerSize[3] = 1; fWeights[3] = new double[1]; 
   // weight matrix from layer 0 to 1
   fWeightMatrix0to1[0][0] = -0.0833975594944879;
   fWeightMatrix0to1[1][0] = 1.81145131734352;
   fWeightMatrix0to1[2][0] = -0.690644287605927;
   fWeightMatrix0to1[3][0] = 1.85291563962659;
   fWeightMatrix0to1[4][0] = -0.755581786199735;
   fWeightMatrix0to1[5][0] = -1.45807983853577;
   fWeightMatrix0to1[6][0] = -0.699497294794732;
   fWeightMatrix0to1[7][0] = 2.11430881931776;
   fWeightMatrix0to1[8][0] = -2.02289273601871;
   fWeightMatrix0to1[9][0] = -0.325755001084349;
   fWeightMatrix0to1[10][0] = -1.46228361475368;
   fWeightMatrix0to1[11][0] = -0.470184382754074;
   fWeightMatrix0to1[12][0] = -1.34270675476855;
   fWeightMatrix0to1[13][0] = -0.678889440825854;
   fWeightMatrix0to1[0][1] = -0.320013829100736;
   fWeightMatrix0to1[1][1] = 0.571131440015681;
   fWeightMatrix0to1[2][1] = -1.48199602572176;
   fWeightMatrix0to1[3][1] = 1.56330189440924;
   fWeightMatrix0to1[4][1] = 0.903077975625793;
   fWeightMatrix0to1[5][1] = 1.10808204700169;
   fWeightMatrix0to1[6][1] = -0.264111324041842;
   fWeightMatrix0to1[7][1] = -0.502352876141385;
   fWeightMatrix0to1[8][1] = 0.776952793243583;
   fWeightMatrix0to1[9][1] = -0.0255382504517125;
   fWeightMatrix0to1[10][1] = -0.905433951723104;
   fWeightMatrix0to1[11][1] = -0.34291318482619;
   fWeightMatrix0to1[12][1] = 2.20396287187258;
   fWeightMatrix0to1[13][1] = -1.10437826119773;
   fWeightMatrix0to1[0][2] = -0.863733439177977;
   fWeightMatrix0to1[1][2] = 0.0668028140774981;
   fWeightMatrix0to1[2][2] = 0.0215308369835719;
   fWeightMatrix0to1[3][2] = 1.57574024218518;
   fWeightMatrix0to1[4][2] = 0.468236108781552;
   fWeightMatrix0to1[5][2] = -0.322735384732505;
   fWeightMatrix0to1[6][2] = 0.276967032537179;
   fWeightMatrix0to1[7][2] = 0.0186803732209747;
   fWeightMatrix0to1[8][2] = 0.901069516970317;
   fWeightMatrix0to1[9][2] = 1.94271175074099;
   fWeightMatrix0to1[10][2] = -1.21908291582615;
   fWeightMatrix0to1[11][2] = 0.97017125979099;
   fWeightMatrix0to1[12][2] = 3.30942439189583;
   fWeightMatrix0to1[13][2] = 0.626260224698255;
   fWeightMatrix0to1[0][3] = 1.03825150586943;
   fWeightMatrix0to1[1][3] = 1.56169602587967;
   fWeightMatrix0to1[2][3] = -0.757490639594402;
   fWeightMatrix0to1[3][3] = -0.921250204478347;
   fWeightMatrix0to1[4][3] = 1.43708499228065;
   fWeightMatrix0to1[5][3] = -0.143372689282223;
   fWeightMatrix0to1[6][3] = 1.69470861513041;
   fWeightMatrix0to1[7][3] = 1.83831352735069;
   fWeightMatrix0to1[8][3] = 1.46818985751096;
   fWeightMatrix0to1[9][3] = -0.0386251750326214;
   fWeightMatrix0to1[10][3] = -2.02507729519459;
   fWeightMatrix0to1[11][3] = 1.21429244045061;
   fWeightMatrix0to1[12][3] = -3.47129804904778;
   fWeightMatrix0to1[13][3] = -1.0662498903493;
   fWeightMatrix0to1[0][4] = -2.53916879534644;
   fWeightMatrix0to1[1][4] = -1.45992206235412;
   fWeightMatrix0to1[2][4] = 2.17481254201515;
   fWeightMatrix0to1[3][4] = 0.989228571433664;
   fWeightMatrix0to1[4][4] = -2.22740699848094;
   fWeightMatrix0to1[5][4] = 0.34093738254399;
   fWeightMatrix0to1[6][4] = -0.174393741693225;
   fWeightMatrix0to1[7][4] = 0.54103886496586;
   fWeightMatrix0to1[8][4] = 1.05964897774498;
   fWeightMatrix0to1[9][4] = -0.15812018629775;
   fWeightMatrix0to1[10][4] = -0.0657083204126328;
   fWeightMatrix0to1[11][4] = -0.782761835520278;
   fWeightMatrix0to1[12][4] = -0.149587968660298;
   fWeightMatrix0to1[13][4] = -0.718301446218296;
   fWeightMatrix0to1[0][5] = -1.06858451185722;
   fWeightMatrix0to1[1][5] = -1.26648427286807;
   fWeightMatrix0to1[2][5] = -0.0135781840993817;
   fWeightMatrix0to1[3][5] = 0.856476334079841;
   fWeightMatrix0to1[4][5] = 0.583297836324082;
   fWeightMatrix0to1[5][5] = -0.491973920552669;
   fWeightMatrix0to1[6][5] = -1.86667626071145;
   fWeightMatrix0to1[7][5] = -2.02388822787972;
   fWeightMatrix0to1[8][5] = -0.294975409111253;
   fWeightMatrix0to1[9][5] = -1.02088302058323;
   fWeightMatrix0to1[10][5] = 2.01674281978132;
   fWeightMatrix0to1[11][5] = 1.10522723933079;
   fWeightMatrix0to1[12][5] = 0.711683528536655;
   fWeightMatrix0to1[13][5] = -0.769498396461242;
   fWeightMatrix0to1[0][6] = -2.01817697559723;
   fWeightMatrix0to1[1][6] = -0.442882734638486;
   fWeightMatrix0to1[2][6] = 1.1371240589412;
   fWeightMatrix0to1[3][6] = -1.75245213660559;
   fWeightMatrix0to1[4][6] = -2.26209941382435;
   fWeightMatrix0to1[5][6] = -1.8060977730132;
   fWeightMatrix0to1[6][6] = -0.292067912861385;
   fWeightMatrix0to1[7][6] = -0.335342109540397;
   fWeightMatrix0to1[8][6] = 5.06739172349634;
   fWeightMatrix0to1[9][6] = -3.61910514500572;
   fWeightMatrix0to1[10][6] = -0.215659644444166;
   fWeightMatrix0to1[11][6] = 1.84941792469149;
   fWeightMatrix0to1[12][6] = -2.78338161560494;
   fWeightMatrix0to1[13][6] = -1.35793717868733;
   fWeightMatrix0to1[0][7] = -0.908133792135432;
   fWeightMatrix0to1[1][7] = 0.319085748390151;
   fWeightMatrix0to1[2][7] = -0.67198779558534;
   fWeightMatrix0to1[3][7] = -0.990017303051743;
   fWeightMatrix0to1[4][7] = -0.252316479758073;
   fWeightMatrix0to1[5][7] = 2.36215763216988;
   fWeightMatrix0to1[6][7] = -1.01324517101502;
   fWeightMatrix0to1[7][7] = 1.1246971371432;
   fWeightMatrix0to1[8][7] = 0.426926442320646;
   fWeightMatrix0to1[9][7] = -0.236030550481221;
   fWeightMatrix0to1[10][7] = 0.21348792984356;
   fWeightMatrix0to1[11][7] = 0.702636396171513;
   fWeightMatrix0to1[12][7] = -0.247115278816791;
   fWeightMatrix0to1[13][7] = 0.612479519648636;
   fWeightMatrix0to1[0][8] = 0.259228922304976;
   fWeightMatrix0to1[1][8] = 0.264271007115257;
   fWeightMatrix0to1[2][8] = -1.10446960932352;
   fWeightMatrix0to1[3][8] = 1.69252619826932;
   fWeightMatrix0to1[4][8] = 0.495876847595697;
   fWeightMatrix0to1[5][8] = -0.805109800527823;
   fWeightMatrix0to1[6][8] = 0.677257739209034;
   fWeightMatrix0to1[7][8] = -1.03072588112917;
   fWeightMatrix0to1[8][8] = -0.142590506313164;
   fWeightMatrix0to1[9][8] = 0.660709738236899;
   fWeightMatrix0to1[10][8] = -0.300407345418503;
   fWeightMatrix0to1[11][8] = 1.41877442771038;
   fWeightMatrix0to1[12][8] = 1.69911886893623;
   fWeightMatrix0to1[13][8] = -0.100204887643548;
   fWeightMatrix0to1[0][9] = -1.06186039345017;
   fWeightMatrix0to1[1][9] = 0.102591349096155;
   fWeightMatrix0to1[2][9] = -0.677983336737986;
   fWeightMatrix0to1[3][9] = 1.20145361135829;
   fWeightMatrix0to1[4][9] = -0.789187788033933;
   fWeightMatrix0to1[5][9] = -1.18275171605088;
   fWeightMatrix0to1[6][9] = 0.560086572941384;
   fWeightMatrix0to1[7][9] = -1.06830219853843;
   fWeightMatrix0to1[8][9] = -0.0836362416568688;
   fWeightMatrix0to1[9][9] = -0.55814614145506;
   fWeightMatrix0to1[10][9] = 1.42754675038612;
   fWeightMatrix0to1[11][9] = -2.02695596251958;
   fWeightMatrix0to1[12][9] = 1.09460117770239;
   fWeightMatrix0to1[13][9] = 1.25927397424028;
   fWeightMatrix0to1[0][10] = 2.49768003596012;
   fWeightMatrix0to1[1][10] = 0.271088848493257;
   fWeightMatrix0to1[2][10] = -2.50050778619374;
   fWeightMatrix0to1[3][10] = -0.0262268993103178;
   fWeightMatrix0to1[4][10] = -3.4210652780505;
   fWeightMatrix0to1[5][10] = 1.34331815096418;
   fWeightMatrix0to1[6][10] = 1.25893954762964;
   fWeightMatrix0to1[7][10] = -0.857119551884442;
   fWeightMatrix0to1[8][10] = 1.14675681897116;
   fWeightMatrix0to1[9][10] = -5.76628410236748;
   fWeightMatrix0to1[10][10] = -1.58392791664968;
   fWeightMatrix0to1[11][10] = 0.299923980407744;
   fWeightMatrix0to1[12][10] = 2.65661132995715;
   fWeightMatrix0to1[13][10] = -0.623944911340104;
   fWeightMatrix0to1[0][11] = -1.54914928892717;
   fWeightMatrix0to1[1][11] = 0.583298110144302;
   fWeightMatrix0to1[2][11] = 1.61482401848167;
   fWeightMatrix0to1[3][11] = 1.26874965004707;
   fWeightMatrix0to1[4][11] = 0.136251545532361;
   fWeightMatrix0to1[5][11] = -1.65289334292875;
   fWeightMatrix0to1[6][11] = 1.73921299351216;
   fWeightMatrix0to1[7][11] = 0.721209568568008;
   fWeightMatrix0to1[8][11] = 1.15191623950562;
   fWeightMatrix0to1[9][11] = 0.105946499627398;
   fWeightMatrix0to1[10][11] = 0.532370316213861;
   fWeightMatrix0to1[11][11] = -0.798727140655625;
   fWeightMatrix0to1[12][11] = -0.537777149261164;
   fWeightMatrix0to1[13][11] = 0.910500497551814;
   fWeightMatrix0to1[0][12] = -0.218018773859407;
   fWeightMatrix0to1[1][12] = -0.583955050349972;
   fWeightMatrix0to1[2][12] = 1.57949435205803;
   fWeightMatrix0to1[3][12] = 0.880118964087332;
   fWeightMatrix0to1[4][12] = -0.0749544386599376;
   fWeightMatrix0to1[5][12] = 1.41238597615728;
   fWeightMatrix0to1[6][12] = 1.85150622755409;
   fWeightMatrix0to1[7][12] = -1.78105050832595;
   fWeightMatrix0to1[8][12] = 2.53287900188623;
   fWeightMatrix0to1[9][12] = -0.0840170515202683;
   fWeightMatrix0to1[10][12] = 0.451329261695072;
   fWeightMatrix0to1[11][12] = -1.78332216936375;
   fWeightMatrix0to1[12][12] = 0.0757455894836332;
   fWeightMatrix0to1[13][12] = 1.05234804668389;
   fWeightMatrix0to1[0][13] = 2.46110654894702;
   fWeightMatrix0to1[1][13] = -2.09854315182325;
   fWeightMatrix0to1[2][13] = -0.753234310430093;
   fWeightMatrix0to1[3][13] = -1.36061911854523;
   fWeightMatrix0to1[4][13] = 0.903888245964163;
   fWeightMatrix0to1[5][13] = 1.95237295202562;
   fWeightMatrix0to1[6][13] = -0.596275724338789;
   fWeightMatrix0to1[7][13] = -0.651238570962737;
   fWeightMatrix0to1[8][13] = -1.88249094631314;
   fWeightMatrix0to1[9][13] = 1.54900090155326;
   fWeightMatrix0to1[10][13] = 2.25592947658922;
   fWeightMatrix0to1[11][13] = 1.29353149400416;
   fWeightMatrix0to1[12][13] = 1.28105778556621;
   fWeightMatrix0to1[13][13] = -0.672368148602593;
   // weight matrix from layer 1 to 2
   fWeightMatrix1to2[0][0] = 0.895781999581823;
   fWeightMatrix1to2[1][0] = 0.991655294787722;
   fWeightMatrix1to2[2][0] = 0.0517024900513124;
   fWeightMatrix1to2[3][0] = -1.19316490385582;
   fWeightMatrix1to2[4][0] = -2.3000030793305;
   fWeightMatrix1to2[5][0] = 0.813945480990813;
   fWeightMatrix1to2[6][0] = 0.479119157771861;
   fWeightMatrix1to2[7][0] = -1.95084793117478;
   fWeightMatrix1to2[8][0] = 1.4418431167741;
   fWeightMatrix1to2[9][0] = 0.842102834856485;
   fWeightMatrix1to2[10][0] = -0.108862482379747;
   fWeightMatrix1to2[11][0] = -0.101994913570074;
   fWeightMatrix1to2[12][0] = 1.62815422145845;
   fWeightMatrix1to2[0][1] = 0.56408546963811;
   fWeightMatrix1to2[1][1] = 0.274651478654507;
   fWeightMatrix1to2[2][1] = -0.197900774981911;
   fWeightMatrix1to2[3][1] = -1.79263838824845;
   fWeightMatrix1to2[4][1] = -0.346121729825543;
   fWeightMatrix1to2[5][1] = 1.49851811899382;
   fWeightMatrix1to2[6][1] = 1.15982864025123;
   fWeightMatrix1to2[7][1] = 1.1592199212923;
   fWeightMatrix1to2[8][1] = 0.0932288181838823;
   fWeightMatrix1to2[9][1] = 2.09017550131549;
   fWeightMatrix1to2[10][1] = -2.1414135632201;
   fWeightMatrix1to2[11][1] = -1.32528695932555;
   fWeightMatrix1to2[12][1] = -0.13079826572892;
   fWeightMatrix1to2[0][2] = -1.8777165660651;
   fWeightMatrix1to2[1][2] = 1.05152365581799;
   fWeightMatrix1to2[2][2] = 1.78619120264399;
   fWeightMatrix1to2[3][2] = -1.45744123305118;
   fWeightMatrix1to2[4][2] = 0.0806228942972085;
   fWeightMatrix1to2[5][2] = -0.184694483508738;
   fWeightMatrix1to2[6][2] = -1.81056456335739;
   fWeightMatrix1to2[7][2] = -1.02396957345609;
   fWeightMatrix1to2[8][2] = 1.12423659271104;
   fWeightMatrix1to2[9][2] = 0.117523940858983;
   fWeightMatrix1to2[10][2] = 0.725947946858085;
   fWeightMatrix1to2[11][2] = -1.16965973641366;
   fWeightMatrix1to2[12][2] = 1.68932443064064;
   fWeightMatrix1to2[0][3] = -1.90306992274215;
   fWeightMatrix1to2[1][3] = 0.600334844815056;
   fWeightMatrix1to2[2][3] = -0.0166374290426064;
   fWeightMatrix1to2[3][3] = -1.54336432919866;
   fWeightMatrix1to2[4][3] = -0.690062960533366;
   fWeightMatrix1to2[5][3] = -2.19931434401097;
   fWeightMatrix1to2[6][3] = -0.472509584962066;
   fWeightMatrix1to2[7][3] = -1.49739397576282;
   fWeightMatrix1to2[8][3] = -1.71451692339397;
   fWeightMatrix1to2[9][3] = -1.58607010928138;
   fWeightMatrix1to2[10][3] = 0.000353826984100723;
   fWeightMatrix1to2[11][3] = -0.99609486302036;
   fWeightMatrix1to2[12][3] = -1.62460956447285;
   fWeightMatrix1to2[0][4] = 2.02806659369348;
   fWeightMatrix1to2[1][4] = -0.823551115159221;
   fWeightMatrix1to2[2][4] = -0.209101708526784;
   fWeightMatrix1to2[3][4] = -0.913145406415358;
   fWeightMatrix1to2[4][4] = -0.228085199617684;
   fWeightMatrix1to2[5][4] = 1.5472223789897;
   fWeightMatrix1to2[6][4] = 1.41329457100492;
   fWeightMatrix1to2[7][4] = -1.14548479190652;
   fWeightMatrix1to2[8][4] = -1.57755165956489;
   fWeightMatrix1to2[9][4] = -1.07823037135313;
   fWeightMatrix1to2[10][4] = -0.807207007592512;
   fWeightMatrix1to2[11][4] = -1.60718954541393;
   fWeightMatrix1to2[12][4] = 0.34272770419852;
   fWeightMatrix1to2[0][5] = 0.776748381840048;
   fWeightMatrix1to2[1][5] = 1.97299305589486;
   fWeightMatrix1to2[2][5] = -0.130051303802224;
   fWeightMatrix1to2[3][5] = 0.0829354734125704;
   fWeightMatrix1to2[4][5] = -1.33269746955464;
   fWeightMatrix1to2[5][5] = -1.47046541665692;
   fWeightMatrix1to2[6][5] = 1.31251130675557;
   fWeightMatrix1to2[7][5] = 0.671618359923953;
   fWeightMatrix1to2[8][5] = -0.725623664990819;
   fWeightMatrix1to2[9][5] = -1.136222700869;
   fWeightMatrix1to2[10][5] = 0.691229528222669;
   fWeightMatrix1to2[11][5] = 1.22234139955891;
   fWeightMatrix1to2[12][5] = 0.463450013435203;
   fWeightMatrix1to2[0][6] = -0.98048535821563;
   fWeightMatrix1to2[1][6] = -0.530275404489873;
   fWeightMatrix1to2[2][6] = 1.36746011281354;
   fWeightMatrix1to2[3][6] = 1.14062070149496;
   fWeightMatrix1to2[4][6] = 1.60352905483126;
   fWeightMatrix1to2[5][6] = -0.490913371809211;
   fWeightMatrix1to2[6][6] = 0.160007754556882;
   fWeightMatrix1to2[7][6] = 0.130964551110236;
   fWeightMatrix1to2[8][6] = -1.56781289808136;
   fWeightMatrix1to2[9][6] = -0.39443968757648;
   fWeightMatrix1to2[10][6] = -2.19058131905538;
   fWeightMatrix1to2[11][6] = -1.39888603695036;
   fWeightMatrix1to2[12][6] = -1.54399417706686;
   fWeightMatrix1to2[0][7] = 1.21726012161978;
   fWeightMatrix1to2[1][7] = -1.74942257183529;
   fWeightMatrix1to2[2][7] = 1.55941701305072;
   fWeightMatrix1to2[3][7] = -1.38276723934219;
   fWeightMatrix1to2[4][7] = 0.823379103950856;
   fWeightMatrix1to2[5][7] = -1.13097314208634;
   fWeightMatrix1to2[6][7] = 0.259997741758136;
   fWeightMatrix1to2[7][7] = 1.23973394546848;
   fWeightMatrix1to2[8][7] = -1.70337826481322;
   fWeightMatrix1to2[9][7] = 0.351844503322561;
   fWeightMatrix1to2[10][7] = 0.150950318630568;
   fWeightMatrix1to2[11][7] = -1.97035990295023;
   fWeightMatrix1to2[12][7] = -1.44844782277315;
   fWeightMatrix1to2[0][8] = -2.48091915505351;
   fWeightMatrix1to2[1][8] = -0.789494099276179;
   fWeightMatrix1to2[2][8] = 1.86065117256847;
   fWeightMatrix1to2[3][8] = -0.830337184462238;
   fWeightMatrix1to2[4][8] = 2.09952206860807;
   fWeightMatrix1to2[5][8] = 0.0962571650769816;
   fWeightMatrix1to2[6][8] = -1.13971486351492;
   fWeightMatrix1to2[7][8] = -0.791271219584701;
   fWeightMatrix1to2[8][8] = -0.873146420343097;
   fWeightMatrix1to2[9][8] = -1.37336824082621;
   fWeightMatrix1to2[10][8] = 0.477303993949672;
   fWeightMatrix1to2[11][8] = -1.35954800995729;
   fWeightMatrix1to2[12][8] = -1.2495357225007;
   fWeightMatrix1to2[0][9] = 2.16365221491054;
   fWeightMatrix1to2[1][9] = 0.404079505130197;
   fWeightMatrix1to2[2][9] = -0.654222915284035;
   fWeightMatrix1to2[3][9] = 2.03142403424642;
   fWeightMatrix1to2[4][9] = -3.30425543939775;
   fWeightMatrix1to2[5][9] = 1.3615066119477;
   fWeightMatrix1to2[6][9] = 1.24295582457727;
   fWeightMatrix1to2[7][9] = -1.11654340148566;
   fWeightMatrix1to2[8][9] = -0.846317005268731;
   fWeightMatrix1to2[9][9] = 0.0890133302946635;
   fWeightMatrix1to2[10][9] = -0.841900485663089;
   fWeightMatrix1to2[11][9] = 0.510399224302178;
   fWeightMatrix1to2[12][9] = 1.88284868055967;
   fWeightMatrix1to2[0][10] = 1.67789201146601;
   fWeightMatrix1to2[1][10] = 1.76665479865367;
   fWeightMatrix1to2[2][10] = -1.34352594540175;
   fWeightMatrix1to2[3][10] = 0.979142539105591;
   fWeightMatrix1to2[4][10] = -2.44333389725021;
   fWeightMatrix1to2[5][10] = 0.822706636491543;
   fWeightMatrix1to2[6][10] = -1.51685356992778;
   fWeightMatrix1to2[7][10] = -2.18049673275677;
   fWeightMatrix1to2[8][10] = 0.0399971497776965;
   fWeightMatrix1to2[9][10] = 1.22607218385282;
   fWeightMatrix1to2[10][10] = 0.851066703315279;
   fWeightMatrix1to2[11][10] = 1.07095220758606;
   fWeightMatrix1to2[12][10] = 0.284398373666158;
   fWeightMatrix1to2[0][11] = 0.244801652875211;
   fWeightMatrix1to2[1][11] = -0.565581611008485;
   fWeightMatrix1to2[2][11] = 0.200852039772091;
   fWeightMatrix1to2[3][11] = 1.66623002490321;
   fWeightMatrix1to2[4][11] = -2.03170380914499;
   fWeightMatrix1to2[5][11] = 0.552587987580382;
   fWeightMatrix1to2[6][11] = -1.3053066772244;
   fWeightMatrix1to2[7][11] = -0.839036945533858;
   fWeightMatrix1to2[8][11] = 0.149081853488754;
   fWeightMatrix1to2[9][11] = 0.0353467702485036;
   fWeightMatrix1to2[10][11] = -0.801577762853231;
   fWeightMatrix1to2[11][11] = 0.967554353441175;
   fWeightMatrix1to2[12][11] = 1.68607195764282;
   fWeightMatrix1to2[0][12] = 1.6641621645653;
   fWeightMatrix1to2[1][12] = -0.227743967825541;
   fWeightMatrix1to2[2][12] = -1.06200861937649;
   fWeightMatrix1to2[3][12] = -1.67634056165177;
   fWeightMatrix1to2[4][12] = -3.18828252877138;
   fWeightMatrix1to2[5][12] = 1.76332839271149;
   fWeightMatrix1to2[6][12] = -0.120324310668605;
   fWeightMatrix1to2[7][12] = -1.21870261359116;
   fWeightMatrix1to2[8][12] = 0.399359853799606;
   fWeightMatrix1to2[9][12] = -1.58056290766817;
   fWeightMatrix1to2[10][12] = -0.652980219457158;
   fWeightMatrix1to2[11][12] = -1.59875045971746;
   fWeightMatrix1to2[12][12] = 0.99364761248368;
   fWeightMatrix1to2[0][13] = -1.9596509207525;
   fWeightMatrix1to2[1][13] = -1.85221074435719;
   fWeightMatrix1to2[2][13] = -0.694865337485764;
   fWeightMatrix1to2[3][13] = -0.712919971923091;
   fWeightMatrix1to2[4][13] = -0.900844294940265;
   fWeightMatrix1to2[5][13] = 0.824124071192794;
   fWeightMatrix1to2[6][13] = -1.41555462199581;
   fWeightMatrix1to2[7][13] = -0.89994213129127;
   fWeightMatrix1to2[8][13] = 1.61103171762384;
   fWeightMatrix1to2[9][13] = 0.686824464785468;
   fWeightMatrix1to2[10][13] = 0.205454159285279;
   fWeightMatrix1to2[11][13] = 0.10684820976023;
   fWeightMatrix1to2[12][13] = 1.3292723606862;
   fWeightMatrix1to2[0][14] = 2.23007308803185;
   fWeightMatrix1to2[1][14] = 0.737408573882673;
   fWeightMatrix1to2[2][14] = -0.860196642121587;
   fWeightMatrix1to2[3][14] = -0.835961588862198;
   fWeightMatrix1to2[4][14] = -2.35680629704411;
   fWeightMatrix1to2[5][14] = 1.12126704799235;
   fWeightMatrix1to2[6][14] = 1.05501278422867;
   fWeightMatrix1to2[7][14] = -0.318600891386058;
   fWeightMatrix1to2[8][14] = 1.20232272048926;
   fWeightMatrix1to2[9][14] = 0.818995457683085;
   fWeightMatrix1to2[10][14] = 2.13442274472814;
   fWeightMatrix1to2[11][14] = -1.32626235917538;
   fWeightMatrix1to2[12][14] = 1.75725661294904;
   // weight matrix from layer 2 to 3
   fWeightMatrix2to3[0][0] = -0.41780303773729;
   fWeightMatrix2to3[0][1] = -1.89011165775018;
   fWeightMatrix2to3[0][2] = -0.115943909242313;
   fWeightMatrix2to3[0][3] = -0.000400262051497625;
   fWeightMatrix2to3[0][4] = 0.674154149296565;
   fWeightMatrix2to3[0][5] = -0.0923820077557958;
   fWeightMatrix2to3[0][6] = -0.00355013830262067;
   fWeightMatrix2to3[0][7] = -0.0982659766072505;
   fWeightMatrix2to3[0][8] = -0.0668282577292088;
   fWeightMatrix2to3[0][9] = 0.00387038827715373;
   fWeightMatrix2to3[0][10] = 1.38958368338699;
   fWeightMatrix2to3[0][11] = 0.0746559915631588;
   fWeightMatrix2to3[0][12] = -1.17828130121096;
   fWeightMatrix2to3[0][13] = 1.65190792069717;
}

inline double ReadMLP1_25_B::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   if (inputValues.size() != (unsigned int)fLayerSize[0]-1) {
      std::cout << "Input vector needs to be of size " << fLayerSize[0]-1 << std::endl;
      return 0;
   }

   for (int l=0; l<fLayers; l++)
      for (int i=0; i<fLayerSize[l]; i++) fWeights[l][i]=0;

   for (int l=0; l<fLayers-1; l++)
      fWeights[l][fLayerSize[l]-1]=1;

   for (int i=0; i<fLayerSize[0]-1; i++)
      fWeights[0][i]=inputValues[i];

   // layer 0 to 1
   for (int o=0; o<fLayerSize[1]-1; o++) {
      for (int i=0; i<fLayerSize[0]; i++) {
         double inputVal = fWeightMatrix0to1[o][i] * fWeights[0][i];
         fWeights[1][o] += inputVal;
      }
      fWeights[1][o] = ActivationFnc(fWeights[1][o]);
   }
   // layer 1 to 2
   for (int o=0; o<fLayerSize[2]-1; o++) {
      for (int i=0; i<fLayerSize[1]; i++) {
         double inputVal = fWeightMatrix1to2[o][i] * fWeights[1][i];
         fWeights[2][o] += inputVal;
      }
      fWeights[2][o] = ActivationFnc(fWeights[2][o]);
   }
   // layer 2 to 3
   for (int o=0; o<fLayerSize[3]; o++) {
      for (int i=0; i<fLayerSize[2]; i++) {
         double inputVal = fWeightMatrix2to3[o][i] * fWeights[2][i];
         fWeights[3][o] += inputVal;
      }
   }

   return fWeights[3][0];
}

double ReadMLP1_25_B::ActivationFnc(double x) const
{
   // hyperbolic tan
   return tanh(x);
}
 
   
// Clean up
inline void ReadMLP1_25_B::Clear() 
{
   // nothing to clear
}
inline double ReadMLP1_25_B::GetMvaValue( const std::vector<double>& inputValues ) const
{
   // classifier response value
   double retval = 0;

   // classifier response, sanity check first
   if (!fStatusIsClean) {
      std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
      retval = 0;
   }
   else {
      if (IsNormalised()) {
         // normalise variables
         std::vector<double> iV;
         int ivar = 0;
         for (std::vector<double>::const_iterator varIt = inputValues.begin();
              varIt != inputValues.end(); varIt++, ivar++) {
            iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
         }
         retval = GetMvaValue__( iV );
      }
      else {
         retval = GetMvaValue__( inputValues );
      }
   }

   return retval;
}

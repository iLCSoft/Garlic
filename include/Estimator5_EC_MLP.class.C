// Class: ReadMLP5_EC
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : MLP::MLP
TMVA Release   : 3.9.6         [198918]
ROOT Release   : 5.16/00       [331776]
Creator        : reinhard
Date           : Sat Aug  8 10:33:50 2009
Host           : Linux polui02.in2p3.fr 2.6.9-67.0.4.ELsmp #1 SMP Thu Jan 31 16:30:09 CST 2008 i686 i686 i386 GNU/Linux
Dir            : /grid_mnt/data2__polgrid/llr/ilc/reinhard/ILCSoft/TMVA/macros
Training events: 10423


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
Normalise: "True" [Normalise input variables]
V: "False" [Verbose mode]
H: "True" [Print classifier-specific help message]
NCycles: "500" [Number of training cycles]
HiddenLayers: "N+1,N" [Specification of hidden layer architecture (N stands for number of variables; any integers may also be used)]
NeuronType: "tanh" [Neuron activation function type]
TestRate: "5" [Test for overtraining performed at each #th epochs]
# Default:
D: "False" [Use-decorrelated-variables flag (depreciated)]
VarTransform: "None" [Variable transformation method]
VarTransformType: "Signal" [Use signal or background events to derive for variable transformation (the transformation is applied on both types of, course)]
NbinsMVAPdf: "60" [Number of bins used for the PDFs of classifier outputs]
NsmoothMVAPdf: "2" [Number of smoothing iterations for classifier PDFs]
VerboseLevel: "Default" [Verbosity level]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
TxtWeightFilesOnly: "True" [If True: write all training results (weights) as text files (False: some are written in ROOT format)]
NeuronInputType: "sum" [Neuron input function type]
TrainingMethod: "BP" [Train with Back-Propagation (BP - default) or Genetic Algorithm (GA - slower and worse)]
LearningRate: "0.02" [ANN learning rate parameter]
DecayRate: "0.01" [Decay rate for learning parameter]
BPMode: "sequential" [Back-propagation learning mode: sequential or batch]
BatchSize: "-1" [Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 14
ClusterParameters.start       ClusterParameters.start           'F'    [0,12.2015619278]
ClusterParameters.end         ClusterParameters.end             'F'    [4.539894104,38.9521751404]
ClusterParameters.depth       ClusterParameters.depth           'F'    [0,26.8457355499]
ClusterParameters.E1C/ClusterParameters.Etot_g   ClusterParameters.E1C_D_ClusterParameters.Etot_g     'F'    [0,0.795362770557]
ClusterParameters.E4C/ClusterParameters.Etot_g   ClusterParameters.E4C_D_ClusterParameters.Etot_g     'F'    [0.00167501997203,0.992404341698]
ClusterParameters.E9C/ClusterParameters.Etot_g   ClusterParameters.E9C_D_ClusterParameters.Etot_g     'F'    [0.155072152615,1]
ClusterParameters.dirErr      ClusterParameters.dirErr          'F'    [0.151588410139,0.999999821186]
ClusterParameters.seedDirErr  ClusterParameters.seedDirErr      'F'    [-9.38652956393e-05,0.999999940395]
ClusterParameters.Es3/ClusterParameters.Etot_g   ClusterParameters.Es3_D_ClusterParameters.Etot_g     'F'    [0,0.846283376217]
ClusterParameters.Width       ClusterParameters.Width           'F'    [1.8475818634,21.9138526917]
ClusterParameters.Eccentricity ClusterParameters.Eccentricity     'F'    [0.0635685622692,0.87299823761]
ClusterParameters.nHits       ClusterParameters.nHits           'F'    [12,211]
ClusterParameters.Volume      ClusterParameters.Volume          'F'    [433.499603271,1046447.9375]
ClusterParameters.depth-ClusterParameters.start   ClusterParameters.depth_M_ClusterParameters.start     'F'    [-1.98671102524,23.4449691772]


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;
};

#endif

class ReadMLP5_EC : public IClassifierReader {

 public:

   // constructor
   ReadMLP5_EC( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadMLP5_EC" ),
        fStatusIsClean( true ),
        fNvars( 14 ),
        fIsNormalised( true )
   {      
      // the training input variables
      const char* inputVars[] = { "ClusterParameters.start", "ClusterParameters.end", "ClusterParameters.depth", "ClusterParameters.E1C/ClusterParameters.Etot_g", "ClusterParameters.E4C/ClusterParameters.Etot_g", "ClusterParameters.E9C/ClusterParameters.Etot_g", "ClusterParameters.dirErr", "ClusterParameters.seedDirErr", "ClusterParameters.Es3/ClusterParameters.Etot_g", "ClusterParameters.Width", "ClusterParameters.Eccentricity", "ClusterParameters.nHits", "ClusterParameters.Volume", "ClusterParameters.depth-ClusterParameters.start" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 12.2015619277954;
      fVmin[1] = 4.53989410400391;
      fVmax[1] = 38.9521751403809;
      fVmin[2] = 0;
      fVmax[2] = 26.8457355499268;
      fVmin[3] = 0;
      fVmax[3] = 0.795362770557404;
      fVmin[4] = 0.00167501997202635;
      fVmax[4] = 0.992404341697693;
      fVmin[5] = 0.155072152614594;
      fVmax[5] = 1;
      fVmin[6] = 0.151588410139084;
      fVmax[6] = 0.999999821186066;
      fVmin[7] = -9.38652956392616e-05;
      fVmax[7] = 0.999999940395355;
      fVmin[8] = 0;
      fVmax[8] = 0.846283376216888;
      fVmin[9] = 1.84758186340332;
      fVmax[9] = 21.9138526916504;
      fVmin[10] = 0.0635685622692108;
      fVmax[10] = 0.872998237609863;
      fVmin[11] = 12;
      fVmax[11] = 211;
      fVmin[12] = 433.499603271484;
      fVmax[12] = 1046447.9375;
      fVmin[13] = -1.98671102523804;
      fVmax[13] = 23.4449691772461;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';
      fType[10] = 'F';
      fType[11] = 'F';
      fType[12] = 'F';
      fType[13] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadMLP5_EC() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;
   bool fStatusIsClean;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[14];
   double fVmax[14];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[14];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)

   double ActivationFnc(double x) const;

   int fLayers;
   int fLayerSize[4];
   double fWeightMatrix0to1[16][15];   // weight matrix from layer 0 to 1
   double fWeightMatrix1to2[15][16];   // weight matrix from layer 1 to 2
   double fWeightMatrix2to3[1][15];   // weight matrix from layer 2 to 3

   double * fWeights[4];
};

inline void ReadMLP5_EC::Initialize()
{
   // build network structure
   fLayers = 4;
   fLayerSize[0] = 15; fWeights[0] = new double[15]; 
   fLayerSize[1] = 16; fWeights[1] = new double[16]; 
   fLayerSize[2] = 15; fWeights[2] = new double[15]; 
   fLayerSize[3] = 1; fWeights[3] = new double[1]; 
   // weight matrix from layer 0 to 1
   fWeightMatrix0to1[0][0] = -0.331760738146378;
   fWeightMatrix0to1[1][0] = 1.89118021794831;
   fWeightMatrix0to1[2][0] = 0.811894253084369;
   fWeightMatrix0to1[3][0] = 2.05745470130086;
   fWeightMatrix0to1[4][0] = -1.95437566302531;
   fWeightMatrix0to1[5][0] = -1.69444710242796;
   fWeightMatrix0to1[6][0] = 0.113109770182255;
   fWeightMatrix0to1[7][0] = 2.16552150925738;
   fWeightMatrix0to1[8][0] = -1.50410325184254;
   fWeightMatrix0to1[9][0] = -0.691379515665627;
   fWeightMatrix0to1[10][0] = -2.0797229544737;
   fWeightMatrix0to1[11][0] = 0.113696934784113;
   fWeightMatrix0to1[12][0] = -0.944164300859965;
   fWeightMatrix0to1[13][0] = 0.0646929877826175;
   fWeightMatrix0to1[14][0] = -0.293171395214128;
   fWeightMatrix0to1[0][1] = 0.807508539626725;
   fWeightMatrix0to1[1][1] = -0.545582083253219;
   fWeightMatrix0to1[2][1] = 1.71912533209386;
   fWeightMatrix0to1[3][1] = 0.0354964273218009;
   fWeightMatrix0to1[4][1] = 0.915321322937942;
   fWeightMatrix0to1[5][1] = -0.190753041067758;
   fWeightMatrix0to1[6][1] = -0.923856550905002;
   fWeightMatrix0to1[7][1] = 0.526260397956953;
   fWeightMatrix0to1[8][1] = 0.342485495268763;
   fWeightMatrix0to1[9][1] = -1.37067117045103;
   fWeightMatrix0to1[10][1] = -1.18578804881605;
   fWeightMatrix0to1[11][1] = 1.13139386516813;
   fWeightMatrix0to1[12][1] = -0.973232035929054;
   fWeightMatrix0to1[13][1] = -1.67282947778023;
   fWeightMatrix0to1[14][1] = 0.357888146435503;
   fWeightMatrix0to1[0][2] = 0.839130122097059;
   fWeightMatrix0to1[1][2] = 1.48330797894858;
   fWeightMatrix0to1[2][2] = -0.394778236791342;
   fWeightMatrix0to1[3][2] = -0.503309051979468;
   fWeightMatrix0to1[4][2] = -0.341309676189657;
   fWeightMatrix0to1[5][2] = -0.118865961715744;
   fWeightMatrix0to1[6][2] = -1.15532256964063;
   fWeightMatrix0to1[7][2] = 1.46599375021032;
   fWeightMatrix0to1[8][2] = -0.804231909643728;
   fWeightMatrix0to1[9][2] = 0.927221138863974;
   fWeightMatrix0to1[10][2] = 1.81003450153143;
   fWeightMatrix0to1[11][2] = 0.30308421920908;
   fWeightMatrix0to1[12][2] = 2.13347592734731;
   fWeightMatrix0to1[13][2] = 1.7204355802393;
   fWeightMatrix0to1[14][2] = -0.414217893443877;
   fWeightMatrix0to1[0][3] = -1.74920526892869;
   fWeightMatrix0to1[1][3] = 1.41346680260871;
   fWeightMatrix0to1[2][3] = 0.232641469852218;
   fWeightMatrix0to1[3][3] = 1.54372493800922;
   fWeightMatrix0to1[4][3] = 0.980598068996154;
   fWeightMatrix0to1[5][3] = 1.24653448111655;
   fWeightMatrix0to1[6][3] = 0.839416195771779;
   fWeightMatrix0to1[7][3] = -0.899626382422078;
   fWeightMatrix0to1[8][3] = 0.620479962320395;
   fWeightMatrix0to1[9][3] = -1.13873811067132;
   fWeightMatrix0to1[10][3] = -1.4358791048617;
   fWeightMatrix0to1[11][3] = -2.3844938805939;
   fWeightMatrix0to1[12][3] = -1.51662435572391;
   fWeightMatrix0to1[13][3] = 1.27032154385495;
   fWeightMatrix0to1[14][3] = 1.49201914674518;
   fWeightMatrix0to1[0][4] = -1.49956589208425;
   fWeightMatrix0to1[1][4] = 0.878550427811311;
   fWeightMatrix0to1[2][4] = -0.194855750491725;
   fWeightMatrix0to1[3][4] = 0.663686190397547;
   fWeightMatrix0to1[4][4] = 1.50972664421304;
   fWeightMatrix0to1[5][4] = -0.758795750630915;
   fWeightMatrix0to1[6][4] = 2.84624831252737;
   fWeightMatrix0to1[7][4] = -0.511737428927026;
   fWeightMatrix0to1[8][4] = 0.295387344170704;
   fWeightMatrix0to1[9][4] = -0.400436807809278;
   fWeightMatrix0to1[10][4] = -1.48096522987403;
   fWeightMatrix0to1[11][4] = -3.54799462088293;
   fWeightMatrix0to1[12][4] = 0.899116602223653;
   fWeightMatrix0to1[13][4] = 0.601081621739042;
   fWeightMatrix0to1[14][4] = 0.760684685151751;
   fWeightMatrix0to1[0][5] = -0.24437133464214;
   fWeightMatrix0to1[1][5] = -1.53233949393692;
   fWeightMatrix0to1[2][5] = -1.84074307032649;
   fWeightMatrix0to1[3][5] = 1.07832466313917;
   fWeightMatrix0to1[4][5] = 0.54758858524642;
   fWeightMatrix0to1[5][5] = 1.82336574001593;
   fWeightMatrix0to1[6][5] = 2.84849867366746;
   fWeightMatrix0to1[7][5] = 1.07955815159787;
   fWeightMatrix0to1[8][5] = -0.738091832005827;
   fWeightMatrix0to1[9][5] = -0.954091605255791;
   fWeightMatrix0to1[10][5] = -0.596634810679931;
   fWeightMatrix0to1[11][5] = 0.634061649405648;
   fWeightMatrix0to1[12][5] = -0.96571152433068;
   fWeightMatrix0to1[13][5] = -2.04755190991707;
   fWeightMatrix0to1[14][5] = -1.99794703370078;
   fWeightMatrix0to1[0][6] = -0.135383666554697;
   fWeightMatrix0to1[1][6] = -0.291427549439617;
   fWeightMatrix0to1[2][6] = 1.46107104516109;
   fWeightMatrix0to1[3][6] = -1.58914076503066;
   fWeightMatrix0to1[4][6] = -0.695236163685876;
   fWeightMatrix0to1[5][6] = 1.8281745416209;
   fWeightMatrix0to1[6][6] = -0.218544287435946;
   fWeightMatrix0to1[7][6] = -1.92068014260899;
   fWeightMatrix0to1[8][6] = -0.828129635571413;
   fWeightMatrix0to1[9][6] = -0.705150219903251;
   fWeightMatrix0to1[10][6] = -2.03709898864066;
   fWeightMatrix0to1[11][6] = -2.31893064256923;
   fWeightMatrix0to1[12][6] = 0.594263848032257;
   fWeightMatrix0to1[13][6] = 1.96538484685525;
   fWeightMatrix0to1[14][6] = -1.25776059942766;
   fWeightMatrix0to1[0][7] = 1.44024260380555;
   fWeightMatrix0to1[1][7] = -0.710953769645879;
   fWeightMatrix0to1[2][7] = -0.639698704047488;
   fWeightMatrix0to1[3][7] = -0.436227738830778;
   fWeightMatrix0to1[4][7] = -0.42355072200758;
   fWeightMatrix0to1[5][7] = -1.36091299779842;
   fWeightMatrix0to1[6][7] = 0.603112894380356;
   fWeightMatrix0to1[7][7] = -0.136787320994391;
   fWeightMatrix0to1[8][7] = 0.862224110816477;
   fWeightMatrix0to1[9][7] = -1.34313922556784;
   fWeightMatrix0to1[10][7] = 1.02477559053052;
   fWeightMatrix0to1[11][7] = -0.25589537856308;
   fWeightMatrix0to1[12][7] = -0.789220723308452;
   fWeightMatrix0to1[13][7] = 0.203471378323274;
   fWeightMatrix0to1[14][7] = -0.477375181648825;
   fWeightMatrix0to1[0][8] = -1.62852874331038;
   fWeightMatrix0to1[1][8] = 0.424323779990377;
   fWeightMatrix0to1[2][8] = -0.22611350331892;
   fWeightMatrix0to1[3][8] = 1.544511726074;
   fWeightMatrix0to1[4][8] = -0.319851192434439;
   fWeightMatrix0to1[5][8] = -0.152185159895116;
   fWeightMatrix0to1[6][8] = -1.33754399410781;
   fWeightMatrix0to1[7][8] = 0.517770946204863;
   fWeightMatrix0to1[8][8] = -1.93855915076084;
   fWeightMatrix0to1[9][8] = 1.37916897377239;
   fWeightMatrix0to1[10][8] = 0.697189842401237;
   fWeightMatrix0to1[11][8] = -1.38220635764586;
   fWeightMatrix0to1[12][8] = 1.18017113159222;
   fWeightMatrix0to1[13][8] = -1.38987941749787;
   fWeightMatrix0to1[14][8] = -0.429884483332089;
   fWeightMatrix0to1[0][9] = 1.06514026467097;
   fWeightMatrix0to1[1][9] = 1.46605575686507;
   fWeightMatrix0to1[2][9] = -1.96009003548985;
   fWeightMatrix0to1[3][9] = 0.260199953670524;
   fWeightMatrix0to1[4][9] = 1.44407992643001;
   fWeightMatrix0to1[5][9] = 1.84288259021232;
   fWeightMatrix0to1[6][9] = 1.3002517634762;
   fWeightMatrix0to1[7][9] = -1.71349193354636;
   fWeightMatrix0to1[8][9] = 0.0141261012291824;
   fWeightMatrix0to1[9][9] = -1.57499550884586;
   fWeightMatrix0to1[10][9] = 1.39559057177909;
   fWeightMatrix0to1[11][9] = 0.17127010623393;
   fWeightMatrix0to1[12][9] = -0.619666470794739;
   fWeightMatrix0to1[13][9] = -0.165198244073022;
   fWeightMatrix0to1[14][9] = 0.847609427987292;
   fWeightMatrix0to1[0][10] = -1.52637394410784;
   fWeightMatrix0to1[1][10] = 0.501058203853529;
   fWeightMatrix0to1[2][10] = 1.62724581457702;
   fWeightMatrix0to1[3][10] = -0.882682315079127;
   fWeightMatrix0to1[4][10] = -0.234418313789628;
   fWeightMatrix0to1[5][10] = 0.423787778927607;
   fWeightMatrix0to1[6][10] = -0.0810605121680117;
   fWeightMatrix0to1[7][10] = 0.32127128709256;
   fWeightMatrix0to1[8][10] = 0.74912680751583;
   fWeightMatrix0to1[9][10] = -1.21280803523413;
   fWeightMatrix0to1[10][10] = 1.62157993557009;
   fWeightMatrix0to1[11][10] = 1.92598877563915;
   fWeightMatrix0to1[12][10] = 0.466101513630084;
   fWeightMatrix0to1[13][10] = 0.727621676138043;
   fWeightMatrix0to1[14][10] = -0.0933682376908897;
   fWeightMatrix0to1[0][11] = -0.488483309000032;
   fWeightMatrix0to1[1][11] = -0.682850808715115;
   fWeightMatrix0to1[2][11] = 0.990714930246317;
   fWeightMatrix0to1[3][11] = -0.45518188896854;
   fWeightMatrix0to1[4][11] = -0.363389564557149;
   fWeightMatrix0to1[5][11] = 1.59738074561381;
   fWeightMatrix0to1[6][11] = 0.812514887045817;
   fWeightMatrix0to1[7][11] = -0.184335884315261;
   fWeightMatrix0to1[8][11] = 1.53308210318866;
   fWeightMatrix0to1[9][11] = 1.77244732386217;
   fWeightMatrix0to1[10][11] = -2.37034040718231;
   fWeightMatrix0to1[11][11] = 1.17770413023447;
   fWeightMatrix0to1[12][11] = -0.100449328267395;
   fWeightMatrix0to1[13][11] = -0.116092221898641;
   fWeightMatrix0to1[14][11] = -2.53898545007669;
   fWeightMatrix0to1[0][12] = -1.6141397236429;
   fWeightMatrix0to1[1][12] = 1.50144971228256;
   fWeightMatrix0to1[2][12] = 1.98114826352926;
   fWeightMatrix0to1[3][12] = -1.76880027608074;
   fWeightMatrix0to1[4][12] = -0.698539399059914;
   fWeightMatrix0to1[5][12] = -0.795416793521647;
   fWeightMatrix0to1[6][12] = 1.97435336005903;
   fWeightMatrix0to1[7][12] = 2.45646593678066;
   fWeightMatrix0to1[8][12] = -0.909868412863525;
   fWeightMatrix0to1[9][12] = 0.181054685070169;
   fWeightMatrix0to1[10][12] = -1.39156061260808;
   fWeightMatrix0to1[11][12] = -0.396932303235418;
   fWeightMatrix0to1[12][12] = 1.62852145217245;
   fWeightMatrix0to1[13][12] = 0.938647555483923;
   fWeightMatrix0to1[14][12] = 0.651180035113366;
   fWeightMatrix0to1[0][13] = -0.644991939432754;
   fWeightMatrix0to1[1][13] = -2.0107860122151;
   fWeightMatrix0to1[2][13] = 1.10223493640808;
   fWeightMatrix0to1[3][13] = -0.0429888551427021;
   fWeightMatrix0to1[4][13] = -2.13513179274628;
   fWeightMatrix0to1[5][13] = -0.500020779667916;
   fWeightMatrix0to1[6][13] = 0.734299101911165;
   fWeightMatrix0to1[7][13] = -0.0679024267219601;
   fWeightMatrix0to1[8][13] = -1.67083362608414;
   fWeightMatrix0to1[9][13] = 1.3952028012782;
   fWeightMatrix0to1[10][13] = 1.60266712218281;
   fWeightMatrix0to1[11][13] = -1.6085977490043;
   fWeightMatrix0to1[12][13] = 0.042735874925985;
   fWeightMatrix0to1[13][13] = 1.77460519545418;
   fWeightMatrix0to1[14][13] = 1.28205844903014;
   fWeightMatrix0to1[0][14] = 0.554520042398493;
   fWeightMatrix0to1[1][14] = -0.552393334442161;
   fWeightMatrix0to1[2][14] = -2.10666494105693;
   fWeightMatrix0to1[3][14] = -0.90915008184688;
   fWeightMatrix0to1[4][14] = 2.15472284919206;
   fWeightMatrix0to1[5][14] = 1.59934119055874;
   fWeightMatrix0to1[6][14] = -1.30594953594316;
   fWeightMatrix0to1[7][14] = -0.585150947524171;
   fWeightMatrix0to1[8][14] = 2.64756667066014;
   fWeightMatrix0to1[9][14] = -2.55157532173151;
   fWeightMatrix0to1[10][14] = -0.975595874067813;
   fWeightMatrix0to1[11][14] = 0.609007821397092;
   fWeightMatrix0to1[12][14] = -1.57975273683019;
   fWeightMatrix0to1[13][14] = 1.53505314270728;
   fWeightMatrix0to1[14][14] = 1.62264295895388;
   // weight matrix from layer 1 to 2
   fWeightMatrix1to2[0][0] = -0.991218683965334;
   fWeightMatrix1to2[1][0] = 0.489817629922817;
   fWeightMatrix1to2[2][0] = -0.113185930009977;
   fWeightMatrix1to2[3][0] = -1.31860985743433;
   fWeightMatrix1to2[4][0] = -1.19281252973237;
   fWeightMatrix1to2[5][0] = 1.09464887840677;
   fWeightMatrix1to2[6][0] = -0.202020018049501;
   fWeightMatrix1to2[7][0] = 1.21414523852782;
   fWeightMatrix1to2[8][0] = -1.41933675287312;
   fWeightMatrix1to2[9][0] = 1.39448311399473;
   fWeightMatrix1to2[10][0] = -1.42011987638603;
   fWeightMatrix1to2[11][0] = 0.872029705439989;
   fWeightMatrix1to2[12][0] = 0.259051031981416;
   fWeightMatrix1to2[13][0] = -1.71965121820034;
   fWeightMatrix1to2[0][1] = -1.54152156757142;
   fWeightMatrix1to2[1][1] = -1.57602607493447;
   fWeightMatrix1to2[2][1] = -0.430693796038448;
   fWeightMatrix1to2[3][1] = -2.29369599298624;
   fWeightMatrix1to2[4][1] = -1.43566935571931;
   fWeightMatrix1to2[5][1] = -1.96524855226365;
   fWeightMatrix1to2[6][1] = 0.250385818784325;
   fWeightMatrix1to2[7][1] = -1.1365844980431;
   fWeightMatrix1to2[8][1] = -1.34295260796492;
   fWeightMatrix1to2[9][1] = 1.63974188385463;
   fWeightMatrix1to2[10][1] = -1.06720376283249;
   fWeightMatrix1to2[11][1] = 0.129221039671888;
   fWeightMatrix1to2[12][1] = -1.1952972481646;
   fWeightMatrix1to2[13][1] = 0.478319468544151;
   fWeightMatrix1to2[0][2] = 1.64025598632046;
   fWeightMatrix1to2[1][2] = 1.62096591973769;
   fWeightMatrix1to2[2][2] = -0.900513165876419;
   fWeightMatrix1to2[3][2] = -1.89888701182745;
   fWeightMatrix1to2[4][2] = -1.00449109724661;
   fWeightMatrix1to2[5][2] = -0.950206769822212;
   fWeightMatrix1to2[6][2] = -1.40527994749119;
   fWeightMatrix1to2[7][2] = 0.1325121292051;
   fWeightMatrix1to2[8][2] = 0.54979798797509;
   fWeightMatrix1to2[9][2] = 2.05982673133136;
   fWeightMatrix1to2[10][2] = -0.695148085100221;
   fWeightMatrix1to2[11][2] = 0.211254099732979;
   fWeightMatrix1to2[12][2] = -0.630213413168957;
   fWeightMatrix1to2[13][2] = -1.7310121931148;
   fWeightMatrix1to2[0][3] = 1.23854402935357;
   fWeightMatrix1to2[1][3] = 1.39159579726123;
   fWeightMatrix1to2[2][3] = -0.915830067574581;
   fWeightMatrix1to2[3][3] = -1.46776016282809;
   fWeightMatrix1to2[4][3] = 0.912139342312633;
   fWeightMatrix1to2[5][3] = 0.638226561207884;
   fWeightMatrix1to2[6][3] = 0.640924929644982;
   fWeightMatrix1to2[7][3] = -0.770740804967333;
   fWeightMatrix1to2[8][3] = -0.14855378619958;
   fWeightMatrix1to2[9][3] = 1.74643726637757;
   fWeightMatrix1to2[10][3] = 0.623982337101103;
   fWeightMatrix1to2[11][3] = 1.15720572477861;
   fWeightMatrix1to2[12][3] = -0.75396656243532;
   fWeightMatrix1to2[13][3] = 0.2953323650286;
   fWeightMatrix1to2[0][4] = -0.277933984927298;
   fWeightMatrix1to2[1][4] = -1.57535409108562;
   fWeightMatrix1to2[2][4] = -0.519032477279481;
   fWeightMatrix1to2[3][4] = -1.34184615419427;
   fWeightMatrix1to2[4][4] = -1.35719349071624;
   fWeightMatrix1to2[5][4] = -1.57721863651391;
   fWeightMatrix1to2[6][4] = 1.53612351053596;
   fWeightMatrix1to2[7][4] = -1.72961914466311;
   fWeightMatrix1to2[8][4] = 1.45740877123415;
   fWeightMatrix1to2[9][4] = -1.58108147100827;
   fWeightMatrix1to2[10][4] = 1.29847951592259;
   fWeightMatrix1to2[11][4] = -1.04116122665064;
   fWeightMatrix1to2[12][4] = 0.60633204374832;
   fWeightMatrix1to2[13][4] = 0.634118918816329;
   fWeightMatrix1to2[0][5] = -1.65996296715342;
   fWeightMatrix1to2[1][5] = 0.0152274785566215;
   fWeightMatrix1to2[2][5] = 0.621064740321214;
   fWeightMatrix1to2[3][5] = -1.54685506748367;
   fWeightMatrix1to2[4][5] = -1.59759970691399;
   fWeightMatrix1to2[5][5] = -1.64415778815371;
   fWeightMatrix1to2[6][5] = -1.05255828324598;
   fWeightMatrix1to2[7][5] = 2.08172294946902;
   fWeightMatrix1to2[8][5] = -0.784863629634549;
   fWeightMatrix1to2[9][5] = -0.025551094541574;
   fWeightMatrix1to2[10][5] = -0.751509598689174;
   fWeightMatrix1to2[11][5] = -1.20360893622218;
   fWeightMatrix1to2[12][5] = -1.56584400905208;
   fWeightMatrix1to2[13][5] = -1.50013649066596;
   fWeightMatrix1to2[0][6] = -1.99994310018492;
   fWeightMatrix1to2[1][6] = 2.4176697696421;
   fWeightMatrix1to2[2][6] = -1.45287339330777;
   fWeightMatrix1to2[3][6] = -1.41342518078978;
   fWeightMatrix1to2[4][6] = 2.01833756096802;
   fWeightMatrix1to2[5][6] = 0.19342829855943;
   fWeightMatrix1to2[6][6] = -0.232692609557541;
   fWeightMatrix1to2[7][6] = 1.45693279782748;
   fWeightMatrix1to2[8][6] = -1.4708701442981;
   fWeightMatrix1to2[9][6] = 1.39840476249416;
   fWeightMatrix1to2[10][6] = 0.620916187144765;
   fWeightMatrix1to2[11][6] = -1.44113242660921;
   fWeightMatrix1to2[12][6] = -1.98024710057345;
   fWeightMatrix1to2[13][6] = -0.0677846273120585;
   fWeightMatrix1to2[0][7] = -1.36876597239853;
   fWeightMatrix1to2[1][7] = 0.707460081120081;
   fWeightMatrix1to2[2][7] = 1.91137404334917;
   fWeightMatrix1to2[3][7] = 0.939049211072504;
   fWeightMatrix1to2[4][7] = 1.63398030168901;
   fWeightMatrix1to2[5][7] = -1.41937158847158;
   fWeightMatrix1to2[6][7] = 1.25572857365121;
   fWeightMatrix1to2[7][7] = -2.18762198819893;
   fWeightMatrix1to2[8][7] = 0.822244213506013;
   fWeightMatrix1to2[9][7] = -1.42585498440257;
   fWeightMatrix1to2[10][7] = -2.04349175458229;
   fWeightMatrix1to2[11][7] = -0.0562989168543816;
   fWeightMatrix1to2[12][7] = 1.09522954327015;
   fWeightMatrix1to2[13][7] = 0.582633027302213;
   fWeightMatrix1to2[0][8] = 1.15993836944595;
   fWeightMatrix1to2[1][8] = -0.018297848958305;
   fWeightMatrix1to2[2][8] = -0.104423597761152;
   fWeightMatrix1to2[3][8] = -0.456923748055944;
   fWeightMatrix1to2[4][8] = 0.111047040641786;
   fWeightMatrix1to2[5][8] = 1.38791520591004;
   fWeightMatrix1to2[6][8] = -1.54538006727382;
   fWeightMatrix1to2[7][8] = 0.195424005816313;
   fWeightMatrix1to2[8][8] = -1.28823494534504;
   fWeightMatrix1to2[9][8] = -0.683518902769874;
   fWeightMatrix1to2[10][8] = 0.121525670413503;
   fWeightMatrix1to2[11][8] = 0.225432502309356;
   fWeightMatrix1to2[12][8] = -1.03478746347446;
   fWeightMatrix1to2[13][8] = 0.930974942485858;
   fWeightMatrix1to2[0][9] = 1.3423813704514;
   fWeightMatrix1to2[1][9] = 0.95838590044848;
   fWeightMatrix1to2[2][9] = -0.19001202411316;
   fWeightMatrix1to2[3][9] = -1.26032760276956;
   fWeightMatrix1to2[4][9] = -1.28418382359517;
   fWeightMatrix1to2[5][9] = -1.72111734757663;
   fWeightMatrix1to2[6][9] = 1.21412268176022;
   fWeightMatrix1to2[7][9] = -0.569319629447188;
   fWeightMatrix1to2[8][9] = -1.15856021656392;
   fWeightMatrix1to2[9][9] = 0.684699190028707;
   fWeightMatrix1to2[10][9] = -1.64672456159964;
   fWeightMatrix1to2[11][9] = -1.18208511629241;
   fWeightMatrix1to2[12][9] = -1.61213179807417;
   fWeightMatrix1to2[13][9] = 1.09059018986528;
   fWeightMatrix1to2[0][10] = -0.976614373217126;
   fWeightMatrix1to2[1][10] = -2.19392881976348;
   fWeightMatrix1to2[2][10] = -0.510783536620711;
   fWeightMatrix1to2[3][10] = -0.973186465992699;
   fWeightMatrix1to2[4][10] = -1.48869682990838;
   fWeightMatrix1to2[5][10] = 1.64032633056396;
   fWeightMatrix1to2[6][10] = -1.34350241613013;
   fWeightMatrix1to2[7][10] = -0.852177263592857;
   fWeightMatrix1to2[8][10] = 1.62088977768159;
   fWeightMatrix1to2[9][10] = 0.42616993361655;
   fWeightMatrix1to2[10][10] = 0.283202588228355;
   fWeightMatrix1to2[11][10] = 0.280187007251692;
   fWeightMatrix1to2[12][10] = 1.82685672558222;
   fWeightMatrix1to2[13][10] = 1.6909194856242;
   fWeightMatrix1to2[0][11] = 0.242260584089665;
   fWeightMatrix1to2[1][11] = -1.93940840876171;
   fWeightMatrix1to2[2][11] = -0.103110423874957;
   fWeightMatrix1to2[3][11] = -1.65599118419444;
   fWeightMatrix1to2[4][11] = 1.77433915361428;
   fWeightMatrix1to2[5][11] = 1.4418200727628;
   fWeightMatrix1to2[6][11] = -0.164330912524102;
   fWeightMatrix1to2[7][11] = 1.05970711458388;
   fWeightMatrix1to2[8][11] = 0.932958160484914;
   fWeightMatrix1to2[9][11] = 1.39640714853322;
   fWeightMatrix1to2[10][11] = -1.20002656760037;
   fWeightMatrix1to2[11][11] = 1.6269886313484;
   fWeightMatrix1to2[12][11] = 0.989895844793361;
   fWeightMatrix1to2[13][11] = -1.43651054822583;
   fWeightMatrix1to2[0][12] = -0.420979814966094;
   fWeightMatrix1to2[1][12] = -1.00847317911016;
   fWeightMatrix1to2[2][12] = 0.875499148455096;
   fWeightMatrix1to2[3][12] = 0.088660318546671;
   fWeightMatrix1to2[4][12] = 1.11908004361831;
   fWeightMatrix1to2[5][12] = 1.56644733411658;
   fWeightMatrix1to2[6][12] = -0.224169036624771;
   fWeightMatrix1to2[7][12] = 1.70448135890277;
   fWeightMatrix1to2[8][12] = 1.78321875025783;
   fWeightMatrix1to2[9][12] = 0.447569779339168;
   fWeightMatrix1to2[10][12] = -1.3933171030604;
   fWeightMatrix1to2[11][12] = 1.64745348987668;
   fWeightMatrix1to2[12][12] = -1.88429121974821;
   fWeightMatrix1to2[13][12] = 0.573040864341796;
   fWeightMatrix1to2[0][13] = 1.63605551627491;
   fWeightMatrix1to2[1][13] = 0.0977433238711466;
   fWeightMatrix1to2[2][13] = -0.813858063091366;
   fWeightMatrix1to2[3][13] = 0.29879349741858;
   fWeightMatrix1to2[4][13] = -1.74155431018903;
   fWeightMatrix1to2[5][13] = 0.587325598784082;
   fWeightMatrix1to2[6][13] = -1.96370465274127;
   fWeightMatrix1to2[7][13] = 0.491118200123242;
   fWeightMatrix1to2[8][13] = -0.409773907476802;
   fWeightMatrix1to2[9][13] = 1.45181615321499;
   fWeightMatrix1to2[10][13] = 1.21657207732114;
   fWeightMatrix1to2[11][13] = 1.60209934951856;
   fWeightMatrix1to2[12][13] = -1.06852202803484;
   fWeightMatrix1to2[13][13] = -0.51260398113638;
   fWeightMatrix1to2[0][14] = 0.558136409170114;
   fWeightMatrix1to2[1][14] = 1.7955425649597;
   fWeightMatrix1to2[2][14] = -1.7791880057102;
   fWeightMatrix1to2[3][14] = -1.69319310509847;
   fWeightMatrix1to2[4][14] = -0.569223205420075;
   fWeightMatrix1to2[5][14] = -2.58448683583696;
   fWeightMatrix1to2[6][14] = -1.43543866284998;
   fWeightMatrix1to2[7][14] = -1.66762383279685;
   fWeightMatrix1to2[8][14] = 1.04942231036744;
   fWeightMatrix1to2[9][14] = 0.303241003142562;
   fWeightMatrix1to2[10][14] = -1.93493310220265;
   fWeightMatrix1to2[11][14] = -1.7759961260815;
   fWeightMatrix1to2[12][14] = 0.134537082431005;
   fWeightMatrix1to2[13][14] = 2.14831602641945;
   fWeightMatrix1to2[0][15] = 2.08960245199523;
   fWeightMatrix1to2[1][15] = 1.02916033652023;
   fWeightMatrix1to2[2][15] = -0.630039524229929;
   fWeightMatrix1to2[3][15] = -1.52210744779581;
   fWeightMatrix1to2[4][15] = -0.24518735986727;
   fWeightMatrix1to2[5][15] = -1.23304542322196;
   fWeightMatrix1to2[6][15] = -1.81600857918626;
   fWeightMatrix1to2[7][15] = -0.459139862151164;
   fWeightMatrix1to2[8][15] = -0.255137497527883;
   fWeightMatrix1to2[9][15] = -1.77369173976673;
   fWeightMatrix1to2[10][15] = 1.92707700027423;
   fWeightMatrix1to2[11][15] = 1.26805166430019;
   fWeightMatrix1to2[12][15] = 0.291921953977862;
   fWeightMatrix1to2[13][15] = -0.815345613884324;
   // weight matrix from layer 2 to 3
   fWeightMatrix2to3[0][0] = -0.145545022553234;
   fWeightMatrix2to3[0][1] = 0.449107409613857;
   fWeightMatrix2to3[0][2] = -0.0333490897997129;
   fWeightMatrix2to3[0][3] = -0.09814448114205;
   fWeightMatrix2to3[0][4] = 1.00143352777802;
   fWeightMatrix2to3[0][5] = 1.0855251282723;
   fWeightMatrix2to3[0][6] = -0.0928376096936049;
   fWeightMatrix2to3[0][7] = 1.1924834888977;
   fWeightMatrix2to3[0][8] = -0.108935665361935;
   fWeightMatrix2to3[0][9] = 1.3112578014864;
   fWeightMatrix2to3[0][10] = 1.6852512036517;
   fWeightMatrix2to3[0][11] = 0.28952361910908;
   fWeightMatrix2to3[0][12] = -0.713605890242556;
   fWeightMatrix2to3[0][13] = 1.21962159509678;
   fWeightMatrix2to3[0][14] = -0.49249465877644;
}

inline double ReadMLP5_EC::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   if (inputValues.size() != (unsigned int)fLayerSize[0]-1) {
      std::cout << "Input vector needs to be of size " << fLayerSize[0]-1 << std::endl;
      return 0;
   }

   for (int l=0; l<fLayers; l++)
      for (int i=0; i<fLayerSize[l]; i++) fWeights[l][i]=0;

   for (int l=0; l<fLayers-1; l++)
      fWeights[l][fLayerSize[l]-1]=1;

   for (int i=0; i<fLayerSize[0]-1; i++)
      fWeights[0][i]=inputValues[i];

   // layer 0 to 1
   for (int o=0; o<fLayerSize[1]-1; o++) {
      for (int i=0; i<fLayerSize[0]; i++) {
         double inputVal = fWeightMatrix0to1[o][i] * fWeights[0][i];
         fWeights[1][o] += inputVal;
      }
      fWeights[1][o] = ActivationFnc(fWeights[1][o]);
   }
   // layer 1 to 2
   for (int o=0; o<fLayerSize[2]-1; o++) {
      for (int i=0; i<fLayerSize[1]; i++) {
         double inputVal = fWeightMatrix1to2[o][i] * fWeights[1][i];
         fWeights[2][o] += inputVal;
      }
      fWeights[2][o] = ActivationFnc(fWeights[2][o]);
   }
   // layer 2 to 3
   for (int o=0; o<fLayerSize[3]; o++) {
      for (int i=0; i<fLayerSize[2]; i++) {
         double inputVal = fWeightMatrix2to3[o][i] * fWeights[2][i];
         fWeights[3][o] += inputVal;
      }
   }

   return fWeights[3][0];
}

double ReadMLP5_EC::ActivationFnc(double x) const
{
   // hyperbolic tan
   return tanh(x);
}
 
   
// Clean up
inline void ReadMLP5_EC::Clear() 
{
   // nothing to clear
}
inline double ReadMLP5_EC::GetMvaValue( const std::vector<double>& inputValues ) const
{
   // classifier response value
   double retval = 0;

   // classifier response, sanity check first
   if (!fStatusIsClean) {
      std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
      retval = 0;
   }
   else {
      if (IsNormalised()) {
         // normalise variables
         std::vector<double> iV;
         int ivar = 0;
         for (std::vector<double>::const_iterator varIt = inputValues.begin();
              varIt != inputValues.end(); varIt++, ivar++) {
            iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
         }
         retval = GetMvaValue__( iV );
      }
      else {
         retval = GetMvaValue__( inputValues );
      }
   }

   return retval;
}

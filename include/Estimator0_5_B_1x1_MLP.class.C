// Class: ReadMLP0_5_B_1x1
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : MLP::MLP
TMVA Release   : 3.9.6         [198918]
ROOT Release   : 5.16/00       [331776]
Creator        : reinhard
Date           : Mon Aug 10 10:50:37 2009
Host           : Linux polui02.in2p3.fr 2.6.9-67.0.4.ELsmp #1 SMP Thu Jan 31 16:30:09 CST 2008 i686 i686 i386 GNU/Linux
Dir            : /grid_mnt/data2__polgrid/llr/ilc/reinhard/ILCSoft/TMVA/macros
Training events: 13077


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
Normalise: "True" [Normalise input variables]
V: "False" [Verbose mode]
H: "True" [Print classifier-specific help message]
NCycles: "500" [Number of training cycles]
HiddenLayers: "N+1,N" [Specification of hidden layer architecture (N stands for number of variables; any integers may also be used)]
NeuronType: "tanh" [Neuron activation function type]
TestRate: "5" [Test for overtraining performed at each #th epochs]
# Default:
D: "False" [Use-decorrelated-variables flag (depreciated)]
VarTransform: "None" [Variable transformation method]
VarTransformType: "Signal" [Use signal or background events to derive for variable transformation (the transformation is applied on both types of, course)]
NbinsMVAPdf: "60" [Number of bins used for the PDFs of classifier outputs]
NsmoothMVAPdf: "2" [Number of smoothing iterations for classifier PDFs]
VerboseLevel: "Default" [Verbosity level]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
TxtWeightFilesOnly: "True" [If True: write all training results (weights) as text files (False: some are written in ROOT format)]
NeuronInputType: "sum" [Neuron input function type]
TrainingMethod: "BP" [Train with Back-Propagation (BP - default) or Genetic Algorithm (GA - slower and worse)]
LearningRate: "0.02" [ANN learning rate parameter]
DecayRate: "0.01" [Decay rate for learning parameter]
BPMode: "sequential" [Back-propagation learning mode: sequential or batch]
BatchSize: "-1" [Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 13
ClusterParameters.start       ClusterParameters.start           'F'    [0,24.8363952637]
ClusterParameters.end         ClusterParameters.end             'F'    [1.01829111576,34.6617012024]
ClusterParameters.depth       ClusterParameters.depth           'F'    [0,28.333776474]
ClusterParameters.E1C/ClusterParameters.Etot_g   ClusterParameters.E1C_D_ClusterParameters.Etot_g     'F'    [0,1]
ClusterParameters.E4C/ClusterParameters.Etot_g   ClusterParameters.E4C_D_ClusterParameters.Etot_g     'F'    [0.02302239649,1]
ClusterParameters.E9C/ClusterParameters.Etot_g   ClusterParameters.E9C_D_ClusterParameters.Etot_g     'F'    [0.322807371616,1]
ClusterParameters.dirErr      ClusterParameters.dirErr          'F'    [0.00045669550309,0.999998450279]
ClusterParameters.seedDirErr  ClusterParameters.seedDirErr      'F'    [-9.4867842563e-05,0.999999523163]
ClusterParameters.Width       ClusterParameters.Width           'F'    [0,33.6999015808]
ClusterParameters.Eccentricity ClusterParameters.Eccentricity     'F'    [0,0.958670973778]
ClusterParameters.nHits       ClusterParameters.nHits           'F'    [5,32]
ClusterParameters.Volume      ClusterParameters.Volume          'F'    [0,2395607]
ClusterParameters.depth-ClusterParameters.start   ClusterParameters.depth_M_ClusterParameters.start     'F'    [-9.64256954193,20.0077590942]


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;
};

#endif

class ReadMLP0_5_B_1x1 : public IClassifierReader {

 public:

   // constructor
   ReadMLP0_5_B_1x1( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadMLP0_5_B_1x1" ),
        fStatusIsClean( true ),
        fNvars( 13 ),
        fIsNormalised( true )
   {      
      // the training input variables
      const char* inputVars[] = { "ClusterParameters.start", "ClusterParameters.end", "ClusterParameters.depth", "ClusterParameters.E1C/ClusterParameters.Etot_g", "ClusterParameters.E4C/ClusterParameters.Etot_g", "ClusterParameters.E9C/ClusterParameters.Etot_g", "ClusterParameters.dirErr", "ClusterParameters.seedDirErr", "ClusterParameters.Width", "ClusterParameters.Eccentricity", "ClusterParameters.nHits", "ClusterParameters.Volume", "ClusterParameters.depth-ClusterParameters.start" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 24.8363952636719;
      fVmin[1] = 1.0182911157608;
      fVmax[1] = 34.6617012023926;
      fVmin[2] = 0;
      fVmax[2] = 28.333776473999;
      fVmin[3] = 0;
      fVmax[3] = 1;
      fVmin[4] = 0.0230223964899778;
      fVmax[4] = 1;
      fVmin[5] = 0.322807371616364;
      fVmax[5] = 1;
      fVmin[6] = 0.000456695503089577;
      fVmax[6] = 0.999998450279236;
      fVmin[7] = -9.48678425629623e-05;
      fVmax[7] = 0.999999523162842;
      fVmin[8] = 0;
      fVmax[8] = 33.6999015808105;
      fVmin[9] = 0;
      fVmax[9] = 0.958670973777771;
      fVmin[10] = 5;
      fVmax[10] = 32;
      fVmin[11] = 0;
      fVmax[11] = 2395607;
      fVmin[12] = -9.64256954193115;
      fVmax[12] = 20.0077590942383;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';
      fType[10] = 'F';
      fType[11] = 'F';
      fType[12] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadMLP0_5_B_1x1() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;
   bool fStatusIsClean;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[13];
   double fVmax[13];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[13];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)

   double ActivationFnc(double x) const;

   int fLayers;
   int fLayerSize[4];
   double fWeightMatrix0to1[15][14];   // weight matrix from layer 0 to 1
   double fWeightMatrix1to2[14][15];   // weight matrix from layer 1 to 2
   double fWeightMatrix2to3[1][14];   // weight matrix from layer 2 to 3

   double * fWeights[4];
};

inline void ReadMLP0_5_B_1x1::Initialize()
{
   // build network structure
   fLayers = 4;
   fLayerSize[0] = 14; fWeights[0] = new double[14]; 
   fLayerSize[1] = 15; fWeights[1] = new double[15]; 
   fLayerSize[2] = 14; fWeights[2] = new double[14]; 
   fLayerSize[3] = 1; fWeights[3] = new double[1]; 
   // weight matrix from layer 0 to 1
   fWeightMatrix0to1[0][0] = -0.0671094338181801;
   fWeightMatrix0to1[1][0] = 2.00420969638006;
   fWeightMatrix0to1[2][0] = 0.999318326602646;
   fWeightMatrix0to1[3][0] = 2.16350763860642;
   fWeightMatrix0to1[4][0] = -2.36191014623911;
   fWeightMatrix0to1[5][0] = -1.7938269637222;
   fWeightMatrix0to1[6][0] = -0.415609624278241;
   fWeightMatrix0to1[7][0] = 2.12998897165705;
   fWeightMatrix0to1[8][0] = -1.76305826229024;
   fWeightMatrix0to1[9][0] = 0.557166022998776;
   fWeightMatrix0to1[10][0] = -1.82700851308477;
   fWeightMatrix0to1[11][0] = -0.614013145702682;
   fWeightMatrix0to1[12][0] = -1.32072523756524;
   fWeightMatrix0to1[13][0] = -0.240608542087776;
   fWeightMatrix0to1[0][1] = -0.712689235080503;
   fWeightMatrix0to1[1][1] = 0.676040937272391;
   fWeightMatrix0to1[2][1] = -0.54352985501925;
   fWeightMatrix0to1[3][1] = 1.29485250220286;
   fWeightMatrix0to1[4][1] = 0.00842951517991479;
   fWeightMatrix0to1[5][1] = 1.16002080825555;
   fWeightMatrix0to1[6][1] = -0.277369148456402;
   fWeightMatrix0to1[7][1] = -0.700999519764148;
   fWeightMatrix0to1[8][1] = 0.68414345751934;
   fWeightMatrix0to1[9][1] = 0.868923647819683;
   fWeightMatrix0to1[10][1] = -1.3686051329791;
   fWeightMatrix0to1[11][1] = 0.925272665144638;
   fWeightMatrix0to1[12][1] = 0.317973150921445;
   fWeightMatrix0to1[13][1] = 0.409461032992552;
   fWeightMatrix0to1[0][2] = -1.6524163907044;
   fWeightMatrix0to1[1][2] = 0.146651206347283;
   fWeightMatrix0to1[2][2] = 0.540896712961382;
   fWeightMatrix0to1[3][2] = 2.00494960821047;
   fWeightMatrix0to1[4][2] = 0.368832876312571;
   fWeightMatrix0to1[5][2] = -0.338415327597269;
   fWeightMatrix0to1[6][2] = 0.32050298815005;
   fWeightMatrix0to1[7][2] = 0.0340600853544644;
   fWeightMatrix0to1[8][2] = -1.63041613273264;
   fWeightMatrix0to1[9][2] = 1.78896231400633;
   fWeightMatrix0to1[10][2] = -1.3545338828397;
   fWeightMatrix0to1[11][2] = 1.82297890110622;
   fWeightMatrix0to1[12][2] = 2.35529428551539;
   fWeightMatrix0to1[13][2] = 0.801697633089983;
   fWeightMatrix0to1[0][3] = 1.44686849923175;
   fWeightMatrix0to1[1][3] = 1.22787341083514;
   fWeightMatrix0to1[2][3] = -0.170378536326609;
   fWeightMatrix0to1[3][3] = -2.32108143030654;
   fWeightMatrix0to1[4][3] = -0.256949867642497;
   fWeightMatrix0to1[5][3] = 0.091036775085408;
   fWeightMatrix0to1[6][3] = 1.79260969367083;
   fWeightMatrix0to1[7][3] = 1.45649703548762;
   fWeightMatrix0to1[8][3] = 1.38655657405124;
   fWeightMatrix0to1[9][3] = -0.0226935949286933;
   fWeightMatrix0to1[10][3] = -1.7633048832462;
   fWeightMatrix0to1[11][3] = 0.421997401203705;
   fWeightMatrix0to1[12][3] = -0.810601523541546;
   fWeightMatrix0to1[13][3] = -0.147668786579091;
   fWeightMatrix0to1[0][4] = -2.0143837802406;
   fWeightMatrix0to1[1][4] = -1.75286046727693;
   fWeightMatrix0to1[2][4] = 1.18467342830944;
   fWeightMatrix0to1[3][4] = 0.444529460169229;
   fWeightMatrix0to1[4][4] = -0.95197505838128;
   fWeightMatrix0to1[5][4] = 0.525715156977831;
   fWeightMatrix0to1[6][4] = -0.234055513673134;
   fWeightMatrix0to1[7][4] = 0.287595192041552;
   fWeightMatrix0to1[8][4] = 1.52334187834015;
   fWeightMatrix0to1[9][4] = -0.350076953089231;
   fWeightMatrix0to1[10][4] = 0.160999198878129;
   fWeightMatrix0to1[11][4] = -1.4543528548207;
   fWeightMatrix0to1[12][4] = -0.810916145611149;
   fWeightMatrix0to1[13][4] = 0.585155773181194;
   fWeightMatrix0to1[0][5] = -1.16316459651194;
   fWeightMatrix0to1[1][5] = -1.4173963145194;
   fWeightMatrix0to1[2][5] = 0.0997953942821702;
   fWeightMatrix0to1[3][5] = 0.808523613065365;
   fWeightMatrix0to1[4][5] = 1.81096047948655;
   fWeightMatrix0to1[5][5] = -0.0942293484228062;
   fWeightMatrix0to1[6][5] = -1.99570698548892;
   fWeightMatrix0to1[7][5] = -2.46366875015296;
   fWeightMatrix0to1[8][5] = 0.918424733192076;
   fWeightMatrix0to1[9][5] = -0.6624356546394;
   fWeightMatrix0to1[10][5] = 2.00344608550326;
   fWeightMatrix0to1[11][5] = 0.712953237567811;
   fWeightMatrix0to1[12][5] = -0.405173714234266;
   fWeightMatrix0to1[13][5] = -0.818625391651725;
   fWeightMatrix0to1[0][6] = -2.35869069541322;
   fWeightMatrix0to1[1][6] = -0.21463334253323;
   fWeightMatrix0to1[2][6] = -3.89346821962918;
   fWeightMatrix0to1[3][6] = -0.500266678912455;
   fWeightMatrix0to1[4][6] = -6.52371375120476;
   fWeightMatrix0to1[5][6] = -1.43532014638725;
   fWeightMatrix0to1[6][6] = -0.317119053716356;
   fWeightMatrix0to1[7][6] = -0.376542939195114;
   fWeightMatrix0to1[8][6] = 1.37411580031308;
   fWeightMatrix0to1[9][6] = -0.433240193056584;
   fWeightMatrix0to1[10][6] = -0.893126834700706;
   fWeightMatrix0to1[11][6] = 0.523994195849316;
   fWeightMatrix0to1[12][6] = -1.25994401055653;
   fWeightMatrix0to1[13][6] = 0.489219535954735;
   fWeightMatrix0to1[0][7] = -0.488634598736805;
   fWeightMatrix0to1[1][7] = 0.0940635900622791;
   fWeightMatrix0to1[2][7] = -0.356916160220953;
   fWeightMatrix0to1[3][7] = -0.666123957796574;
   fWeightMatrix0to1[4][7] = 0.320812153741045;
   fWeightMatrix0to1[5][7] = 1.28395270864226;
   fWeightMatrix0to1[6][7] = -0.953500452016206;
   fWeightMatrix0to1[7][7] = 1.16971568055985;
   fWeightMatrix0to1[8][7] = -0.553204828202165;
   fWeightMatrix0to1[9][7] = 0.138110613779638;
   fWeightMatrix0to1[10][7] = 0.561269564526954;
   fWeightMatrix0to1[11][7] = 0.748577451265178;
   fWeightMatrix0to1[12][7] = -0.652033951116068;
   fWeightMatrix0to1[13][7] = -0.574589189008326;
   fWeightMatrix0to1[0][8] = 0.222613382134433;
   fWeightMatrix0to1[1][8] = 0.444804524666759;
   fWeightMatrix0to1[2][8] = -4.29090685329811;
   fWeightMatrix0to1[3][8] = 3.16860513870351;
   fWeightMatrix0to1[4][8] = -0.732874340075922;
   fWeightMatrix0to1[5][8] = -0.953472689600834;
   fWeightMatrix0to1[6][8] = 0.598572962727649;
   fWeightMatrix0to1[7][8] = -0.734756319539218;
   fWeightMatrix0to1[8][8] = -1.47673767669923;
   fWeightMatrix0to1[9][8] = 0.175727924258771;
   fWeightMatrix0to1[10][8] = -0.347580268711198;
   fWeightMatrix0to1[11][8] = 3.14962639226038;
   fWeightMatrix0to1[12][8] = -1.17796512357736;
   fWeightMatrix0to1[13][8] = 4.49738875482465;
   fWeightMatrix0to1[0][9] = -0.543832921940719;
   fWeightMatrix0to1[1][9] = 0.166533400638501;
   fWeightMatrix0to1[2][9] = -2.33156839230507;
   fWeightMatrix0to1[3][9] = 0.534249525195884;
   fWeightMatrix0to1[4][9] = 0.133674867864001;
   fWeightMatrix0to1[5][9] = -1.67062765938533;
   fWeightMatrix0to1[6][9] = 0.63921159935907;
   fWeightMatrix0to1[7][9] = -1.22575042483051;
   fWeightMatrix0to1[8][9] = -0.0111281850768567;
   fWeightMatrix0to1[9][9] = 0.171088286376304;
   fWeightMatrix0to1[10][9] = 1.8123675391059;
   fWeightMatrix0to1[11][9] = -1.73327431841036;
   fWeightMatrix0to1[12][9] = -1.90176014263398;
   fWeightMatrix0to1[13][9] = 0.0623973046368458;
   fWeightMatrix0to1[0][10] = 2.31218542503302;
   fWeightMatrix0to1[1][10] = 0.163174131298191;
   fWeightMatrix0to1[2][10] = 0.809520174950749;
   fWeightMatrix0to1[3][10] = -0.758195905405174;
   fWeightMatrix0to1[4][10] = 0.607794401311698;
   fWeightMatrix0to1[5][10] = 1.44351233325838;
   fWeightMatrix0to1[6][10] = 1.21190332411191;
   fWeightMatrix0to1[7][10] = -0.102941984873626;
   fWeightMatrix0to1[8][10] = -0.40160187771303;
   fWeightMatrix0to1[9][10] = -5.09095564774654;
   fWeightMatrix0to1[10][10] = -1.15614069182325;
   fWeightMatrix0to1[11][10] = -1.78882765058084;
   fWeightMatrix0to1[12][10] = 3.97202272479673;
   fWeightMatrix0to1[13][10] = -2.04868863821722;
   fWeightMatrix0to1[0][11] = -0.142864135414179;
   fWeightMatrix0to1[1][11] = 0.28729747640734;
   fWeightMatrix0to1[2][11] = -0.714408905482544;
   fWeightMatrix0to1[3][11] = 9.52026124176682e-05;
   fWeightMatrix0to1[4][11] = -0.905796830977765;
   fWeightMatrix0to1[5][11] = -1.76254515477283;
   fWeightMatrix0to1[6][11] = 1.82782873741346;
   fWeightMatrix0to1[7][11] = 1.22020133993963;
   fWeightMatrix0to1[8][11] = 0.477156831792235;
   fWeightMatrix0to1[9][11] = 0.283143848981543;
   fWeightMatrix0to1[10][11] = 0.934990916351948;
   fWeightMatrix0to1[11][11] = -0.896895309154796;
   fWeightMatrix0to1[12][11] = -0.715060626605374;
   fWeightMatrix0to1[13][11] = 0.693592460126308;
   fWeightMatrix0to1[0][12] = -0.75833340083716;
   fWeightMatrix0to1[1][12] = -0.574320083702685;
   fWeightMatrix0to1[2][12] = 1.51761499017338;
   fWeightMatrix0to1[3][12] = 0.814528173628129;
   fWeightMatrix0to1[4][12] = 0.318540185195602;
   fWeightMatrix0to1[5][12] = 1.55339804266847;
   fWeightMatrix0to1[6][12] = 1.72419564545243;
   fWeightMatrix0to1[7][12] = -1.60029576992555;
   fWeightMatrix0to1[8][12] = 0.676334603096583;
   fWeightMatrix0to1[9][12] = -1.0587855720328;
   fWeightMatrix0to1[10][12] = 0.495090695691532;
   fWeightMatrix0to1[11][12] = -0.980353129537246;
   fWeightMatrix0to1[12][12] = -0.54627599631769;
   fWeightMatrix0to1[13][12] = 0.487990256144055;
   fWeightMatrix0to1[0][13] = 1.1231595865148;
   fWeightMatrix0to1[1][13] = -1.76063559279197;
   fWeightMatrix0to1[2][13] = -0.92411531360369;
   fWeightMatrix0to1[3][13] = 0.143494896725418;
   fWeightMatrix0to1[4][13] = 1.89328903274435;
   fWeightMatrix0to1[5][13] = 2.06416672668262;
   fWeightMatrix0to1[6][13] = -0.786513007285943;
   fWeightMatrix0to1[7][13] = -1.2047182246621;
   fWeightMatrix0to1[8][13] = -0.675273796912907;
   fWeightMatrix0to1[9][13] = -0.108493521836733;
   fWeightMatrix0to1[10][13] = 1.68155380817706;
   fWeightMatrix0to1[11][13] = 1.60986435376401;
   fWeightMatrix0to1[12][13] = 0.991953185137396;
   fWeightMatrix0to1[13][13] = 1.04621955066374;
   // weight matrix from layer 1 to 2
   fWeightMatrix1to2[0][0] = -1.67065589723903;
   fWeightMatrix1to2[1][0] = 0.56323064102809;
   fWeightMatrix1to2[2][0] = 0.0583318355351934;
   fWeightMatrix1to2[3][0] = -1.06019752697692;
   fWeightMatrix1to2[4][0] = -1.1242399399035;
   fWeightMatrix1to2[5][0] = -0.337428616615225;
   fWeightMatrix1to2[6][0] = 0.832624688645667;
   fWeightMatrix1to2[7][0] = -1.59428802093347;
   fWeightMatrix1to2[8][0] = 1.3276860525913;
   fWeightMatrix1to2[9][0] = 1.3175180109348;
   fWeightMatrix1to2[10][0] = -0.322506436523874;
   fWeightMatrix1to2[11][0] = 0.471342245686623;
   fWeightMatrix1to2[12][0] = 1.10718438837106;
   fWeightMatrix1to2[0][1] = 0.933470651126076;
   fWeightMatrix1to2[1][1] = 0.0141771902906659;
   fWeightMatrix1to2[2][1] = 0.07282294383463;
   fWeightMatrix1to2[3][1] = -1.22463208743934;
   fWeightMatrix1to2[4][1] = -0.870566125698906;
   fWeightMatrix1to2[5][1] = 0.865840652588798;
   fWeightMatrix1to2[6][1] = 1.68306004761167;
   fWeightMatrix1to2[7][1] = 1.01814621644991;
   fWeightMatrix1to2[8][1] = 0.131831347031118;
   fWeightMatrix1to2[9][1] = 2.5882737594916;
   fWeightMatrix1to2[10][1] = -1.95715122615545;
   fWeightMatrix1to2[11][1] = -0.776763461726973;
   fWeightMatrix1to2[12][1] = -0.629047044324968;
   fWeightMatrix1to2[0][2] = -0.593461846618187;
   fWeightMatrix1to2[1][2] = 1.11847035817367;
   fWeightMatrix1to2[2][2] = 1.20806775055779;
   fWeightMatrix1to2[3][2] = -1.38316147136186;
   fWeightMatrix1to2[4][2] = -1.45712036351833;
   fWeightMatrix1to2[5][2] = 1.68893656571408;
   fWeightMatrix1to2[6][2] = -1.65005581191563;
   fWeightMatrix1to2[7][2] = -1.53965624431579;
   fWeightMatrix1to2[8][2] = 0.500768937578856;
   fWeightMatrix1to2[9][2] = 1.02823207724589;
   fWeightMatrix1to2[10][2] = 0.956269137797996;
   fWeightMatrix1to2[11][2] = -1.42961665220156;
   fWeightMatrix1to2[12][2] = 1.3082525398116;
   fWeightMatrix1to2[0][3] = -2.28796682942737;
   fWeightMatrix1to2[1][3] = 1.85902342434121;
   fWeightMatrix1to2[2][3] = 0.170018214832745;
   fWeightMatrix1to2[3][3] = -1.01930264715142;
   fWeightMatrix1to2[4][3] = -2.06109742127764;
   fWeightMatrix1to2[5][3] = 0.0495695313440284;
   fWeightMatrix1to2[6][3] = -0.329642219333255;
   fWeightMatrix1to2[7][3] = -1.70476613796337;
   fWeightMatrix1to2[8][3] = -0.597605543899764;
   fWeightMatrix1to2[9][3] = -1.03900241270151;
   fWeightMatrix1to2[10][3] = 0.114728714858721;
   fWeightMatrix1to2[11][3] = -0.889618005437391;
   fWeightMatrix1to2[12][3] = -1.55320713506028;
   fWeightMatrix1to2[0][4] = 1.5861853359114;
   fWeightMatrix1to2[1][4] = -1.29674627718317;
   fWeightMatrix1to2[2][4] = 1.1400640120736;
   fWeightMatrix1to2[3][4] = -1.47177369417225;
   fWeightMatrix1to2[4][4] = -1.45440939984452;
   fWeightMatrix1to2[5][4] = 1.88701824228767;
   fWeightMatrix1to2[6][4] = 1.1908348878183;
   fWeightMatrix1to2[7][4] = -1.65263075309511;
   fWeightMatrix1to2[8][4] = -0.479540697593211;
   fWeightMatrix1to2[9][4] = -0.590224844563065;
   fWeightMatrix1to2[10][4] = -0.682483200346076;
   fWeightMatrix1to2[11][4] = -1.94044014027578;
   fWeightMatrix1to2[12][4] = 0.104997437075123;
   fWeightMatrix1to2[0][5] = 0.399541169499856;
   fWeightMatrix1to2[1][5] = 2.35787587945126;
   fWeightMatrix1to2[2][5] = -0.537941388330174;
   fWeightMatrix1to2[3][5] = -0.383685280467093;
   fWeightMatrix1to2[4][5] = -0.406948050264276;
   fWeightMatrix1to2[5][5] = -1.18982524990737;
   fWeightMatrix1to2[6][5] = 0.910830646451552;
   fWeightMatrix1to2[7][5] = 0.848625006689089;
   fWeightMatrix1to2[8][5] = -0.790895257002239;
   fWeightMatrix1to2[9][5] = -1.51178447419943;
   fWeightMatrix1to2[10][5] = 1.00109526867983;
   fWeightMatrix1to2[11][5] = 0.673449161606724;
   fWeightMatrix1to2[12][5] = 0.947085358653795;
   fWeightMatrix1to2[0][6] = -0.553884935175002;
   fWeightMatrix1to2[1][6] = -0.76746266657167;
   fWeightMatrix1to2[2][6] = 1.65789353377291;
   fWeightMatrix1to2[3][6] = 1.70722746466067;
   fWeightMatrix1to2[4][6] = 1.01021133260613;
   fWeightMatrix1to2[5][6] = -1.10882430402517;
   fWeightMatrix1to2[6][6] = 0.57503948138881;
   fWeightMatrix1to2[7][6] = -0.0466261648972712;
   fWeightMatrix1to2[8][6] = -1.52499367440002;
   fWeightMatrix1to2[9][6] = 0.0227052696387374;
   fWeightMatrix1to2[10][6] = -1.90712720093733;
   fWeightMatrix1to2[11][6] = -0.852809713946491;
   fWeightMatrix1to2[12][6] = -2.03346624617639;
   fWeightMatrix1to2[0][7] = 1.61020410302712;
   fWeightMatrix1to2[1][7] = -1.94153179377083;
   fWeightMatrix1to2[2][7] = 2.22605967621151;
   fWeightMatrix1to2[3][7] = -0.856230726156981;
   fWeightMatrix1to2[4][7] = 0.813078831685119;
   fWeightMatrix1to2[5][7] = -1.67375572665045;
   fWeightMatrix1to2[6][7] = 0.692157114592624;
   fWeightMatrix1to2[7][7] = 1.10874027984934;
   fWeightMatrix1to2[8][7] = -1.91347007982458;
   fWeightMatrix1to2[9][7] = 0.602180035678899;
   fWeightMatrix1to2[10][7] = 0.374497479259902;
   fWeightMatrix1to2[11][7] = -1.49282026623453;
   fWeightMatrix1to2[12][7] = -1.75809452576262;
   fWeightMatrix1to2[0][8] = -1.59401052730051;
   fWeightMatrix1to2[1][8] = -0.678531019286951;
   fWeightMatrix1to2[2][8] = 1.66209010325272;
   fWeightMatrix1to2[3][8] = -1.24836239131828;
   fWeightMatrix1to2[4][8] = 0.742620056388556;
   fWeightMatrix1to2[5][8] = -0.712452025724737;
   fWeightMatrix1to2[6][8] = -0.642372780588548;
   fWeightMatrix1to2[7][8] = -1.23797975392057;
   fWeightMatrix1to2[8][8] = -1.09548976268789;
   fWeightMatrix1to2[9][8] = -0.805893768983854;
   fWeightMatrix1to2[10][8] = 0.769193858551428;
   fWeightMatrix1to2[11][8] = -1.65336252952566;
   fWeightMatrix1to2[12][8] = -0.738424349975198;
   fWeightMatrix1to2[0][9] = 1.53859558854571;
   fWeightMatrix1to2[1][9] = 0.679518648501079;
   fWeightMatrix1to2[2][9] = -0.870132479732574;
   fWeightMatrix1to2[3][9] = 1.90128987174726;
   fWeightMatrix1to2[4][9] = -2.57957843986831;
   fWeightMatrix1to2[5][9] = 1.71087305463646;
   fWeightMatrix1to2[6][9] = 0.927048411297655;
   fWeightMatrix1to2[7][9] = -1.20657629922109;
   fWeightMatrix1to2[8][9] = -0.0508849438097039;
   fWeightMatrix1to2[9][9] = -0.995287991806472;
   fWeightMatrix1to2[10][9] = -1.09857324130301;
   fWeightMatrix1to2[11][9] = 0.910707926681561;
   fWeightMatrix1to2[12][9] = 1.46340389862384;
   fWeightMatrix1to2[0][10] = 1.40549448750792;
   fWeightMatrix1to2[1][10] = 1.95088076609316;
   fWeightMatrix1to2[2][10] = -1.58022084565275;
   fWeightMatrix1to2[3][10] = 0.326344695791465;
   fWeightMatrix1to2[4][10] = -2.12164500924214;
   fWeightMatrix1to2[5][10] = 1.49538011624299;
   fWeightMatrix1to2[6][10] = -2.03797797504458;
   fWeightMatrix1to2[7][10] = -2.18696287659673;
   fWeightMatrix1to2[8][10] = -0.00158746487288762;
   fWeightMatrix1to2[9][10] = 0.665386032627522;
   fWeightMatrix1to2[10][10] = 0.664098745388795;
   fWeightMatrix1to2[11][10] = 0.555542103979268;
   fWeightMatrix1to2[12][10] = 0.791159833811751;
   fWeightMatrix1to2[0][11] = -0.273154592448308;
   fWeightMatrix1to2[1][11] = -0.191087891115986;
   fWeightMatrix1to2[2][11] = 0.261021621879019;
   fWeightMatrix1to2[3][11] = 1.52169673153365;
   fWeightMatrix1to2[4][11] = -2.89082985831459;
   fWeightMatrix1to2[5][11] = 0.211826937024682;
   fWeightMatrix1to2[6][11] = -1.65390381405501;
   fWeightMatrix1to2[7][11] = -1.29763807855696;
   fWeightMatrix1to2[8][11] = 0.301497514829032;
   fWeightMatrix1to2[9][11] = -0.661888155211294;
   fWeightMatrix1to2[10][11] = -0.909783005837844;
   fWeightMatrix1to2[11][11] = 0.427962456459657;
   fWeightMatrix1to2[12][11] = 1.86040683120095;
   fWeightMatrix1to2[0][12] = 1.01946521114414;
   fWeightMatrix1to2[1][12] = 1.05162203990458;
   fWeightMatrix1to2[2][12] = -1.34290572062307;
   fWeightMatrix1to2[3][12] = -1.78294724474327;
   fWeightMatrix1to2[4][12] = -1.23225674442765;
   fWeightMatrix1to2[5][12] = 0.922683129932025;
   fWeightMatrix1to2[6][12] = -0.245742506541737;
   fWeightMatrix1to2[7][12] = -0.636135072309749;
   fWeightMatrix1to2[8][12] = 0.914683942266056;
   fWeightMatrix1to2[9][12] = -1.72358878217358;
   fWeightMatrix1to2[10][12] = -0.913947165183788;
   fWeightMatrix1to2[11][12] = -1.55081919246943;
   fWeightMatrix1to2[12][12] = 0.58558706804274;
   fWeightMatrix1to2[0][13] = -1.53478575949354;
   fWeightMatrix1to2[1][13] = -1.31215554382284;
   fWeightMatrix1to2[2][13] = -0.741623376366192;
   fWeightMatrix1to2[3][13] = -0.77345656146525;
   fWeightMatrix1to2[4][13] = -1.7201058550515;
   fWeightMatrix1to2[5][13] = 2.30479512393973;
   fWeightMatrix1to2[6][13] = -1.41072644000726;
   fWeightMatrix1to2[7][13] = -1.39446505958103;
   fWeightMatrix1to2[8][13] = 1.8459425284592;
   fWeightMatrix1to2[9][13] = 0.423033607345617;
   fWeightMatrix1to2[10][13] = 0.357207466175521;
   fWeightMatrix1to2[11][13] = 0.433838561861431;
   fWeightMatrix1to2[12][13] = 1.20800422595426;
   fWeightMatrix1to2[0][14] = 1.82428326164309;
   fWeightMatrix1to2[1][14] = 0.972933038916724;
   fWeightMatrix1to2[2][14] = -1.1501905331004;
   fWeightMatrix1to2[3][14] = -1.4140301397802;
   fWeightMatrix1to2[4][14] = -1.7902485226407;
   fWeightMatrix1to2[5][14] = 1.76501631549696;
   fWeightMatrix1to2[6][14] = 0.584379079911905;
   fWeightMatrix1to2[7][14] = -0.164393635692103;
   fWeightMatrix1to2[8][14] = 1.16229487952027;
   fWeightMatrix1to2[9][14] = 0.347901474450746;
   fWeightMatrix1to2[10][14] = 1.87399847666248;
   fWeightMatrix1to2[11][14] = -1.87245913931672;
   fWeightMatrix1to2[12][14] = 2.24684858288082;
   // weight matrix from layer 2 to 3
   fWeightMatrix2to3[0][0] = 0.00352618226651633;
   fWeightMatrix2to3[0][1] = -1.96580205090243;
   fWeightMatrix2to3[0][2] = -0.315196517090939;
   fWeightMatrix2to3[0][3] = -0.0289556827233989;
   fWeightMatrix2to3[0][4] = 0.562825811204716;
   fWeightMatrix2to3[0][5] = -0.211689770640384;
   fWeightMatrix2to3[0][6] = -0.335064446706079;
   fWeightMatrix2to3[0][7] = 0.210520973720306;
   fWeightMatrix2to3[0][8] = -0.0395971936151947;
   fWeightMatrix2to3[0][9] = 1.21275792850295;
   fWeightMatrix2to3[0][10] = 1.58663708109441;
   fWeightMatrix2to3[0][11] = 0.00955664262172279;
   fWeightMatrix2to3[0][12] = -0.704089660615721;
   fWeightMatrix2to3[0][13] = 1.64101627750538;
}

inline double ReadMLP0_5_B_1x1::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   if (inputValues.size() != (unsigned int)fLayerSize[0]-1) {
      std::cout << "Input vector needs to be of size " << fLayerSize[0]-1 << std::endl;
      return 0;
   }

   for (int l=0; l<fLayers; l++)
      for (int i=0; i<fLayerSize[l]; i++) fWeights[l][i]=0;

   for (int l=0; l<fLayers-1; l++)
      fWeights[l][fLayerSize[l]-1]=1;

   for (int i=0; i<fLayerSize[0]-1; i++)
      fWeights[0][i]=inputValues[i];

   // layer 0 to 1
   for (int o=0; o<fLayerSize[1]-1; o++) {
      for (int i=0; i<fLayerSize[0]; i++) {
         double inputVal = fWeightMatrix0to1[o][i] * fWeights[0][i];
         fWeights[1][o] += inputVal;
      }
      fWeights[1][o] = ActivationFnc(fWeights[1][o]);
   }
   // layer 1 to 2
   for (int o=0; o<fLayerSize[2]-1; o++) {
      for (int i=0; i<fLayerSize[1]; i++) {
         double inputVal = fWeightMatrix1to2[o][i] * fWeights[1][i];
         fWeights[2][o] += inputVal;
      }
      fWeights[2][o] = ActivationFnc(fWeights[2][o]);
   }
   // layer 2 to 3
   for (int o=0; o<fLayerSize[3]; o++) {
      for (int i=0; i<fLayerSize[2]; i++) {
         double inputVal = fWeightMatrix2to3[o][i] * fWeights[2][i];
         fWeights[3][o] += inputVal;
      }
   }

   return fWeights[3][0];
}

double ReadMLP0_5_B_1x1::ActivationFnc(double x) const
{
   // hyperbolic tan
   return tanh(x);
}
 
   
// Clean up
inline void ReadMLP0_5_B_1x1::Clear() 
{
   // nothing to clear
}
inline double ReadMLP0_5_B_1x1::GetMvaValue( const std::vector<double>& inputValues ) const
{
   // classifier response value
   double retval = 0;

   // classifier response, sanity check first
   if (!fStatusIsClean) {
      std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
      retval = 0;
   }
   else {
      if (IsNormalised()) {
         // normalise variables
         std::vector<double> iV;
         int ivar = 0;
         for (std::vector<double>::const_iterator varIt = inputValues.begin();
              varIt != inputValues.end(); varIt++, ivar++) {
            iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
         }
         retval = GetMvaValue__( iV );
      }
      else {
         retval = GetMvaValue__( inputValues );
      }
   }

   return retval;
}

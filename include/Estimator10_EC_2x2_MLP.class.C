// Class: ReadMLP10_EC_2x2
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : MLP::MLP
TMVA Release   : 3.9.6         [198918]
ROOT Release   : 5.16/00       [331776]
Creator        : reinhard
Date           : Tue Aug 11 16:19:02 2009
Host           : Linux polui02.in2p3.fr 2.6.9-67.0.4.ELsmp #1 SMP Thu Jan 31 16:30:09 CST 2008 i686 i686 i386 GNU/Linux
Dir            : /grid_mnt/data2__polgrid/llr/ilc/reinhard/ILCSoft/TMVA/macros
Training events: 17648


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
Normalise: "True" [Normalise input variables]
V: "False" [Verbose mode]
H: "True" [Print classifier-specific help message]
NCycles: "500" [Number of training cycles]
HiddenLayers: "N+1,N" [Specification of hidden layer architecture (N stands for number of variables; any integers may also be used)]
NeuronType: "tanh" [Neuron activation function type]
TestRate: "5" [Test for overtraining performed at each #th epochs]
# Default:
D: "False" [Use-decorrelated-variables flag (depreciated)]
VarTransform: "None" [Variable transformation method]
VarTransformType: "Signal" [Use signal or background events to derive for variable transformation (the transformation is applied on both types of, course)]
NbinsMVAPdf: "60" [Number of bins used for the PDFs of classifier outputs]
NsmoothMVAPdf: "2" [Number of smoothing iterations for classifier PDFs]
VerboseLevel: "Default" [Verbosity level]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
TxtWeightFilesOnly: "True" [If True: write all training results (weights) as text files (False: some are written in ROOT format)]
NeuronInputType: "sum" [Neuron input function type]
TrainingMethod: "BP" [Train with Back-Propagation (BP - default) or Genetic Algorithm (GA - slower and worse)]
LearningRate: "0.02" [ANN learning rate parameter]
DecayRate: "0.01" [Decay rate for learning parameter]
BPMode: "sequential" [Back-propagation learning mode: sequential or batch]
BatchSize: "-1" [Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 14
ClusterParameters.start       ClusterParameters.start           'F'    [0,8.89995098114]
ClusterParameters.end         ClusterParameters.end             'F'    [8.34173488617,41.6520004272]
ClusterParameters.depth       ClusterParameters.depth           'F'    [0,24.9847373962]
ClusterParameters.E1C/ClusterParameters.Etot_g   ClusterParameters.E1C_D_ClusterParameters.Etot_g     'F'    [0,0.962542772293]
ClusterParameters.E4C/ClusterParameters.Etot_g   ClusterParameters.E4C_D_ClusterParameters.Etot_g     'F'    [0.268195152283,1]
ClusterParameters.E9C/ClusterParameters.Etot_g   ClusterParameters.E9C_D_ClusterParameters.Etot_g     'F'    [0.88076710701,1]
ClusterParameters.dirErr      ClusterParameters.dirErr          'F'    [0.0313993729651,0.999999344349]
ClusterParameters.seedDirErr  ClusterParameters.seedDirErr      'F'    [0,0.999997079372]
ClusterParameters.Es3/ClusterParameters.Etot_g   ClusterParameters.Es3_D_ClusterParameters.Etot_g     'F'    [0,0.863929688931]
ClusterParameters.Width       ClusterParameters.Width           'F'    [4.87993812561,37.6478691101]
ClusterParameters.Eccentricity ClusterParameters.Eccentricity     'F'    [0.17915853858,0.906721532345]
ClusterParameters.nHits       ClusterParameters.nHits           'F'    [7,209]
ClusterParameters.Volume      ClusterParameters.Volume          'F'    [1106.52807617,1344745.75]
ClusterParameters.depth-ClusterParameters.start   ClusterParameters.depth_M_ClusterParameters.start     'F'    [-0.759606719017,24.9847373962]


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;
};

#endif

class ReadMLP10_EC_2x2 : public IClassifierReader {

 public:

   // constructor
   ReadMLP10_EC_2x2( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadMLP10_EC_2x2" ),
        fStatusIsClean( true ),
        fNvars( 14 ),
        fIsNormalised( true )
   {      
      // the training input variables
      const char* inputVars[] = { "ClusterParameters.start", "ClusterParameters.end", "ClusterParameters.depth", "ClusterParameters.E1C/ClusterParameters.Etot_g", "ClusterParameters.E4C/ClusterParameters.Etot_g", "ClusterParameters.E9C/ClusterParameters.Etot_g", "ClusterParameters.dirErr", "ClusterParameters.seedDirErr", "ClusterParameters.Es3/ClusterParameters.Etot_g", "ClusterParameters.Width", "ClusterParameters.Eccentricity", "ClusterParameters.nHits", "ClusterParameters.Volume", "ClusterParameters.depth-ClusterParameters.start" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 8.89995098114014;
      fVmin[1] = 8.34173488616943;
      fVmax[1] = 41.6520004272461;
      fVmin[2] = 0;
      fVmax[2] = 24.9847373962402;
      fVmin[3] = 0;
      fVmax[3] = 0.962542772293091;
      fVmin[4] = 0.268195152282715;
      fVmax[4] = 1;
      fVmin[5] = 0.880767107009888;
      fVmax[5] = 1;
      fVmin[6] = 0.0313993729650974;
      fVmax[6] = 0.999999344348907;
      fVmin[7] = 0;
      fVmax[7] = 0.999997079372406;
      fVmin[8] = 0;
      fVmax[8] = 0.863929688930511;
      fVmin[9] = 4.87993812561035;
      fVmax[9] = 37.6478691101074;
      fVmin[10] = 0.179158538579941;
      fVmax[10] = 0.906721532344818;
      fVmin[11] = 7;
      fVmax[11] = 209;
      fVmin[12] = 1106.52807617188;
      fVmax[12] = 1344745.75;
      fVmin[13] = -0.759606719017029;
      fVmax[13] = 24.9847373962402;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';
      fType[10] = 'F';
      fType[11] = 'F';
      fType[12] = 'F';
      fType[13] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadMLP10_EC_2x2() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;
   bool fStatusIsClean;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[14];
   double fVmax[14];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[14];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)

   double ActivationFnc(double x) const;

   int fLayers;
   int fLayerSize[4];
   double fWeightMatrix0to1[16][15];   // weight matrix from layer 0 to 1
   double fWeightMatrix1to2[15][16];   // weight matrix from layer 1 to 2
   double fWeightMatrix2to3[1][15];   // weight matrix from layer 2 to 3

   double * fWeights[4];
};

inline void ReadMLP10_EC_2x2::Initialize()
{
   // build network structure
   fLayers = 4;
   fLayerSize[0] = 15; fWeights[0] = new double[15]; 
   fLayerSize[1] = 16; fWeights[1] = new double[16]; 
   fLayerSize[2] = 15; fWeights[2] = new double[15]; 
   fLayerSize[3] = 1; fWeights[3] = new double[1]; 
   // weight matrix from layer 0 to 1
   fWeightMatrix0to1[0][0] = -0.462713496843962;
   fWeightMatrix0to1[1][0] = 1.50641234150666;
   fWeightMatrix0to1[2][0] = 0.947739567783221;
   fWeightMatrix0to1[3][0] = 0.912450469337494;
   fWeightMatrix0to1[4][0] = -2.4910660046803;
   fWeightMatrix0to1[5][0] = -1.58694698374629;
   fWeightMatrix0to1[6][0] = -0.691912006975429;
   fWeightMatrix0to1[7][0] = 2.42616279089599;
   fWeightMatrix0to1[8][0] = -1.43191661784084;
   fWeightMatrix0to1[9][0] = -1.00612705913722;
   fWeightMatrix0to1[10][0] = -1.81431901567616;
   fWeightMatrix0to1[11][0] = -0.278810957079109;
   fWeightMatrix0to1[12][0] = -1.19820256026002;
   fWeightMatrix0to1[13][0] = -0.328960966368555;
   fWeightMatrix0to1[14][0] = -0.539257043675157;
   fWeightMatrix0to1[0][1] = 1.78475727879592;
   fWeightMatrix0to1[1][1] = -0.33663677296047;
   fWeightMatrix0to1[2][1] = 1.69802121451632;
   fWeightMatrix0to1[3][1] = 0.0636790018932604;
   fWeightMatrix0to1[4][1] = 0.985562221368715;
   fWeightMatrix0to1[5][1] = 0.0664978016988693;
   fWeightMatrix0to1[6][1] = -0.684028394124702;
   fWeightMatrix0to1[7][1] = 0.768164826290824;
   fWeightMatrix0to1[8][1] = 0.331928276802218;
   fWeightMatrix0to1[9][1] = -1.27023335931705;
   fWeightMatrix0to1[10][1] = 0.373285349646162;
   fWeightMatrix0to1[11][1] = 0.0469137139104367;
   fWeightMatrix0to1[12][1] = -1.18388484756598;
   fWeightMatrix0to1[13][1] = -2.04423756790268;
   fWeightMatrix0to1[14][1] = 0.956123335306015;
   fWeightMatrix0to1[0][2] = 0.9915178323061;
   fWeightMatrix0to1[1][2] = 1.44650711042516;
   fWeightMatrix0to1[2][2] = -0.365871681571636;
   fWeightMatrix0to1[3][2] = -0.573490588143464;
   fWeightMatrix0to1[4][2] = -0.145818856471479;
   fWeightMatrix0to1[5][2] = 0.452942751585628;
   fWeightMatrix0to1[6][2] = -1.08614641188616;
   fWeightMatrix0to1[7][2] = 1.70450544836901;
   fWeightMatrix0to1[8][2] = -0.910811437095979;
   fWeightMatrix0to1[9][2] = 0.848858025747365;
   fWeightMatrix0to1[10][2] = 1.88299713443908;
   fWeightMatrix0to1[11][2] = 1.76819162092804;
   fWeightMatrix0to1[12][2] = 1.85452928288478;
   fWeightMatrix0to1[13][2] = 1.06684930317072;
   fWeightMatrix0to1[14][2] = -0.534777913273141;
   fWeightMatrix0to1[0][3] = -2.1261818050869;
   fWeightMatrix0to1[1][3] = 0.657026469103042;
   fWeightMatrix0to1[2][3] = 0.138140044029194;
   fWeightMatrix0to1[3][3] = 1.12559871378876;
   fWeightMatrix0to1[4][3] = 1.14334422937457;
   fWeightMatrix0to1[5][3] = 1.47879145324283;
   fWeightMatrix0to1[6][3] = 1.08348571532415;
   fWeightMatrix0to1[7][3] = -1.56059965331261;
   fWeightMatrix0to1[8][3] = 1.51652283273272;
   fWeightMatrix0to1[9][3] = -1.47378645463249;
   fWeightMatrix0to1[10][3] = -1.01881330860818;
   fWeightMatrix0to1[11][3] = -0.494548986949163;
   fWeightMatrix0to1[12][3] = -1.78907430672867;
   fWeightMatrix0to1[13][3] = 1.0603135733579;
   fWeightMatrix0to1[14][3] = 0.385411658691949;
   fWeightMatrix0to1[0][4] = -1.35570110873147;
   fWeightMatrix0to1[1][4] = 0.121868980146757;
   fWeightMatrix0to1[2][4] = -0.284713061740264;
   fWeightMatrix0to1[3][4] = 0.513208138113914;
   fWeightMatrix0to1[4][4] = 1.6280368934488;
   fWeightMatrix0to1[5][4] = -0.403201763344062;
   fWeightMatrix0to1[6][4] = 0.37217395785969;
   fWeightMatrix0to1[7][4] = -1.25736857398098;
   fWeightMatrix0to1[8][4] = 0.968275723820639;
   fWeightMatrix0to1[9][4] = -0.832566776776556;
   fWeightMatrix0to1[10][4] = -1.41626333569132;
   fWeightMatrix0to1[11][4] = -2.75765930327564;
   fWeightMatrix0to1[12][4] = 0.626711049043357;
   fWeightMatrix0to1[13][4] = 0.973217490216408;
   fWeightMatrix0to1[14][4] = 1.29115066035267;
   fWeightMatrix0to1[0][5] = -0.263891694957966;
   fWeightMatrix0to1[1][5] = -2.34685981909401;
   fWeightMatrix0to1[2][5] = -1.87169963116283;
   fWeightMatrix0to1[3][5] = 0.94697593009361;
   fWeightMatrix0to1[4][5] = 0.731304281319869;
   fWeightMatrix0to1[5][5] = 1.62462254068701;
   fWeightMatrix0to1[6][5] = 1.03906926390419;
   fWeightMatrix0to1[7][5] = 0.778733191867947;
   fWeightMatrix0to1[8][5] = -0.555900473086573;
   fWeightMatrix0to1[9][5] = -1.01430860834507;
   fWeightMatrix0to1[10][5] = -0.148105925233854;
   fWeightMatrix0to1[11][5] = 1.4398660922014;
   fWeightMatrix0to1[12][5] = -1.20197313584797;
   fWeightMatrix0to1[13][5] = -1.41779840924379;
   fWeightMatrix0to1[14][5] = -1.37008909373114;
   fWeightMatrix0to1[0][6] = 0.383649494126721;
   fWeightMatrix0to1[1][6] = -0.0590929575868477;
   fWeightMatrix0to1[2][6] = 1.58120202590423;
   fWeightMatrix0to1[3][6] = -2.3690868276052;
   fWeightMatrix0to1[4][6] = -0.857552799065641;
   fWeightMatrix0to1[5][6] = 1.8401302021585;
   fWeightMatrix0to1[6][6] = -0.275406983166624;
   fWeightMatrix0to1[7][6] = -1.37969286128701;
   fWeightMatrix0to1[8][6] = -1.07076242744181;
   fWeightMatrix0to1[9][6] = -0.112294363241768;
   fWeightMatrix0to1[10][6] = -1.374422259255;
   fWeightMatrix0to1[11][6] = -0.861642793788665;
   fWeightMatrix0to1[12][6] = 0.334556246737114;
   fWeightMatrix0to1[13][6] = 2.19771044363605;
   fWeightMatrix0to1[14][6] = -0.758568317622997;
   fWeightMatrix0to1[0][7] = 1.09347759470799;
   fWeightMatrix0to1[1][7] = -0.424655968066225;
   fWeightMatrix0to1[2][7] = -0.804328885844281;
   fWeightMatrix0to1[3][7] = 0.00558908902865142;
   fWeightMatrix0to1[4][7] = 0.544747770464332;
   fWeightMatrix0to1[5][7] = -1.51068619716958;
   fWeightMatrix0to1[6][7] = 0.14241292985029;
   fWeightMatrix0to1[7][7] = 0.512068040099563;
   fWeightMatrix0to1[8][7] = 0.394002204272729;
   fWeightMatrix0to1[9][7] = -1.63392792836539;
   fWeightMatrix0to1[10][7] = 0.942513307005156;
   fWeightMatrix0to1[11][7] = -0.17991731812352;
   fWeightMatrix0to1[12][7] = -0.724259838737982;
   fWeightMatrix0to1[13][7] = 0.878874015262268;
   fWeightMatrix0to1[14][7] = -1.22592168348944;
   fWeightMatrix0to1[0][8] = -0.939283779141641;
   fWeightMatrix0to1[1][8] = 0.13622711951906;
   fWeightMatrix0to1[2][8] = -0.307925095055719;
   fWeightMatrix0to1[3][8] = 1.83873001723877;
   fWeightMatrix0to1[4][8] = 0.388614082545027;
   fWeightMatrix0to1[5][8] = -0.000965620020361571;
   fWeightMatrix0to1[6][8] = -0.621242569835354;
   fWeightMatrix0to1[7][8] = 0.27652975305416;
   fWeightMatrix0to1[8][8] = -1.84217198884801;
   fWeightMatrix0to1[9][8] = 1.04007074928473;
   fWeightMatrix0to1[10][8] = 0.0460255860090558;
   fWeightMatrix0to1[11][8] = -1.95227914225148;
   fWeightMatrix0to1[12][8] = 0.802021288050953;
   fWeightMatrix0to1[13][8] = -1.53323795021768;
   fWeightMatrix0to1[14][8] = 0.249859919260072;
   fWeightMatrix0to1[0][9] = 1.29549996189474;
   fWeightMatrix0to1[1][9] = 2.05946238479793;
   fWeightMatrix0to1[2][9] = -1.94713528281366;
   fWeightMatrix0to1[3][9] = 0.501201028800375;
   fWeightMatrix0to1[4][9] = 1.85707003009906;
   fWeightMatrix0to1[5][9] = 1.9432625161011;
   fWeightMatrix0to1[6][9] = 0.0593876963359769;
   fWeightMatrix0to1[7][9] = -1.47751962215766;
   fWeightMatrix0to1[8][9] = -0.431205213225962;
   fWeightMatrix0to1[9][9] = -1.52577552297042;
   fWeightMatrix0to1[10][9] = 2.36669117535282;
   fWeightMatrix0to1[11][9] = 2.3949100090951;
   fWeightMatrix0to1[12][9] = -0.570540330168406;
   fWeightMatrix0to1[13][9] = -0.221214102958332;
   fWeightMatrix0to1[14][9] = 0.375900996751023;
   fWeightMatrix0to1[0][10] = -1.50079141155137;
   fWeightMatrix0to1[1][10] = 0.207457055418574;
   fWeightMatrix0to1[2][10] = 1.69562713514202;
   fWeightMatrix0to1[3][10] = -0.299764209418255;
   fWeightMatrix0to1[4][10] = -0.369838766452717;
   fWeightMatrix0to1[5][10] = 0.27657008382604;
   fWeightMatrix0to1[6][10] = 0.946856421240451;
   fWeightMatrix0to1[7][10] = 0.456128671212094;
   fWeightMatrix0to1[8][10] = 0.706627301880182;
   fWeightMatrix0to1[9][10] = -1.43142364940431;
   fWeightMatrix0to1[10][10] = 0.982580384619545;
   fWeightMatrix0to1[11][10] = 0.259000751561943;
   fWeightMatrix0to1[12][10] = 0.499431620185763;
   fWeightMatrix0to1[13][10] = 0.599117552252747;
   fWeightMatrix0to1[14][10] = 0.661779538112493;
   fWeightMatrix0to1[0][11] = 0.291799848220187;
   fWeightMatrix0to1[1][11] = -0.410919911562801;
   fWeightMatrix0to1[2][11] = 1.03382369521627;
   fWeightMatrix0to1[3][11] = -0.831334540588542;
   fWeightMatrix0to1[4][11] = -0.660356045346998;
   fWeightMatrix0to1[5][11] = 2.25828313406991;
   fWeightMatrix0to1[6][11] = 0.834343007537889;
   fWeightMatrix0to1[7][11] = -0.244895310702386;
   fWeightMatrix0to1[8][11] = 1.78591340662707;
   fWeightMatrix0to1[9][11] = 1.99864604559905;
   fWeightMatrix0to1[10][11] = -1.41027984046924;
   fWeightMatrix0to1[11][11] = -2.6693697865019;
   fWeightMatrix0to1[12][11] = -0.109743050432835;
   fWeightMatrix0to1[13][11] = 0.606245883510041;
   fWeightMatrix0to1[14][11] = -1.7459627334274;
   fWeightMatrix0to1[0][12] = -1.76483990672171;
   fWeightMatrix0to1[1][12] = 1.81905174581026;
   fWeightMatrix0to1[2][12] = 1.79706921089151;
   fWeightMatrix0to1[3][12] = -1.93032444356999;
   fWeightMatrix0to1[4][12] = -0.163286059526104;
   fWeightMatrix0to1[5][12] = -0.347090544468992;
   fWeightMatrix0to1[6][12] = -0.112977036255799;
   fWeightMatrix0to1[7][12] = 1.93571642991469;
   fWeightMatrix0to1[8][12] = -0.541235025451916;
   fWeightMatrix0to1[9][12] = -0.33488888089327;
   fWeightMatrix0to1[10][12] = -0.789813867227541;
   fWeightMatrix0to1[11][12] = 0.749796133831431;
   fWeightMatrix0to1[12][12] = 1.45591848810763;
   fWeightMatrix0to1[13][12] = 1.01021488896108;
   fWeightMatrix0to1[14][12] = 0.262179864279356;
   fWeightMatrix0to1[0][13] = -0.544009733708372;
   fWeightMatrix0to1[1][13] = -2.01400642103116;
   fWeightMatrix0to1[2][13] = 1.05133618080995;
   fWeightMatrix0to1[3][13] = 0.280991797247059;
   fWeightMatrix0to1[4][13] = -1.61228520056624;
   fWeightMatrix0to1[5][13] = 0.0967738426448874;
   fWeightMatrix0to1[6][13] = 0.437373429204213;
   fWeightMatrix0to1[7][13] = -0.0138315411741891;
   fWeightMatrix0to1[8][13] = -1.75671326259469;
   fWeightMatrix0to1[9][13] = 1.35415368865641;
   fWeightMatrix0to1[10][13] = 1.55270465492513;
   fWeightMatrix0to1[11][13] = 0.287658109737047;
   fWeightMatrix0to1[12][13] = -0.141095537266855;
   fWeightMatrix0to1[13][13] = 1.40413972491948;
   fWeightMatrix0to1[14][13] = 1.08368433104778;
   fWeightMatrix0to1[0][14] = 0.794459349848821;
   fWeightMatrix0to1[1][14] = -0.165007546302472;
   fWeightMatrix0to1[2][14] = -1.99175729729744;
   fWeightMatrix0to1[3][14] = -0.671437082825461;
   fWeightMatrix0to1[4][14] = 1.79547756327415;
   fWeightMatrix0to1[5][14] = 1.17746315634722;
   fWeightMatrix0to1[6][14] = 1.34844680872397;
   fWeightMatrix0to1[7][14] = -0.0384094543126961;
   fWeightMatrix0to1[8][14] = 2.26544264079095;
   fWeightMatrix0to1[9][14] = -1.98657009894745;
   fWeightMatrix0to1[10][14] = -1.28876372894448;
   fWeightMatrix0to1[11][14] = -0.197310328740457;
   fWeightMatrix0to1[12][14] = -1.49552077106593;
   fWeightMatrix0to1[13][14] = 1.12538748365644;
   fWeightMatrix0to1[14][14] = 2.21372344849403;
   // weight matrix from layer 1 to 2
   fWeightMatrix1to2[0][0] = -0.836031552208972;
   fWeightMatrix1to2[1][0] = 0.816534789191355;
   fWeightMatrix1to2[2][0] = -0.200838866511792;
   fWeightMatrix1to2[3][0] = -1.63243525050266;
   fWeightMatrix1to2[4][0] = -0.786027042843334;
   fWeightMatrix1to2[5][0] = 0.794454442011432;
   fWeightMatrix1to2[6][0] = -0.0608121684838965;
   fWeightMatrix1to2[7][0] = 1.06015973506946;
   fWeightMatrix1to2[8][0] = -1.31969790279952;
   fWeightMatrix1to2[9][0] = 1.59325274984599;
   fWeightMatrix1to2[10][0] = -1.79680874514213;
   fWeightMatrix1to2[11][0] = 0.803823757932875;
   fWeightMatrix1to2[12][0] = 0.0177149255476542;
   fWeightMatrix1to2[13][0] = -1.6919696848968;
   fWeightMatrix1to2[0][1] = -1.50875603629126;
   fWeightMatrix1to2[1][1] = -1.95040675482646;
   fWeightMatrix1to2[2][1] = -0.346174306389239;
   fWeightMatrix1to2[3][1] = -1.84354120899127;
   fWeightMatrix1to2[4][1] = -1.18510000971646;
   fWeightMatrix1to2[5][1] = -1.51671206654034;
   fWeightMatrix1to2[6][1] = 0.0552319482082492;
   fWeightMatrix1to2[7][1] = -0.965884258249077;
   fWeightMatrix1to2[8][1] = -1.96491357539719;
   fWeightMatrix1to2[9][1] = 1.6890155930032;
   fWeightMatrix1to2[10][1] = -0.928769066726469;
   fWeightMatrix1to2[11][1] = 0.212115241563588;
   fWeightMatrix1to2[12][1] = -1.09801225755083;
   fWeightMatrix1to2[13][1] = 0.374211265308782;
   fWeightMatrix1to2[0][2] = 1.60207752580921;
   fWeightMatrix1to2[1][2] = 1.23418129476334;
   fWeightMatrix1to2[2][2] = -0.82543907096121;
   fWeightMatrix1to2[3][2] = -1.47543095986856;
   fWeightMatrix1to2[4][2] = -0.83659366901622;
   fWeightMatrix1to2[5][2] = -0.536895949658145;
   fWeightMatrix1to2[6][2] = -1.53816487639198;
   fWeightMatrix1to2[7][2] = 0.201274216971893;
   fWeightMatrix1to2[8][2] = 0.0317741827036714;
   fWeightMatrix1to2[9][2] = 1.95257293489782;
   fWeightMatrix1to2[10][2] = -0.31721858067729;
   fWeightMatrix1to2[11][2] = 0.279802227899493;
   fWeightMatrix1to2[12][2] = -0.536677150025218;
   fWeightMatrix1to2[13][2] = -1.82252345282559;
   fWeightMatrix1to2[0][3] = 0.676274554472035;
   fWeightMatrix1to2[1][3] = 1.29081481570594;
   fWeightMatrix1to2[2][3] = -0.819881174999677;
   fWeightMatrix1to2[3][3] = -1.1434671714734;
   fWeightMatrix1to2[4][3] = 0.643576178091177;
   fWeightMatrix1to2[5][3] = 1.34624445448567;
   fWeightMatrix1to2[6][3] = 0.438890077509339;
   fWeightMatrix1to2[7][3] = -0.594605207313252;
   fWeightMatrix1to2[8][3] = -0.559241427174262;
   fWeightMatrix1to2[9][3] = 1.5638021265936;
   fWeightMatrix1to2[10][3] = 0.997368867963221;
   fWeightMatrix1to2[11][3] = 0.956112809774463;
   fWeightMatrix1to2[12][3] = -0.0543409227728774;
   fWeightMatrix1to2[13][3] = 0.372584902205524;
   fWeightMatrix1to2[0][4] = -0.092389123498787;
   fWeightMatrix1to2[1][4] = -1.29479480790058;
   fWeightMatrix1to2[2][4] = -0.648342761964938;
   fWeightMatrix1to2[3][4] = -1.81631953764935;
   fWeightMatrix1to2[4][4] = -1.8443414856699;
   fWeightMatrix1to2[5][4] = -1.71442857975824;
   fWeightMatrix1to2[6][4] = 1.6205347124336;
   fWeightMatrix1to2[7][4] = -1.84122476888116;
   fWeightMatrix1to2[8][4] = 1.91912765289111;
   fWeightMatrix1to2[9][4] = -1.6416312337943;
   fWeightMatrix1to2[10][4] = 1.57855953079907;
   fWeightMatrix1to2[11][4] = -1.11359578263423;
   fWeightMatrix1to2[12][4] = 0.464493923012651;
   fWeightMatrix1to2[13][4] = 0.759513435951898;
   fWeightMatrix1to2[0][5] = -1.56963573340365;
   fWeightMatrix1to2[1][5] = 0.226225657419616;
   fWeightMatrix1to2[2][5] = 0.574067726871753;
   fWeightMatrix1to2[3][5] = -1.88349182190201;
   fWeightMatrix1to2[4][5] = -1.50052947463817;
   fWeightMatrix1to2[5][5] = -1.89022298375371;
   fWeightMatrix1to2[6][5] = -0.895525512455668;
   fWeightMatrix1to2[7][5] = 2.54676050193026;
   fWeightMatrix1to2[8][5] = -0.510305481315476;
   fWeightMatrix1to2[9][5] = 0.177542070743177;
   fWeightMatrix1to2[10][5] = -0.686539047191609;
   fWeightMatrix1to2[11][5] = -1.14616445208741;
   fWeightMatrix1to2[12][5] = -1.80085651781992;
   fWeightMatrix1to2[13][5] = -1.34735147300393;
   fWeightMatrix1to2[0][6] = -1.01392978883882;
   fWeightMatrix1to2[1][6] = 0.786100755364025;
   fWeightMatrix1to2[2][6] = -1.3024450567927;
   fWeightMatrix1to2[3][6] = -1.34442213335631;
   fWeightMatrix1to2[4][6] = 1.08246818301581;
   fWeightMatrix1to2[5][6] = -0.11193588123177;
   fWeightMatrix1to2[6][6] = -0.36354655667309;
   fWeightMatrix1to2[7][6] = 1.77503469939531;
   fWeightMatrix1to2[8][6] = -1.39712922264542;
   fWeightMatrix1to2[9][6] = 1.24829708055207;
   fWeightMatrix1to2[10][6] = 0.623688203225345;
   fWeightMatrix1to2[11][6] = -1.08638703038651;
   fWeightMatrix1to2[12][6] = -0.797744986683352;
   fWeightMatrix1to2[13][6] = -0.142329828288706;
   fWeightMatrix1to2[0][7] = -1.39171601063886;
   fWeightMatrix1to2[1][7] = 0.380758869512872;
   fWeightMatrix1to2[2][7] = 1.94895419037197;
   fWeightMatrix1to2[3][7] = 1.43121547370777;
   fWeightMatrix1to2[4][7] = 2.29738521004477;
   fWeightMatrix1to2[5][7] = -1.11598811013802;
   fWeightMatrix1to2[6][7] = 0.889827406310448;
   fWeightMatrix1to2[7][7] = -1.78964794009553;
   fWeightMatrix1to2[8][7] = 0.338824474548497;
   fWeightMatrix1to2[9][7] = -1.67299176196398;
   fWeightMatrix1to2[10][7] = -2.04632774049223;
   fWeightMatrix1to2[11][7] = -0.0912941998605682;
   fWeightMatrix1to2[12][7] = 1.27131361177939;
   fWeightMatrix1to2[13][7] = 0.519198636242432;
   fWeightMatrix1to2[0][8] = 1.53604725068431;
   fWeightMatrix1to2[1][8] = -0.129188388528551;
   fWeightMatrix1to2[2][8] = -0.137235861967756;
   fWeightMatrix1to2[3][8] = -0.890853693078731;
   fWeightMatrix1to2[4][8] = -0.685132770112079;
   fWeightMatrix1to2[5][8] = 1.59675357717007;
   fWeightMatrix1to2[6][8] = -1.36559507584313;
   fWeightMatrix1to2[7][8] = -0.0878170292725852;
   fWeightMatrix1to2[8][8] = -1.31308878856831;
   fWeightMatrix1to2[9][8] = -0.753139439160982;
   fWeightMatrix1to2[10][8] = -0.143770650210159;
   fWeightMatrix1to2[11][8] = 0.139828059956606;
   fWeightMatrix1to2[12][8] = -1.11216729435999;
   fWeightMatrix1to2[13][8] = 0.921215535395005;
   fWeightMatrix1to2[0][9] = 1.35777453304967;
   fWeightMatrix1to2[1][9] = 0.568479901894154;
   fWeightMatrix1to2[2][9] = -0.106553827229769;
   fWeightMatrix1to2[3][9] = -0.904612917435354;
   fWeightMatrix1to2[4][9] = -1.20665013718844;
   fWeightMatrix1to2[5][9] = -1.28904431167869;
   fWeightMatrix1to2[6][9] = 1.17196341503317;
   fWeightMatrix1to2[7][9] = -0.639054734111904;
   fWeightMatrix1to2[8][9] = -1.43611999062267;
   fWeightMatrix1to2[9][9] = 0.829839378435425;
   fWeightMatrix1to2[10][9] = -1.52992885006068;
   fWeightMatrix1to2[11][9] = -1.10586294050511;
   fWeightMatrix1to2[12][9] = -1.64618727314111;
   fWeightMatrix1to2[13][9] = 1.11220846143788;
   fWeightMatrix1to2[0][10] = -1.6034898897222;
   fWeightMatrix1to2[1][10] = -1.80343371857204;
   fWeightMatrix1to2[2][10] = -0.579817952068911;
   fWeightMatrix1to2[3][10] = -0.880530182862501;
   fWeightMatrix1to2[4][10] = -1.25412784371926;
   fWeightMatrix1to2[5][10] = 2.0827829654426;
   fWeightMatrix1to2[6][10] = -1.46092726894847;
   fWeightMatrix1to2[7][10] = -0.701393112261904;
   fWeightMatrix1to2[8][10] = 2.0569045207845;
   fWeightMatrix1to2[9][10] = 0.619571442421266;
   fWeightMatrix1to2[10][10] = 0.71864442476935;
   fWeightMatrix1to2[11][10] = 0.125863883776335;
   fWeightMatrix1to2[12][10] = 1.39716852116533;
   fWeightMatrix1to2[13][10] = 1.78236060159114;
   fWeightMatrix1to2[0][11] = 0.474586394972589;
   fWeightMatrix1to2[1][11] = -0.958697428651977;
   fWeightMatrix1to2[2][11] = -0.653914428845543;
   fWeightMatrix1to2[3][11] = -1.65202228518731;
   fWeightMatrix1to2[4][11] = 1.10337092153687;
   fWeightMatrix1to2[5][11] = 1.32757118308135;
   fWeightMatrix1to2[6][11] = 0.149326514159015;
   fWeightMatrix1to2[7][11] = 1.39975801045939;
   fWeightMatrix1to2[8][11] = 3.18107532266682;
   fWeightMatrix1to2[9][11] = 1.47281962131885;
   fWeightMatrix1to2[10][11] = -1.44936053272744;
   fWeightMatrix1to2[11][11] = 1.71754752429041;
   fWeightMatrix1to2[12][11] = 1.19001346964218;
   fWeightMatrix1to2[13][11] = -1.70709838147096;
   fWeightMatrix1to2[0][12] = -0.459766052131335;
   fWeightMatrix1to2[1][12] = -1.43199114744749;
   fWeightMatrix1to2[2][12] = 0.897904892254258;
   fWeightMatrix1to2[3][12] = 0.534305955288482;
   fWeightMatrix1to2[4][12] = 1.36763397879771;
   fWeightMatrix1to2[5][12] = 1.91830371381835;
   fWeightMatrix1to2[6][12] = -0.398564472405915;
   fWeightMatrix1to2[7][12] = 1.72347778416315;
   fWeightMatrix1to2[8][12] = 1.54992403209881;
   fWeightMatrix1to2[9][12] = 0.231637145087355;
   fWeightMatrix1to2[10][12] = -0.810535604630001;
   fWeightMatrix1to2[11][12] = 1.67561260629206;
   fWeightMatrix1to2[12][12] = -1.90458703627323;
   fWeightMatrix1to2[13][12] = 0.710759736204715;
   fWeightMatrix1to2[0][13] = 2.02760900102149;
   fWeightMatrix1to2[1][13] = -0.287540052128004;
   fWeightMatrix1to2[2][13] = -0.879037709434669;
   fWeightMatrix1to2[3][13] = -0.105025346129899;
   fWeightMatrix1to2[4][13] = -1.63074286596429;
   fWeightMatrix1to2[5][13] = -0.166382762480223;
   fWeightMatrix1to2[6][13] = -2.00934520760107;
   fWeightMatrix1to2[7][13] = 0.0137419145743046;
   fWeightMatrix1to2[8][13] = -0.176644535460681;
   fWeightMatrix1to2[9][13] = 1.50142870753586;
   fWeightMatrix1to2[10][13] = 1.17871267799021;
   fWeightMatrix1to2[11][13] = 1.73259117472742;
   fWeightMatrix1to2[12][13] = -0.588217769664155;
   fWeightMatrix1to2[13][13] = -0.504903027043214;
   fWeightMatrix1to2[0][14] = 0.581961281555193;
   fWeightMatrix1to2[1][14] = 1.7799573565621;
   fWeightMatrix1to2[2][14] = -1.85220063229559;
   fWeightMatrix1to2[3][14] = -1.3004593396615;
   fWeightMatrix1to2[4][14] = -0.7406397224275;
   fWeightMatrix1to2[5][14] = -1.48457906396362;
   fWeightMatrix1to2[6][14] = -1.93595122404185;
   fWeightMatrix1to2[7][14] = -1.30451250316246;
   fWeightMatrix1to2[8][14] = 1.32802584540794;
   fWeightMatrix1to2[9][14] = 0.114415798299949;
   fWeightMatrix1to2[10][14] = -1.80152979172887;
   fWeightMatrix1to2[11][14] = -2.00355450369908;
   fWeightMatrix1to2[12][14] = 0.0310087347880521;
   fWeightMatrix1to2[13][14] = 1.6974803199044;
   fWeightMatrix1to2[0][15] = 2.11416785004073;
   fWeightMatrix1to2[1][15] = 1.43852400823223;
   fWeightMatrix1to2[2][15] = -0.725240358887019;
   fWeightMatrix1to2[3][15] = -1.96723217424288;
   fWeightMatrix1to2[4][15] = -0.337981105323861;
   fWeightMatrix1to2[5][15] = -1.64850262107455;
   fWeightMatrix1to2[6][15] = -1.67108742554015;
   fWeightMatrix1to2[7][15] = -0.52736587942898;
   fWeightMatrix1to2[8][15] = 0.252598628539789;
   fWeightMatrix1to2[9][15] = -1.5599542192473;
   fWeightMatrix1to2[10][15] = 1.55489259741394;
   fWeightMatrix1to2[11][15] = 1.20218275208104;
   fWeightMatrix1to2[12][15] = 0.143091834967442;
   fWeightMatrix1to2[13][15] = -0.725066721264854;
   // weight matrix from layer 2 to 3
   fWeightMatrix2to3[0][0] = -0.226604891765475;
   fWeightMatrix2to3[0][1] = 0.906559463350639;
   fWeightMatrix2to3[0][2] = -0.281174764276641;
   fWeightMatrix2to3[0][3] = 0.28824195667258;
   fWeightMatrix2to3[0][4] = 0.759115237770704;
   fWeightMatrix2to3[0][5] = 0.609788475418315;
   fWeightMatrix2to3[0][6] = -0.820014356100958;
   fWeightMatrix2to3[0][7] = 1.39476871450707;
   fWeightMatrix2to3[0][8] = -1.14227794699765;
   fWeightMatrix2to3[0][9] = 1.50260246333779;
   fWeightMatrix2to3[0][10] = 0.961321531833455;
   fWeightMatrix2to3[0][11] = 0.274252601907884;
   fWeightMatrix2to3[0][12] = 0.102841741528061;
   fWeightMatrix2to3[0][13] = 0.204025487843561;
   fWeightMatrix2to3[0][14] = -0.539432019766588;
}

inline double ReadMLP10_EC_2x2::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   if (inputValues.size() != (unsigned int)fLayerSize[0]-1) {
      std::cout << "Input vector needs to be of size " << fLayerSize[0]-1 << std::endl;
      return 0;
   }

   for (int l=0; l<fLayers; l++)
      for (int i=0; i<fLayerSize[l]; i++) fWeights[l][i]=0;

   for (int l=0; l<fLayers-1; l++)
      fWeights[l][fLayerSize[l]-1]=1;

   for (int i=0; i<fLayerSize[0]-1; i++)
      fWeights[0][i]=inputValues[i];

   // layer 0 to 1
   for (int o=0; o<fLayerSize[1]-1; o++) {
      for (int i=0; i<fLayerSize[0]; i++) {
         double inputVal = fWeightMatrix0to1[o][i] * fWeights[0][i];
         fWeights[1][o] += inputVal;
      }
      fWeights[1][o] = ActivationFnc(fWeights[1][o]);
   }
   // layer 1 to 2
   for (int o=0; o<fLayerSize[2]-1; o++) {
      for (int i=0; i<fLayerSize[1]; i++) {
         double inputVal = fWeightMatrix1to2[o][i] * fWeights[1][i];
         fWeights[2][o] += inputVal;
      }
      fWeights[2][o] = ActivationFnc(fWeights[2][o]);
   }
   // layer 2 to 3
   for (int o=0; o<fLayerSize[3]; o++) {
      for (int i=0; i<fLayerSize[2]; i++) {
         double inputVal = fWeightMatrix2to3[o][i] * fWeights[2][i];
         fWeights[3][o] += inputVal;
      }
   }

   return fWeights[3][0];
}

double ReadMLP10_EC_2x2::ActivationFnc(double x) const
{
   // hyperbolic tan
   return tanh(x);
}
 
   
// Clean up
inline void ReadMLP10_EC_2x2::Clear() 
{
   // nothing to clear
}
inline double ReadMLP10_EC_2x2::GetMvaValue( const std::vector<double>& inputValues ) const
{
   // classifier response value
   double retval = 0;

   // classifier response, sanity check first
   if (!fStatusIsClean) {
      std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
      retval = 0;
   }
   else {
      if (IsNormalised()) {
         // normalise variables
         std::vector<double> iV;
         int ivar = 0;
         for (std::vector<double>::const_iterator varIt = inputValues.begin();
              varIt != inputValues.end(); varIt++, ivar++) {
            iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
         }
         retval = GetMvaValue__( iV );
      }
      else {
         retval = GetMvaValue__( inputValues );
      }
   }

   return retval;
}

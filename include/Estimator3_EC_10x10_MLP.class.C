// Class: ReadMLP3_EC_10x10
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : MLP::MLP
TMVA Release   : 3.9.6         [198918]
ROOT Release   : 5.16/00       [331776]
Creator        : reinhard
Date           : Tue Sep 22 15:40:42 2009
Host           : Linux polui02.in2p3.fr 2.6.9-67.0.4.ELsmp #1 SMP Thu Jan 31 16:30:09 CST 2008 i686 i686 i386 GNU/Linux
Dir            : /grid_mnt/data2__polgrid/llr/ilc/reinhard/ILCSoft/TMVA/macros
Training events: 5200


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
Normalise: "True" [Normalise input variables]
V: "False" [Verbose mode]
H: "True" [Print classifier-specific help message]
NCycles: "500" [Number of training cycles]
HiddenLayers: "N+1,N" [Specification of hidden layer architecture (N stands for number of variables; any integers may also be used)]
NeuronType: "tanh" [Neuron activation function type]
TestRate: "5" [Test for overtraining performed at each #th epochs]
# Default:
D: "False" [Use-decorrelated-variables flag (depreciated)]
VarTransform: "None" [Variable transformation method]
VarTransformType: "Signal" [Use signal or background events to derive for variable transformation (the transformation is applied on both types of, course)]
NbinsMVAPdf: "60" [Number of bins used for the PDFs of classifier outputs]
NsmoothMVAPdf: "2" [Number of smoothing iterations for classifier PDFs]
VerboseLevel: "Default" [Verbosity level]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
TxtWeightFilesOnly: "True" [If True: write all training results (weights) as text files (False: some are written in ROOT format)]
NeuronInputType: "sum" [Neuron input function type]
TrainingMethod: "BP" [Train with Back-Propagation (BP - default) or Genetic Algorithm (GA - slower and worse)]
LearningRate: "0.02" [ANN learning rate parameter]
DecayRate: "0.01" [Decay rate for learning parameter]
BPMode: "sequential" [Back-propagation learning mode: sequential or batch]
BatchSize: "-1" [Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 13
ClusterParameters.start       ClusterParameters.start           'F'    [0,9.1911239624]
ClusterParameters.end         ClusterParameters.end             'F'    [5.12682533264,33.2693481445]
ClusterParameters.depth       ClusterParameters.depth           'F'    [0,22.2186565399]
ClusterParameters.E1C/ClusterParameters.Etot_g   ClusterParameters.E1C_D_ClusterParameters.Etot_g     'F'    [0,0.964051306248]
ClusterParameters.E4C/ClusterParameters.Etot_g   ClusterParameters.E4C_D_ClusterParameters.Etot_g     'F'    [0.0417873375118,1]
ClusterParameters.E9C/ClusterParameters.Etot_g   ClusterParameters.E9C_D_ClusterParameters.Etot_g     'F'    [0.514727473259,1]
ClusterParameters.dirErr      ClusterParameters.dirErr          'F'    [0.161907702684,0.999999821186]
ClusterParameters.seedDirErr  ClusterParameters.seedDirErr      'F'    [0,0.999999761581]
ClusterParameters.Width       ClusterParameters.Width           'F'    [1.15572047234,29.0823822021]
ClusterParameters.Eccentricity ClusterParameters.Eccentricity     'F'    [0.125687360764,0.846615254879]
ClusterParameters.nHits       ClusterParameters.nHits           'F'    [5,156]
ClusterParameters.Volume      ClusterParameters.Volume          'F'    [216.205612183,593133.8125]
ClusterParameters.depth-ClusterParameters.start   ClusterParameters.depth_M_ClusterParameters.start     'F'    [-1.9902857542,20.6279678345]


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;
};

#endif

class ReadMLP3_EC_10x10 : public IClassifierReader {

 public:

   // constructor
   ReadMLP3_EC_10x10( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadMLP3_EC_10x10" ),
        fStatusIsClean( true ),
        fNvars( 13 ),
        fIsNormalised( true )
   {      
      // the training input variables
      const char* inputVars[] = { "ClusterParameters.start", "ClusterParameters.end", "ClusterParameters.depth", "ClusterParameters.E1C/ClusterParameters.Etot_g", "ClusterParameters.E4C/ClusterParameters.Etot_g", "ClusterParameters.E9C/ClusterParameters.Etot_g", "ClusterParameters.dirErr", "ClusterParameters.seedDirErr", "ClusterParameters.Width", "ClusterParameters.Eccentricity", "ClusterParameters.nHits", "ClusterParameters.Volume", "ClusterParameters.depth-ClusterParameters.start" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 9.19112396240234;
      fVmin[1] = 5.1268253326416;
      fVmax[1] = 33.2693481445312;
      fVmin[2] = 0;
      fVmax[2] = 22.218656539917;
      fVmin[3] = 0;
      fVmax[3] = 0.964051306247711;
      fVmin[4] = 0.0417873375117779;
      fVmax[4] = 1;
      fVmin[5] = 0.514727473258972;
      fVmax[5] = 1;
      fVmin[6] = 0.161907702684402;
      fVmax[6] = 0.999999821186066;
      fVmin[7] = 0;
      fVmax[7] = 0.999999761581421;
      fVmin[8] = 1.15572047233582;
      fVmax[8] = 29.0823822021484;
      fVmin[9] = 0.12568736076355;
      fVmax[9] = 0.846615254878998;
      fVmin[10] = 5;
      fVmax[10] = 156;
      fVmin[11] = 216.205612182617;
      fVmax[11] = 593133.8125;
      fVmin[12] = -1.9902857542038;
      fVmax[12] = 20.6279678344727;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';
      fType[10] = 'F';
      fType[11] = 'F';
      fType[12] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadMLP3_EC_10x10() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;
   bool fStatusIsClean;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[13];
   double fVmax[13];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[13];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)

   double ActivationFnc(double x) const;

   int fLayers;
   int fLayerSize[4];
   double fWeightMatrix0to1[15][14];   // weight matrix from layer 0 to 1
   double fWeightMatrix1to2[14][15];   // weight matrix from layer 1 to 2
   double fWeightMatrix2to3[1][14];   // weight matrix from layer 2 to 3

   double * fWeights[4];
};

inline void ReadMLP3_EC_10x10::Initialize()
{
   // build network structure
   fLayers = 4;
   fLayerSize[0] = 14; fWeights[0] = new double[14]; 
   fLayerSize[1] = 15; fWeights[1] = new double[15]; 
   fLayerSize[2] = 14; fWeights[2] = new double[14]; 
   fLayerSize[3] = 1; fWeights[3] = new double[1]; 
   // weight matrix from layer 0 to 1
   fWeightMatrix0to1[0][0] = -0.447824840850288;
   fWeightMatrix0to1[1][0] = 1.89685897711202;
   fWeightMatrix0to1[2][0] = 0.42965811273883;
   fWeightMatrix0to1[3][0] = 1.60021756906005;
   fWeightMatrix0to1[4][0] = -1.39039938539209;
   fWeightMatrix0to1[5][0] = -1.34991113592808;
   fWeightMatrix0to1[6][0] = -0.671356421927057;
   fWeightMatrix0to1[7][0] = 1.75398517805068;
   fWeightMatrix0to1[8][0] = -1.40430716850534;
   fWeightMatrix0to1[9][0] = -0.28060844508277;
   fWeightMatrix0to1[10][0] = -1.77257291620041;
   fWeightMatrix0to1[11][0] = -0.392590899296251;
   fWeightMatrix0to1[12][0] = -1.64946603161964;
   fWeightMatrix0to1[13][0] = -0.452311090367302;
   fWeightMatrix0to1[0][1] = -0.578118133509635;
   fWeightMatrix0to1[1][1] = 0.679125803719959;
   fWeightMatrix0to1[2][1] = -0.519230960680572;
   fWeightMatrix0to1[3][1] = 1.92765425848872;
   fWeightMatrix0to1[4][1] = 0.31997739079717;
   fWeightMatrix0to1[5][1] = 1.34793777458326;
   fWeightMatrix0to1[6][1] = -0.360279958213122;
   fWeightMatrix0to1[7][1] = -0.53573348918315;
   fWeightMatrix0to1[8][1] = 1.4240018626008;
   fWeightMatrix0to1[9][1] = 0.190790005085519;
   fWeightMatrix0to1[10][1] = -1.32699866482659;
   fWeightMatrix0to1[11][1] = -0.390379313880885;
   fWeightMatrix0to1[12][1] = 1.04429510710068;
   fWeightMatrix0to1[13][1] = -1.41493251278593;
   fWeightMatrix0to1[0][2] = -1.8997611295908;
   fWeightMatrix0to1[1][2] = 0.126813987047039;
   fWeightMatrix0to1[2][2] = 0.428999448243132;
   fWeightMatrix0to1[3][2] = 1.65730282797418;
   fWeightMatrix0to1[4][2] = -0.0857391040518921;
   fWeightMatrix0to1[5][2] = -0.220628537000588;
   fWeightMatrix0to1[6][2] = 0.243308952275071;
   fWeightMatrix0to1[7][2] = -0.291383467974879;
   fWeightMatrix0to1[8][2] = -1.65466218139409;
   fWeightMatrix0to1[9][2] = 2.2182212449113;
   fWeightMatrix0to1[10][2] = -1.48337847869918;
   fWeightMatrix0to1[11][2] = 1.05420397308761;
   fWeightMatrix0to1[12][2] = 1.73579699589333;
   fWeightMatrix0to1[13][2] = 0.743539897704329;
   fWeightMatrix0to1[0][3] = 2.07721355403782;
   fWeightMatrix0to1[1][3] = 1.35017106170508;
   fWeightMatrix0to1[2][3] = -0.868834811826681;
   fWeightMatrix0to1[3][3] = -1.56625761806234;
   fWeightMatrix0to1[4][3] = 1.13175416036808;
   fWeightMatrix0to1[5][3] = 0.0985986590102457;
   fWeightMatrix0to1[6][3] = 1.59699574433026;
   fWeightMatrix0to1[7][3] = 1.61672407554192;
   fWeightMatrix0to1[8][3] = 1.98210989031671;
   fWeightMatrix0to1[9][3] = 0.756874121275091;
   fWeightMatrix0to1[10][3] = -0.726518749302409;
   fWeightMatrix0to1[11][3] = 1.16848618312415;
   fWeightMatrix0to1[12][3] = -2.64864108071977;
   fWeightMatrix0to1[13][3] = -1.08429065240083;
   fWeightMatrix0to1[0][4] = -1.39598447042686;
   fWeightMatrix0to1[1][4] = -1.65994944787445;
   fWeightMatrix0to1[2][4] = 1.82327171913926;
   fWeightMatrix0to1[3][4] = 0.378371552239324;
   fWeightMatrix0to1[4][4] = -1.62852507322831;
   fWeightMatrix0to1[5][4] = 0.523189787347047;
   fWeightMatrix0to1[6][4] = -0.239514156814748;
   fWeightMatrix0to1[7][4] = 0.749493062324521;
   fWeightMatrix0to1[8][4] = 1.95015380523497;
   fWeightMatrix0to1[9][4] = -0.204310983255271;
   fWeightMatrix0to1[10][4] = -0.542702870387529;
   fWeightMatrix0to1[11][4] = -1.06032722840271;
   fWeightMatrix0to1[12][4] = -0.557387209364305;
   fWeightMatrix0to1[13][4] = -0.707112658122317;
   fWeightMatrix0to1[0][5] = -1.06489657067291;
   fWeightMatrix0to1[1][5] = -1.43623306275129;
   fWeightMatrix0to1[2][5] = 1.26588497647323;
   fWeightMatrix0to1[3][5] = 0.991828432171505;
   fWeightMatrix0to1[4][5] = 1.01224152277216;
   fWeightMatrix0to1[5][5] = -0.0883613863450283;
   fWeightMatrix0to1[6][5] = -1.86897195560512;
   fWeightMatrix0to1[7][5] = -1.71288320603742;
   fWeightMatrix0to1[8][5] = 0.446116542057178;
   fWeightMatrix0to1[9][5] = 0.308033066108227;
   fWeightMatrix0to1[10][5] = 1.56155038840686;
   fWeightMatrix0to1[11][5] = 0.850999779104014;
   fWeightMatrix0to1[12][5] = 0.618821487399407;
   fWeightMatrix0to1[13][5] = -0.60805314656789;
   fWeightMatrix0to1[0][6] = -1.32294126558173;
   fWeightMatrix0to1[1][6] = -0.261843872576361;
   fWeightMatrix0to1[2][6] = 1.7437051027548;
   fWeightMatrix0to1[3][6] = -1.16565769493042;
   fWeightMatrix0to1[4][6] = -1.87048613948254;
   fWeightMatrix0to1[5][6] = -1.36596095464366;
   fWeightMatrix0to1[6][6] = -0.326080658807396;
   fWeightMatrix0to1[7][6] = 0.181873735972352;
   fWeightMatrix0to1[8][6] = 1.49474392443804;
   fWeightMatrix0to1[9][6] = -1.97318171025722;
   fWeightMatrix0to1[10][6] = -1.23448442780273;
   fWeightMatrix0to1[11][6] = 1.57249471858817;
   fWeightMatrix0to1[12][6] = -1.47001759737964;
   fWeightMatrix0to1[13][6] = -1.37453547739774;
   fWeightMatrix0to1[0][7] = -1.36136954455436;
   fWeightMatrix0to1[1][7] = 0.203078617851341;
   fWeightMatrix0to1[2][7] = -1.43806913015773;
   fWeightMatrix0to1[3][7] = -1.25947636459746;
   fWeightMatrix0to1[4][7] = 0.452895596393731;
   fWeightMatrix0to1[5][7] = 1.9845407663424;
   fWeightMatrix0to1[6][7] = -1.14175563160576;
   fWeightMatrix0to1[7][7] = 1.7796877998931;
   fWeightMatrix0to1[8][7] = -0.440267230474969;
   fWeightMatrix0to1[9][7] = 0.107846402593615;
   fWeightMatrix0to1[10][7] = -0.011589972225474;
   fWeightMatrix0to1[11][7] = 0.41128727142834;
   fWeightMatrix0to1[12][7] = -1.88114449539479;
   fWeightMatrix0to1[13][7] = 0.288817765212684;
   fWeightMatrix0to1[0][8] = 0.351532040819727;
   fWeightMatrix0to1[1][8] = 0.395492741818013;
   fWeightMatrix0to1[2][8] = -1.54378774930107;
   fWeightMatrix0to1[3][8] = 2.03138500654078;
   fWeightMatrix0to1[4][8] = 0.368441384400843;
   fWeightMatrix0to1[5][8] = -1.0746860362592;
   fWeightMatrix0to1[6][8] = 0.726635195932072;
   fWeightMatrix0to1[7][8] = -0.964645712443761;
   fWeightMatrix0to1[8][8] = -1.61693789654266;
   fWeightMatrix0to1[9][8] = -0.245112659581347;
   fWeightMatrix0to1[10][8] = -0.132989748050916;
   fWeightMatrix0to1[11][8] = 1.65668984158642;
   fWeightMatrix0to1[12][8] = 1.23399861805359;
   fWeightMatrix0to1[13][8] = -0.124098435306079;
   fWeightMatrix0to1[0][9] = -0.308960841333711;
   fWeightMatrix0to1[1][9] = 0.0637439027583179;
   fWeightMatrix0to1[2][9] = -1.77104734886414;
   fWeightMatrix0to1[3][9] = 0.889707723531384;
   fWeightMatrix0to1[4][9] = 0.0133038970640815;
   fWeightMatrix0to1[5][9] = -1.61945067301498;
   fWeightMatrix0to1[6][9] = 0.658545487381858;
   fWeightMatrix0to1[7][9] = -1.54506185392076;
   fWeightMatrix0to1[8][9] = 0.606654790557285;
   fWeightMatrix0to1[9][9] = 0.907903925801746;
   fWeightMatrix0to1[10][9] = 1.96323901473567;
   fWeightMatrix0to1[11][9] = -1.85843132100982;
   fWeightMatrix0to1[12][9] = -0.610553524249476;
   fWeightMatrix0to1[13][9] = 1.52678936475185;
   fWeightMatrix0to1[0][10] = 1.70076561758029;
   fWeightMatrix0to1[1][10] = 0.170980657155722;
   fWeightMatrix0to1[2][10] = -1.54827346900007;
   fWeightMatrix0to1[3][10] = -0.281107397357164;
   fWeightMatrix0to1[4][10] = -1.44723189883582;
   fWeightMatrix0to1[5][10] = 1.33983245276653;
   fWeightMatrix0to1[6][10] = 1.22551239176611;
   fWeightMatrix0to1[7][10] = 0.163279248039762;
   fWeightMatrix0to1[8][10] = 0.818234523025707;
   fWeightMatrix0to1[9][10] = -1.9199821942927;
   fWeightMatrix0to1[10][10] = -1.63527257940437;
   fWeightMatrix0to1[11][10] = 0.403166476681783;
   fWeightMatrix0to1[12][10] = 0.904063327729681;
   fWeightMatrix0to1[13][10] = -0.900369605149719;
   fWeightMatrix0to1[0][11] = -0.250811598812874;
   fWeightMatrix0to1[1][11] = 0.385684348645624;
   fWeightMatrix0to1[2][11] = 0.485206653819627;
   fWeightMatrix0to1[3][11] = 0.879910727518827;
   fWeightMatrix0to1[4][11] = 1.4320477457527;
   fWeightMatrix0to1[5][11] = -1.78939954194233;
   fWeightMatrix0to1[6][11] = 1.56160445392283;
   fWeightMatrix0to1[7][11] = 0.921580338314405;
   fWeightMatrix0to1[8][11] = 0.606225967798204;
   fWeightMatrix0to1[9][11] = 1.01383658993547;
   fWeightMatrix0to1[10][11] = 1.43202443116803;
   fWeightMatrix0to1[11][11] = -0.816045174812409;
   fWeightMatrix0to1[12][11] = 0.376921736290424;
   fWeightMatrix0to1[13][11] = 0.760627903458468;
   fWeightMatrix0to1[0][12] = -0.760145272280609;
   fWeightMatrix0to1[1][12] = -0.510611232864586;
   fWeightMatrix0to1[2][12] = 1.36212952272837;
   fWeightMatrix0to1[3][12] = 1.08215115730427;
   fWeightMatrix0to1[4][12] = -0.130592760912213;
   fWeightMatrix0to1[5][12] = 1.33303978998648;
   fWeightMatrix0to1[6][12] = 1.85301411324274;
   fWeightMatrix0to1[7][12] = -1.84152723000206;
   fWeightMatrix0to1[8][12] = 0.523820436742694;
   fWeightMatrix0to1[9][12] = 0.0317563030860268;
   fWeightMatrix0to1[10][12] = 0.333914299966911;
   fWeightMatrix0to1[11][12] = -1.82975884413566;
   fWeightMatrix0to1[12][12] = -0.760958611709121;
   fWeightMatrix0to1[13][12] = 0.935740719925635;
   fWeightMatrix0to1[0][13] = 1.30533584106947;
   fWeightMatrix0to1[1][13] = -1.89119156717832;
   fWeightMatrix0to1[2][13] = 0.430765696105462;
   fWeightMatrix0to1[3][13] = -0.646237705211525;
   fWeightMatrix0to1[4][13] = -0.347072658998915;
   fWeightMatrix0to1[5][13] = 2.12149754260963;
   fWeightMatrix0to1[6][13] = -0.503478484051786;
   fWeightMatrix0to1[7][13] = -0.590902172254644;
   fWeightMatrix0to1[8][13] = -1.39848396648876;
   fWeightMatrix0to1[9][13] = 1.45198614915202;
   fWeightMatrix0to1[10][13] = 1.3701253618834;
   fWeightMatrix0to1[11][13] = 1.3204341108079;
   fWeightMatrix0to1[12][13] = -0.0936962639896448;
   fWeightMatrix0to1[13][13] = -0.409711792771786;
   // weight matrix from layer 1 to 2
   fWeightMatrix1to2[0][0] = -1.91633710813462;
   fWeightMatrix1to2[1][0] = 0.812786892707625;
   fWeightMatrix1to2[2][0] = 0.420553901599592;
   fWeightMatrix1to2[3][0] = -1.35756660673197;
   fWeightMatrix1to2[4][0] = -0.61260518115639;
   fWeightMatrix1to2[5][0] = 0.326761524332699;
   fWeightMatrix1to2[6][0] = 0.209301711991465;
   fWeightMatrix1to2[7][0] = -2.25955254754094;
   fWeightMatrix1to2[8][0] = 1.37652578894587;
   fWeightMatrix1to2[9][0] = 0.998573766645229;
   fWeightMatrix1to2[10][0] = -0.376102342560471;
   fWeightMatrix1to2[11][0] = -0.0972134473788343;
   fWeightMatrix1to2[12][0] = 1.41950109752127;
   fWeightMatrix1to2[0][1] = 1.04140108942059;
   fWeightMatrix1to2[1][1] = 0.172671351503448;
   fWeightMatrix1to2[2][1] = -0.246951974620956;
   fWeightMatrix1to2[3][1] = -2.11714273369741;
   fWeightMatrix1to2[4][1] = -0.882059347936193;
   fWeightMatrix1to2[5][1] = 1.72357535970746;
   fWeightMatrix1to2[6][1] = 1.70505965299621;
   fWeightMatrix1to2[7][1] = 0.599892738107469;
   fWeightMatrix1to2[8][1] = 0.0448073783808876;
   fWeightMatrix1to2[9][1] = 2.02174094197075;
   fWeightMatrix1to2[10][1] = -1.90701235470645;
   fWeightMatrix1to2[11][1] = -1.31026597829948;
   fWeightMatrix1to2[12][1] = -0.326799351183951;
   fWeightMatrix1to2[0][2] = -1.37225930718366;
   fWeightMatrix1to2[1][2] = 1.10585890393031;
   fWeightMatrix1to2[2][2] = 1.75987004536812;
   fWeightMatrix1to2[3][2] = -1.2237106058988;
   fWeightMatrix1to2[4][2] = 0.591637087235668;
   fWeightMatrix1to2[5][2] = -0.127592081420161;
   fWeightMatrix1to2[6][2] = -1.78558970708961;
   fWeightMatrix1to2[7][2] = -0.904694048432138;
   fWeightMatrix1to2[8][2] = 1.14993585798457;
   fWeightMatrix1to2[9][2] = 0.198034255487735;
   fWeightMatrix1to2[10][2] = 0.829043541784439;
   fWeightMatrix1to2[11][2] = -1.16693343220861;
   fWeightMatrix1to2[12][2] = 1.89429424034151;
   fWeightMatrix1to2[0][3] = -1.67547261231388;
   fWeightMatrix1to2[1][3] = 0.520780697023439;
   fWeightMatrix1to2[2][3] = -0.0667416533199136;
   fWeightMatrix1to2[3][3] = -1.34227659676255;
   fWeightMatrix1to2[4][3] = -0.963925962234768;
   fWeightMatrix1to2[5][3] = -1.90520952668321;
   fWeightMatrix1to2[6][3] = -0.101806420584636;
   fWeightMatrix1to2[7][3] = -1.61100372931689;
   fWeightMatrix1to2[8][3] = -1.74042688301948;
   fWeightMatrix1to2[9][3] = -1.70651408093235;
   fWeightMatrix1to2[10][3] = 0.107796964633463;
   fWeightMatrix1to2[11][3] = -1.01509170492511;
   fWeightMatrix1to2[12][3] = -1.78002078685929;
   fWeightMatrix1to2[0][4] = 1.40980715881697;
   fWeightMatrix1to2[1][4] = -0.995646015734789;
   fWeightMatrix1to2[2][4] = -0.0370550722155845;
   fWeightMatrix1to2[3][4] = -1.16977690412249;
   fWeightMatrix1to2[4][4] = 0.153921334493587;
   fWeightMatrix1to2[5][4] = 1.84963831311444;
   fWeightMatrix1to2[6][4] = 1.43142144923918;
   fWeightMatrix1to2[7][4] = -1.00493529432703;
   fWeightMatrix1to2[8][4] = -1.59463312685787;
   fWeightMatrix1to2[9][4] = -1.05806736850595;
   fWeightMatrix1to2[10][4] = -0.998186680744136;
   fWeightMatrix1to2[11][4] = -1.63204421636879;
   fWeightMatrix1to2[12][4] = 0.162475612103307;
   fWeightMatrix1to2[0][5] = 0.264128000084621;
   fWeightMatrix1to2[1][5] = 2.01489384963673;
   fWeightMatrix1to2[2][5] = -0.167583464670082;
   fWeightMatrix1to2[3][5] = 0.301456879321092;
   fWeightMatrix1to2[4][5] = -0.782502137829976;
   fWeightMatrix1to2[5][5] = -1.9425546752912;
   fWeightMatrix1to2[6][5] = 0.881668255787309;
   fWeightMatrix1to2[7][5] = 1.15951691073805;
   fWeightMatrix1to2[8][5] = -0.704266820797977;
   fWeightMatrix1to2[9][5] = -1.23657914228002;
   fWeightMatrix1to2[10][5] = 0.922928928871671;
   fWeightMatrix1to2[11][5] = 1.20713266191724;
   fWeightMatrix1to2[12][5] = 0.619378222269107;
   fWeightMatrix1to2[0][6] = -0.469758220630608;
   fWeightMatrix1to2[1][6] = -0.62110712665211;
   fWeightMatrix1to2[2][6] = 1.33651335235407;
   fWeightMatrix1to2[3][6] = 0.807439620340505;
   fWeightMatrix1to2[4][6] = 1.01220282658393;
   fWeightMatrix1to2[5][6] = -0.290057531769372;
   fWeightMatrix1to2[6][6] = 0.578286815407667;
   fWeightMatrix1to2[7][6] = -0.417735309581236;
   fWeightMatrix1to2[8][6] = -1.6051602589645;
   fWeightMatrix1to2[9][6] = -0.484431629469628;
   fWeightMatrix1to2[10][6] = -1.76860486585253;
   fWeightMatrix1to2[11][6] = -1.38712188580192;
   fWeightMatrix1to2[12][6] = -1.73205649028063;
   fWeightMatrix1to2[0][7] = 1.92429288759466;
   fWeightMatrix1to2[1][7] = -1.68532634297785;
   fWeightMatrix1to2[2][7] = 1.5436972182619;
   fWeightMatrix1to2[3][7] = -1.73567848326274;
   fWeightMatrix1to2[4][7] = 0.993249202394942;
   fWeightMatrix1to2[5][7] = -1.08916890750598;
   fWeightMatrix1to2[6][7] = 0.421707512967262;
   fWeightMatrix1to2[7][7] = 0.628104053033802;
   fWeightMatrix1to2[8][7] = -1.9094432325462;
   fWeightMatrix1to2[9][7] = 0.118562190918106;
   fWeightMatrix1to2[10][7] = 0.362000028445115;
   fWeightMatrix1to2[11][7] = -1.94645901262387;
   fWeightMatrix1to2[12][7] = -1.36590250432881;
   fWeightMatrix1to2[0][8] = -1.88355937703666;
   fWeightMatrix1to2[1][8] = -0.739870306352107;
   fWeightMatrix1to2[2][8] = 2.20368959703063;
   fWeightMatrix1to2[3][8] = -0.760955486010742;
   fWeightMatrix1to2[4][8] = 2.16089072496852;
   fWeightMatrix1to2[5][8] = -0.914628959916312;
   fWeightMatrix1to2[6][8] = -1.07966072234051;
   fWeightMatrix1to2[7][8] = -1.88033752088707;
   fWeightMatrix1to2[8][8] = -0.354489946404637;
   fWeightMatrix1to2[9][8] = -1.05157835697298;
   fWeightMatrix1to2[10][8] = 0.733113603674385;
   fWeightMatrix1to2[11][8] = -1.3528003409653;
   fWeightMatrix1to2[12][8] = -1.04769052476607;
   fWeightMatrix1to2[0][9] = 1.65118982839338;
   fWeightMatrix1to2[1][9] = 0.0736693275963495;
   fWeightMatrix1to2[2][9] = -0.759912821724398;
   fWeightMatrix1to2[3][9] = 1.82095363804204;
   fWeightMatrix1to2[4][9] = -2.7321813399104;
   fWeightMatrix1to2[5][9] = 1.39252927961565;
   fWeightMatrix1to2[6][9] = 1.04536957707061;
   fWeightMatrix1to2[7][9] = -1.19820009569696;
   fWeightMatrix1to2[8][9] = -1.87236976560311;
   fWeightMatrix1to2[9][9] = 0.0340931612477185;
   fWeightMatrix1to2[10][9] = -1.21946360681125;
   fWeightMatrix1to2[11][9] = 0.483900341894824;
   fWeightMatrix1to2[12][9] = 1.69197861890039;
   fWeightMatrix1to2[0][10] = 1.25054045098832;
   fWeightMatrix1to2[1][10] = 1.75350242486958;
   fWeightMatrix1to2[2][10] = -1.2164653905391;
   fWeightMatrix1to2[3][10] = 1.11085580629184;
   fWeightMatrix1to2[4][10] = -2.46936801830584;
   fWeightMatrix1to2[5][10] = 0.597944750215183;
   fWeightMatrix1to2[6][10] = -1.75928460089658;
   fWeightMatrix1to2[7][10] = -1.66424882908472;
   fWeightMatrix1to2[8][10] = 0.0351025080853027;
   fWeightMatrix1to2[9][10] = 1.32959391916117;
   fWeightMatrix1to2[10][10] = 0.644758581389219;
   fWeightMatrix1to2[11][10] = 1.07928776385095;
   fWeightMatrix1to2[12][10] = 0.332781726539566;
   fWeightMatrix1to2[0][11] = -0.172024431328952;
   fWeightMatrix1to2[1][11] = -0.411367438888627;
   fWeightMatrix1to2[2][11] = 0.256337259470943;
   fWeightMatrix1to2[3][11] = 1.93851954566426;
   fWeightMatrix1to2[4][11] = -1.54245444357408;
   fWeightMatrix1to2[5][11] = 0.31578460506273;
   fWeightMatrix1to2[6][11] = -1.72912126179192;
   fWeightMatrix1to2[7][11] = -0.275575241353582;
   fWeightMatrix1to2[8][11] = 0.181230903001206;
   fWeightMatrix1to2[9][11] = 0.192506791060337;
   fWeightMatrix1to2[10][11] = -0.981858200416257;
   fWeightMatrix1to2[11][11] = 0.987167530974751;
   fWeightMatrix1to2[12][11] = 1.83673951169532;
   fWeightMatrix1to2[0][12] = 0.701992073705688;
   fWeightMatrix1to2[1][12] = -0.333516294864722;
   fWeightMatrix1to2[2][12] = -1.05765622849683;
   fWeightMatrix1to2[3][12] = -1.30558633225772;
   fWeightMatrix1to2[4][12] = -1.93401890073608;
   fWeightMatrix1to2[5][12] = 1.04881391579568;
   fWeightMatrix1to2[6][12] = -0.391328610882259;
   fWeightMatrix1to2[7][12] = -0.848860722281726;
   fWeightMatrix1to2[8][12] = 0.407497239476326;
   fWeightMatrix1to2[9][12] = -1.70537144876108;
   fWeightMatrix1to2[10][12] = -0.897102342835276;
   fWeightMatrix1to2[11][12] = -1.62143290171647;
   fWeightMatrix1to2[12][12] = 0.828896463109766;
   fWeightMatrix1to2[0][13] = -1.39756705093209;
   fWeightMatrix1to2[1][13] = -1.88813292407145;
   fWeightMatrix1to2[2][13] = -0.715112566880601;
   fWeightMatrix1to2[3][13] = -0.968762998059991;
   fWeightMatrix1to2[4][13] = -1.59601031392267;
   fWeightMatrix1to2[5][13] = 1.2213519016975;
   fWeightMatrix1to2[6][13] = -1.21868336494277;
   fWeightMatrix1to2[7][13] = -1.36953409202066;
   fWeightMatrix1to2[8][13] = 1.6472080832853;
   fWeightMatrix1to2[9][13] = 0.533362412427184;
   fWeightMatrix1to2[10][13] = 0.323344985831404;
   fWeightMatrix1to2[11][13] = 0.100419722533706;
   fWeightMatrix1to2[12][13] = 1.14378362805196;
   fWeightMatrix1to2[0][14] = 1.71004702309655;
   fWeightMatrix1to2[1][14] = 0.821156863841174;
   fWeightMatrix1to2[2][14] = -0.830667994531007;
   fWeightMatrix1to2[3][14] = -0.501527974091755;
   fWeightMatrix1to2[4][14] = -1.77925555539901;
   fWeightMatrix1to2[5][14] = 0.90651607257886;
   fWeightMatrix1to2[6][14] = 0.588687657833484;
   fWeightMatrix1to2[7][14] = 0.260148931642199;
   fWeightMatrix1to2[8][14] = 1.24188472830913;
   fWeightMatrix1to2[9][14] = 0.917661652015819;
   fWeightMatrix1to2[10][14] = 1.88596452927939;
   fWeightMatrix1to2[11][14] = -1.33740913505005;
   fWeightMatrix1to2[12][14] = 1.94521923324936;
   // weight matrix from layer 2 to 3
   fWeightMatrix2to3[0][0] = 0.001442810519012;
   fWeightMatrix2to3[0][1] = -1.91046603751965;
   fWeightMatrix2to3[0][2] = -0.18633020976169;
   fWeightMatrix2to3[0][3] = -1.02161664955083;
   fWeightMatrix2to3[0][4] = 1.18484263897241;
   fWeightMatrix2to3[0][5] = -0.00593274031389724;
   fWeightMatrix2to3[0][6] = 0.0599296406355454;
   fWeightMatrix2to3[0][7] = -0.0122067251729508;
   fWeightMatrix2to3[0][8] = 1.26487144572669;
   fWeightMatrix2to3[0][9] = 0.00379629847843916;
   fWeightMatrix2to3[0][10] = 1.3736245902501;
   fWeightMatrix2to3[0][11] = 0.00573120846976487;
   fWeightMatrix2to3[0][12] = -1.18898227911736;
   fWeightMatrix2to3[0][13] = 1.54233874339252;
}

inline double ReadMLP3_EC_10x10::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   if (inputValues.size() != (unsigned int)fLayerSize[0]-1) {
      std::cout << "Input vector needs to be of size " << fLayerSize[0]-1 << std::endl;
      return 0;
   }

   for (int l=0; l<fLayers; l++)
      for (int i=0; i<fLayerSize[l]; i++) fWeights[l][i]=0;

   for (int l=0; l<fLayers-1; l++)
      fWeights[l][fLayerSize[l]-1]=1;

   for (int i=0; i<fLayerSize[0]-1; i++)
      fWeights[0][i]=inputValues[i];

   // layer 0 to 1
   for (int o=0; o<fLayerSize[1]-1; o++) {
      for (int i=0; i<fLayerSize[0]; i++) {
         double inputVal = fWeightMatrix0to1[o][i] * fWeights[0][i];
         fWeights[1][o] += inputVal;
      }
      fWeights[1][o] = ActivationFnc(fWeights[1][o]);
   }
   // layer 1 to 2
   for (int o=0; o<fLayerSize[2]-1; o++) {
      for (int i=0; i<fLayerSize[1]; i++) {
         double inputVal = fWeightMatrix1to2[o][i] * fWeights[1][i];
         fWeights[2][o] += inputVal;
      }
      fWeights[2][o] = ActivationFnc(fWeights[2][o]);
   }
   // layer 2 to 3
   for (int o=0; o<fLayerSize[3]; o++) {
      for (int i=0; i<fLayerSize[2]; i++) {
         double inputVal = fWeightMatrix2to3[o][i] * fWeights[2][i];
         fWeights[3][o] += inputVal;
      }
   }

   return fWeights[3][0];
}

double ReadMLP3_EC_10x10::ActivationFnc(double x) const
{
   // hyperbolic tan
   return tanh(x);
}
 
   
// Clean up
inline void ReadMLP3_EC_10x10::Clear() 
{
   // nothing to clear
}
inline double ReadMLP3_EC_10x10::GetMvaValue( const std::vector<double>& inputValues ) const
{
   // classifier response value
   double retval = 0;

   // classifier response, sanity check first
   if (!fStatusIsClean) {
      std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
      retval = 0;
   }
   else {
      if (IsNormalised()) {
         // normalise variables
         std::vector<double> iV;
         int ivar = 0;
         for (std::vector<double>::const_iterator varIt = inputValues.begin();
              varIt != inputValues.end(); varIt++, ivar++) {
            iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
         }
         retval = GetMvaValue__( iV );
      }
      else {
         retval = GetMvaValue__( inputValues );
      }
   }

   return retval;
}

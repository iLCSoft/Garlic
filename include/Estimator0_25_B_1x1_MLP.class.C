// Class: ReadMLP0_25_B_1x1
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : MLP::MLP
TMVA Release   : 3.9.6         [198918]
ROOT Release   : 5.16/00       [331776]
Creator        : reinhard
Date           : Mon Aug 10 10:18:37 2009
Host           : Linux polui02.in2p3.fr 2.6.9-67.0.4.ELsmp #1 SMP Thu Jan 31 16:30:09 CST 2008 i686 i686 i386 GNU/Linux
Dir            : /grid_mnt/data2__polgrid/llr/ilc/reinhard/ILCSoft/TMVA/macros
Training events: 23617


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
Normalise: "True" [Normalise input variables]
V: "False" [Verbose mode]
H: "True" [Print classifier-specific help message]
NCycles: "500" [Number of training cycles]
HiddenLayers: "N+1,N" [Specification of hidden layer architecture (N stands for number of variables; any integers may also be used)]
NeuronType: "tanh" [Neuron activation function type]
TestRate: "5" [Test for overtraining performed at each #th epochs]
# Default:
D: "False" [Use-decorrelated-variables flag (depreciated)]
VarTransform: "None" [Variable transformation method]
VarTransformType: "Signal" [Use signal or background events to derive for variable transformation (the transformation is applied on both types of, course)]
NbinsMVAPdf: "60" [Number of bins used for the PDFs of classifier outputs]
NsmoothMVAPdf: "2" [Number of smoothing iterations for classifier PDFs]
VerboseLevel: "Default" [Verbosity level]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
TxtWeightFilesOnly: "True" [If True: write all training results (weights) as text files (False: some are written in ROOT format)]
NeuronInputType: "sum" [Neuron input function type]
TrainingMethod: "BP" [Train with Back-Propagation (BP - default) or Genetic Algorithm (GA - slower and worse)]
LearningRate: "0.02" [ANN learning rate parameter]
DecayRate: "0.01" [Decay rate for learning parameter]
BPMode: "sequential" [Back-propagation learning mode: sequential or batch]
BatchSize: "-1" [Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 13
ClusterParameters.start       ClusterParameters.start           'F'    [0,27.7265510559]
ClusterParameters.end         ClusterParameters.end             'F'    [0.839602410793,32.7750701904]
ClusterParameters.depth       ClusterParameters.depth           'F'    [-0.357400119305,31.1791763306]
ClusterParameters.E1C/ClusterParameters.Etot_g   ClusterParameters.E1C_D_ClusterParameters.Etot_g     'F'    [0,1]
ClusterParameters.E4C/ClusterParameters.Etot_g   ClusterParameters.E4C_D_ClusterParameters.Etot_g     'F'    [0.0859934836626,1]
ClusterParameters.E9C/ClusterParameters.Etot_g   ClusterParameters.E9C_D_ClusterParameters.Etot_g     'F'    [0.673714876175,1]
ClusterParameters.dirErr      ClusterParameters.dirErr          'F'    [-4.55836197943e-05,1]
ClusterParameters.seedDirErr  ClusterParameters.seedDirErr      'F'    [-4.55836197943e-05,0.999997735023]
ClusterParameters.Width       ClusterParameters.Width           'F'    [0,29.665517807]
ClusterParameters.Eccentricity ClusterParameters.Eccentricity     'F'    [0,0.929417967796]
ClusterParameters.nHits       ClusterParameters.nHits           'F'    [5,23]
ClusterParameters.Volume      ClusterParameters.Volume          'F'    [0,3434447.75]
ClusterParameters.depth-ClusterParameters.start   ClusterParameters.depth_M_ClusterParameters.start     'F'    [-8.76977920532,21.5937633514]


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;
};

#endif

class ReadMLP0_25_B_1x1 : public IClassifierReader {

 public:

   // constructor
   ReadMLP0_25_B_1x1( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadMLP0_25_B_1x1" ),
        fStatusIsClean( true ),
        fNvars( 13 ),
        fIsNormalised( true )
   {      
      // the training input variables
      const char* inputVars[] = { "ClusterParameters.start", "ClusterParameters.end", "ClusterParameters.depth", "ClusterParameters.E1C/ClusterParameters.Etot_g", "ClusterParameters.E4C/ClusterParameters.Etot_g", "ClusterParameters.E9C/ClusterParameters.Etot_g", "ClusterParameters.dirErr", "ClusterParameters.seedDirErr", "ClusterParameters.Width", "ClusterParameters.Eccentricity", "ClusterParameters.nHits", "ClusterParameters.Volume", "ClusterParameters.depth-ClusterParameters.start" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 27.7265510559082;
      fVmin[1] = 0.839602410793304;
      fVmax[1] = 32.7750701904297;
      fVmin[2] = -0.357400119304657;
      fVmax[2] = 31.1791763305664;
      fVmin[3] = 0;
      fVmax[3] = 1;
      fVmin[4] = 0.0859934836626053;
      fVmax[4] = 1;
      fVmin[5] = 0.673714876174927;
      fVmax[5] = 1;
      fVmin[6] = -4.55836197943427e-05;
      fVmax[6] = 1;
      fVmin[7] = -4.55836197943427e-05;
      fVmax[7] = 0.999997735023499;
      fVmin[8] = 0;
      fVmax[8] = 29.6655178070068;
      fVmin[9] = 0;
      fVmax[9] = 0.929417967796326;
      fVmin[10] = 5;
      fVmax[10] = 23;
      fVmin[11] = 0;
      fVmax[11] = 3434447.75;
      fVmin[12] = -8.76977920532227;
      fVmax[12] = 21.5937633514404;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';
      fType[10] = 'F';
      fType[11] = 'F';
      fType[12] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadMLP0_25_B_1x1() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;
   bool fStatusIsClean;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[13];
   double fVmax[13];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[13];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)

   double ActivationFnc(double x) const;

   int fLayers;
   int fLayerSize[4];
   double fWeightMatrix0to1[15][14];   // weight matrix from layer 0 to 1
   double fWeightMatrix1to2[14][15];   // weight matrix from layer 1 to 2
   double fWeightMatrix2to3[1][14];   // weight matrix from layer 2 to 3

   double * fWeights[4];
};

inline void ReadMLP0_25_B_1x1::Initialize()
{
   // build network structure
   fLayers = 4;
   fLayerSize[0] = 14; fWeights[0] = new double[14]; 
   fLayerSize[1] = 15; fWeights[1] = new double[15]; 
   fLayerSize[2] = 14; fWeights[2] = new double[14]; 
   fLayerSize[3] = 1; fWeights[3] = new double[1]; 
   // weight matrix from layer 0 to 1
   fWeightMatrix0to1[0][0] = 0.364744847739967;
   fWeightMatrix0to1[1][0] = 1.99206371235575;
   fWeightMatrix0to1[2][0] = 0.0803376186258538;
   fWeightMatrix0to1[3][0] = 1.70765418703099;
   fWeightMatrix0to1[4][0] = -2.14410101625738;
   fWeightMatrix0to1[5][0] = -1.87041477158092;
   fWeightMatrix0to1[6][0] = -0.665217895743736;
   fWeightMatrix0to1[7][0] = 2.22442471290162;
   fWeightMatrix0to1[8][0] = -2.25057829814023;
   fWeightMatrix0to1[9][0] = 0.756088911218824;
   fWeightMatrix0to1[10][0] = -1.45882619397348;
   fWeightMatrix0to1[11][0] = -0.727147746042116;
   fWeightMatrix0to1[12][0] = -0.547334577283319;
   fWeightMatrix0to1[13][0] = -11.7404887863047;
   fWeightMatrix0to1[0][1] = -0.632481405377251;
   fWeightMatrix0to1[1][1] = 0.681909067330887;
   fWeightMatrix0to1[2][1] = 3.01014529224988;
   fWeightMatrix0to1[3][1] = 1.68973876476362;
   fWeightMatrix0to1[4][1] = 3.77518202461649;
   fWeightMatrix0to1[5][1] = 0.862309204006542;
   fWeightMatrix0to1[6][1] = -0.496025461427769;
   fWeightMatrix0to1[7][1] = -0.633706648686834;
   fWeightMatrix0to1[8][1] = 0.468950926435284;
   fWeightMatrix0to1[9][1] = -3.54467442244605;
   fWeightMatrix0to1[10][1] = -0.908061903093712;
   fWeightMatrix0to1[11][1] = 0.996753085372211;
   fWeightMatrix0to1[12][1] = 0.69917692991721;
   fWeightMatrix0to1[13][1] = 0.235248557442746;
   fWeightMatrix0to1[0][2] = -2.26408672056106;
   fWeightMatrix0to1[1][2] = 0.14078611473655;
   fWeightMatrix0to1[2][2] = -1.36269616121153;
   fWeightMatrix0to1[3][2] = 1.38802852411059;
   fWeightMatrix0to1[4][2] = 1.93713321136459;
   fWeightMatrix0to1[5][2] = -0.672623364340415;
   fWeightMatrix0to1[6][2] = 0.242654289812089;
   fWeightMatrix0to1[7][2] = -0.10091228868047;
   fWeightMatrix0to1[8][2] = -1.83501982579292;
   fWeightMatrix0to1[9][2] = 3.81601879530617;
   fWeightMatrix0to1[10][2] = -0.980237557766498;
   fWeightMatrix0to1[11][2] = 1.83887031869386;
   fWeightMatrix0to1[12][2] = 2.287805253023;
   fWeightMatrix0to1[13][2] = -6.31247809457632;
   fWeightMatrix0to1[0][3] = 2.87206458880288;
   fWeightMatrix0to1[1][3] = 1.212704109477;
   fWeightMatrix0to1[2][3] = 0.154798155225346;
   fWeightMatrix0to1[3][3] = -0.196186384391443;
   fWeightMatrix0to1[4][3] = -0.0821588602181779;
   fWeightMatrix0to1[5][3] = -0.328316643692949;
   fWeightMatrix0to1[6][3] = 1.58430322497795;
   fWeightMatrix0to1[7][3] = 1.00434149697268;
   fWeightMatrix0to1[8][3] = 0.504507592570679;
   fWeightMatrix0to1[9][3] = -0.187143740736178;
   fWeightMatrix0to1[10][3] = -1.39059909128304;
   fWeightMatrix0to1[11][3] = 1.19017124786586;
   fWeightMatrix0to1[12][3] = -0.591532263850292;
   fWeightMatrix0to1[13][3] = 0.0651155671090151;
   fWeightMatrix0to1[0][4] = -1.80136708649216;
   fWeightMatrix0to1[1][4] = -1.7591966327823;
   fWeightMatrix0to1[2][4] = 2.60253469381396;
   fWeightMatrix0to1[3][4] = -0.301096034481374;
   fWeightMatrix0to1[4][4] = -1.20712878964459;
   fWeightMatrix0to1[5][4] = -0.62397494914022;
   fWeightMatrix0to1[6][4] = -0.286876306545743;
   fWeightMatrix0to1[7][4] = 0.0238878455352139;
   fWeightMatrix0to1[8][4] = 1.63228521676246;
   fWeightMatrix0to1[9][4] = 0.86480298610364;
   fWeightMatrix0to1[10][4] = 0.519088498560746;
   fWeightMatrix0to1[11][4] = -1.80272449220379;
   fWeightMatrix0to1[12][4] = -0.795526064314625;
   fWeightMatrix0to1[13][4] = 0.139279955972412;
   fWeightMatrix0to1[0][5] = -1.28585549856698;
   fWeightMatrix0to1[1][5] = -1.4304806945187;
   fWeightMatrix0to1[2][5] = -0.454158853289521;
   fWeightMatrix0to1[3][5] = 0.010936399487014;
   fWeightMatrix0to1[4][5] = 1.55610816779075;
   fWeightMatrix0to1[5][5] = -0.303270581153894;
   fWeightMatrix0to1[6][5] = -1.90063828049388;
   fWeightMatrix0to1[7][5] = -2.55587924321062;
   fWeightMatrix0to1[8][5] = 1.37575209313006;
   fWeightMatrix0to1[9][5] = 0.342157484036374;
   fWeightMatrix0to1[10][5] = 2.30257080974477;
   fWeightMatrix0to1[11][5] = 1.12414363861462;
   fWeightMatrix0to1[12][5] = -0.398115317243008;
   fWeightMatrix0to1[13][5] = -5.48046417346484;
   fWeightMatrix0to1[0][6] = -2.03766867083672;
   fWeightMatrix0to1[1][6] = -0.210310942578502;
   fWeightMatrix0to1[2][6] = -1.28619917362385;
   fWeightMatrix0to1[3][6] = -0.728084843963242;
   fWeightMatrix0to1[4][6] = -1.82711102089071;
   fWeightMatrix0to1[5][6] = -0.861851615174755;
   fWeightMatrix0to1[6][6] = -0.25014834144311;
   fWeightMatrix0to1[7][6] = -0.900408153492342;
   fWeightMatrix0to1[8][6] = 1.23997127237717;
   fWeightMatrix0to1[9][6] = -5.10184544065866;
   fWeightMatrix0to1[10][6] = -0.5143363329749;
   fWeightMatrix0to1[11][6] = 2.0672094968189;
   fWeightMatrix0to1[12][6] = -0.944938229965937;
   fWeightMatrix0to1[13][6] = -0.084557398056083;
   fWeightMatrix0to1[0][7] = -1.49100820064641;
   fWeightMatrix0to1[1][7] = 0.101982229498312;
   fWeightMatrix0to1[2][7] = -0.703871970326354;
   fWeightMatrix0to1[3][7] = -0.500147160588697;
   fWeightMatrix0to1[4][7] = 1.60441652834582;
   fWeightMatrix0to1[5][7] = 1.13974893737725;
   fWeightMatrix0to1[6][7] = -1.18792462866736;
   fWeightMatrix0to1[7][7] = 0.833861270029812;
   fWeightMatrix0to1[8][7] = -0.976038071474674;
   fWeightMatrix0to1[9][7] = 0.602870184776181;
   fWeightMatrix0to1[10][7] = 0.238654381282952;
   fWeightMatrix0to1[11][7] = 0.925378282246277;
   fWeightMatrix0to1[12][7] = -0.293868137907639;
   fWeightMatrix0to1[13][7] = -0.140641129557433;
   fWeightMatrix0to1[0][8] = 1.15953654313361;
   fWeightMatrix0to1[1][8] = 0.455354588660081;
   fWeightMatrix0to1[2][8] = -5.44351721442435;
   fWeightMatrix0to1[3][8] = 2.16490913177054;
   fWeightMatrix0to1[4][8] = 1.10001277735805;
   fWeightMatrix0to1[5][8] = -2.09348037805317;
   fWeightMatrix0to1[6][8] = 0.663009940156185;
   fWeightMatrix0to1[7][8] = -0.707110887406693;
   fWeightMatrix0to1[8][8] = -1.57398045941961;
   fWeightMatrix0to1[9][8] = -4.7336190543613;
   fWeightMatrix0to1[10][8] = -0.698550042191138;
   fWeightMatrix0to1[11][8] = 1.0118529247012;
   fWeightMatrix0to1[12][8] = 1.13677088873049;
   fWeightMatrix0to1[13][8] = 0.262733941448914;
   fWeightMatrix0to1[0][9] = 0.797080257504201;
   fWeightMatrix0to1[1][9] = 0.163146717514044;
   fWeightMatrix0to1[2][9] = -1.41465322555037;
   fWeightMatrix0to1[3][9] = -0.761525601192496;
   fWeightMatrix0to1[4][9] = -1.89928349911598;
   fWeightMatrix0to1[5][9] = -1.2048461520644;
   fWeightMatrix0to1[6][9] = 0.722513186315079;
   fWeightMatrix0to1[7][9] = -1.5943217612042;
   fWeightMatrix0to1[8][9] = -0.0712004503943452;
   fWeightMatrix0to1[9][9] = 1.44596816134972;
   fWeightMatrix0to1[10][9] = 1.37589209837381;
   fWeightMatrix0to1[11][9] = -1.89794176023136;
   fWeightMatrix0to1[12][9] = -0.530802656502604;
   fWeightMatrix0to1[13][9] = 0.166036127455533;
   fWeightMatrix0to1[0][10] = 0.472371434478452;
   fWeightMatrix0to1[1][10] = 0.161139634952408;
   fWeightMatrix0to1[2][10] = 1.25640569641418;
   fWeightMatrix0to1[3][10] = -6.09809456110412;
   fWeightMatrix0to1[4][10] = -2.65352910955634;
   fWeightMatrix0to1[5][10] = 3.47873070820576;
   fWeightMatrix0to1[6][10] = 1.1963476827905;
   fWeightMatrix0to1[7][10] = 0.0812050093944961;
   fWeightMatrix0to1[8][10] = -0.777471405855907;
   fWeightMatrix0to1[9][10] = 2.80642032951922;
   fWeightMatrix0to1[10][10] = -1.71454788139868;
   fWeightMatrix0to1[11][10] = -0.610929344261436;
   fWeightMatrix0to1[12][10] = 0.92632389150825;
   fWeightMatrix0to1[13][10] = -0.906418029068562;
   fWeightMatrix0to1[0][11] = 0.21739618663672;
   fWeightMatrix0to1[1][11] = 0.279758826873987;
   fWeightMatrix0to1[2][11] = 1.54342544340477;
   fWeightMatrix0to1[3][11] = 0.686212472027993;
   fWeightMatrix0to1[4][11] = -0.198544653362983;
   fWeightMatrix0to1[5][11] = -1.34178950153069;
   fWeightMatrix0to1[6][11] = 1.27448927157741;
   fWeightMatrix0to1[7][11] = 1.37930298077013;
   fWeightMatrix0to1[8][11] = -0.723218498582517;
   fWeightMatrix0to1[9][11] = -1.00059905063866;
   fWeightMatrix0to1[10][11] = 0.58758997804392;
   fWeightMatrix0to1[11][11] = -1.4014200626406;
   fWeightMatrix0to1[12][11] = -1.19078218392033;
   fWeightMatrix0to1[13][11] = 5.5050445700214;
   fWeightMatrix0to1[0][12] = -1.63921120043337;
   fWeightMatrix0to1[1][12] = -0.574653292540224;
   fWeightMatrix0to1[2][12] = 0.378811928139653;
   fWeightMatrix0to1[3][12] = 0.450859943111182;
   fWeightMatrix0to1[4][12] = 1.75491955775762;
   fWeightMatrix0to1[5][12] = 1.48434215245788;
   fWeightMatrix0to1[6][12] = 1.77278889192412;
   fWeightMatrix0to1[7][12] = -1.78159709558509;
   fWeightMatrix0to1[8][12] = 0.580528425653127;
   fWeightMatrix0to1[9][12] = 0.10718924182526;
   fWeightMatrix0to1[10][12] = 0.408941587508065;
   fWeightMatrix0to1[11][12] = -0.942636928334886;
   fWeightMatrix0to1[12][12] = -1.4554766307289;
   fWeightMatrix0to1[13][12] = 5.42668626818214;
   fWeightMatrix0to1[0][13] = 0.845103150940447;
   fWeightMatrix0to1[1][13] = -1.74062270362806;
   fWeightMatrix0to1[2][13] = -0.785295288413334;
   fWeightMatrix0to1[3][13] = 0.366099388788423;
   fWeightMatrix0to1[4][13] = 1.70234342618335;
   fWeightMatrix0to1[5][13] = 1.36120472062321;
   fWeightMatrix0to1[6][13] = -0.429203157996749;
   fWeightMatrix0to1[7][13] = -1.09581474012478;
   fWeightMatrix0to1[8][13] = 0.278306249752742;
   fWeightMatrix0to1[9][13] = 2.20623718245293;
   fWeightMatrix0to1[10][13] = 2.10377827235359;
   fWeightMatrix0to1[11][13] = 1.95210428799871;
   fWeightMatrix0to1[12][13] = 1.52760431750279;
   fWeightMatrix0to1[13][13] = -5.22964715643391;
   // weight matrix from layer 1 to 2
   fWeightMatrix1to2[0][0] = -1.64565011719788;
   fWeightMatrix1to2[1][0] = 0.673318917052697;
   fWeightMatrix1to2[2][0] = 0.117049431076607;
   fWeightMatrix1to2[3][0] = 1.27623386429268;
   fWeightMatrix1to2[4][0] = -1.695956536141;
   fWeightMatrix1to2[5][0] = 0.106402352032411;
   fWeightMatrix1to2[6][0] = 1.12407324364131;
   fWeightMatrix1to2[7][0] = -1.22703671837421;
   fWeightMatrix1to2[8][0] = 1.74415963250599;
   fWeightMatrix1to2[9][0] = 1.45386138700103;
   fWeightMatrix1to2[10][0] = -0.665869098606797;
   fWeightMatrix1to2[11][0] = 0.387244610080751;
   fWeightMatrix1to2[12][0] = 1.08895417415947;
   fWeightMatrix1to2[0][1] = 0.628044560187062;
   fWeightMatrix1to2[1][1] = -0.0107127879891531;
   fWeightMatrix1to2[2][1] = -0.730251769259359;
   fWeightMatrix1to2[3][1] = -0.737111587958679;
   fWeightMatrix1to2[4][1] = -1.06470307533937;
   fWeightMatrix1to2[5][1] = 1.58982529195844;
   fWeightMatrix1to2[6][1] = 1.72196623228336;
   fWeightMatrix1to2[7][1] = 1.45532370939317;
   fWeightMatrix1to2[8][1] = 0.914396282488345;
   fWeightMatrix1to2[9][1] = 2.70909003537529;
   fWeightMatrix1to2[10][1] = -1.88845644834113;
   fWeightMatrix1to2[11][1] = -0.347740675767275;
   fWeightMatrix1to2[12][1] = -0.660880094860647;
   fWeightMatrix1to2[0][2] = 1.02714601989423;
   fWeightMatrix1to2[1][2] = 0.512558075832194;
   fWeightMatrix1to2[2][2] = 0.0505108388896403;
   fWeightMatrix1to2[3][2] = -1.16235211944574;
   fWeightMatrix1to2[4][2] = 1.23969078380393;
   fWeightMatrix1to2[5][2] = 0.103862562196851;
   fWeightMatrix1to2[6][2] = -1.60469998861944;
   fWeightMatrix1to2[7][2] = -0.386544583308357;
   fWeightMatrix1to2[8][2] = 0.231353442413085;
   fWeightMatrix1to2[9][2] = 0.717673212749991;
   fWeightMatrix1to2[10][2] = 0.566592767106728;
   fWeightMatrix1to2[11][2] = -0.902284971122755;
   fWeightMatrix1to2[12][2] = 1.23399910017028;
   fWeightMatrix1to2[0][3] = -2.27642070702057;
   fWeightMatrix1to2[1][3] = 0.745334952873651;
   fWeightMatrix1to2[2][3] = 0.235942277216802;
   fWeightMatrix1to2[3][3] = -0.578798283753718;
   fWeightMatrix1to2[4][3] = -0.943459160559232;
   fWeightMatrix1to2[5][3] = -0.0873328745812147;
   fWeightMatrix1to2[6][3] = -1.17012439086643;
   fWeightMatrix1to2[7][3] = -1.58550975408093;
   fWeightMatrix1to2[8][3] = -2.57113403866814;
   fWeightMatrix1to2[9][3] = -0.855235474280957;
   fWeightMatrix1to2[10][3] = 0.582987351688602;
   fWeightMatrix1to2[11][3] = -0.292921761971955;
   fWeightMatrix1to2[12][3] = -1.28216894539228;
   fWeightMatrix1to2[0][4] = 1.46764603651013;
   fWeightMatrix1to2[1][4] = -1.12493716754027;
   fWeightMatrix1to2[2][4] = 0.347170503260744;
   fWeightMatrix1to2[3][4] = 0.152655639602449;
   fWeightMatrix1to2[4][4] = -1.43019326117774;
   fWeightMatrix1to2[5][4] = 1.07674797916053;
   fWeightMatrix1to2[6][4] = 1.72932837010959;
   fWeightMatrix1to2[7][4] = -2.61272811392194;
   fWeightMatrix1to2[8][4] = -1.26585084859287;
   fWeightMatrix1to2[9][4] = -1.00052863637438;
   fWeightMatrix1to2[10][4] = -0.819702184051542;
   fWeightMatrix1to2[11][4] = -2.04116659550432;
   fWeightMatrix1to2[12][4] = 0.36430718314149;
   fWeightMatrix1to2[0][5] = 0.983316907614978;
   fWeightMatrix1to2[1][5] = 1.18546507558453;
   fWeightMatrix1to2[2][5] = 0.0443202689680915;
   fWeightMatrix1to2[3][5] = -0.166229426960802;
   fWeightMatrix1to2[4][5] = 1.08441102705197;
   fWeightMatrix1to2[5][5] = -1.57742045652325;
   fWeightMatrix1to2[6][5] = 1.23851096416176;
   fWeightMatrix1to2[7][5] = 2.49575182752571;
   fWeightMatrix1to2[8][5] = 0.184288529264094;
   fWeightMatrix1to2[9][5] = -1.22219334035371;
   fWeightMatrix1to2[10][5] = 0.497737209212903;
   fWeightMatrix1to2[11][5] = 1.23386907275164;
   fWeightMatrix1to2[12][5] = 0.758374133961754;
   fWeightMatrix1to2[0][6] = -0.843035961917339;
   fWeightMatrix1to2[1][6] = -0.614699967292862;
   fWeightMatrix1to2[2][6] = 0.871337775092157;
   fWeightMatrix1to2[3][6] = 2.22939468719908;
   fWeightMatrix1to2[4][6] = 0.855120879041119;
   fWeightMatrix1to2[5][6] = -0.407418971926828;
   fWeightMatrix1to2[6][6] = 0.661104321810378;
   fWeightMatrix1to2[7][6] = 0.391004147771946;
   fWeightMatrix1to2[8][6] = -0.766897297160035;
   fWeightMatrix1to2[9][6] = 0.142987086645451;
   fWeightMatrix1to2[10][6] = -1.42886316480567;
   fWeightMatrix1to2[11][6] = -0.385302338686484;
   fWeightMatrix1to2[12][6] = -2.07734730044089;
   fWeightMatrix1to2[0][7] = 1.31229426598564;
   fWeightMatrix1to2[1][7] = -1.95475298509297;
   fWeightMatrix1to2[2][7] = 1.06188901220876;
   fWeightMatrix1to2[3][7] = -0.371030085855175;
   fWeightMatrix1to2[4][7] = 0.696175376436043;
   fWeightMatrix1to2[5][7] = -1.20380089749619;
   fWeightMatrix1to2[6][7] = 0.591250882645674;
   fWeightMatrix1to2[7][7] = 1.54754147817146;
   fWeightMatrix1to2[8][7] = -1.1665529364668;
   fWeightMatrix1to2[9][7] = 0.783176971506657;
   fWeightMatrix1to2[10][7] = 0.450861058395433;
   fWeightMatrix1to2[11][7] = -1.05380496942662;
   fWeightMatrix1to2[12][7] = -1.93266878415242;
   fWeightMatrix1to2[0][8] = -1.29599875568763;
   fWeightMatrix1to2[1][8] = -0.378821842511122;
   fWeightMatrix1to2[2][8] = 2.43577290086946;
   fWeightMatrix1to2[3][8] = -1.79402049969976;
   fWeightMatrix1to2[4][8] = 0.418447493014499;
   fWeightMatrix1to2[5][8] = -0.797594393442549;
   fWeightMatrix1to2[6][8] = -1.25431963300106;
   fWeightMatrix1to2[7][8] = -2.11958549424378;
   fWeightMatrix1to2[8][8] = -1.48867757501922;
   fWeightMatrix1to2[9][8] = -1.78925053196509;
   fWeightMatrix1to2[10][8] = 0.820884333686856;
   fWeightMatrix1to2[11][8] = -1.97835243273145;
   fWeightMatrix1to2[12][8] = -0.661624471928615;
   fWeightMatrix1to2[0][9] = 0.86280693396049;
   fWeightMatrix1to2[1][9] = 0.687449406379851;
   fWeightMatrix1to2[2][9] = 0.0386965135282429;
   fWeightMatrix1to2[3][9] = 1.26881168782984;
   fWeightMatrix1to2[4][9] = -1.80033591763783;
   fWeightMatrix1to2[5][9] = 0.0447148624046592;
   fWeightMatrix1to2[6][9] = 0.918616383394079;
   fWeightMatrix1to2[7][9] = -1.68382117649514;
   fWeightMatrix1to2[8][9] = -1.22562897242897;
   fWeightMatrix1to2[9][9] = -0.0640507350346737;
   fWeightMatrix1to2[10][9] = -0.914286788942559;
   fWeightMatrix1to2[11][9] = -1.64492965371257;
   fWeightMatrix1to2[12][9] = 1.51045034610493;
   fWeightMatrix1to2[0][10] = 1.74892873388752;
   fWeightMatrix1to2[1][10] = 1.88254529924855;
   fWeightMatrix1to2[2][10] = -0.772280464350567;
   fWeightMatrix1to2[3][10] = -0.154949121213487;
   fWeightMatrix1to2[4][10] = -1.70650884450187;
   fWeightMatrix1to2[5][10] = 0.726383278777007;
   fWeightMatrix1to2[6][10] = -1.97543011408639;
   fWeightMatrix1to2[7][10] = -2.46614365695836;
   fWeightMatrix1to2[8][10] = -0.747988615341615;
   fWeightMatrix1to2[9][10] = 0.560155690562429;
   fWeightMatrix1to2[10][10] = 0.621401591812997;
   fWeightMatrix1to2[11][10] = 0.179960346952857;
   fWeightMatrix1to2[12][10] = 0.820471817106136;
   fWeightMatrix1to2[0][11] = -0.378880496565146;
   fWeightMatrix1to2[1][11] = -0.462933819130678;
   fWeightMatrix1to2[2][11] = -0.187517982627057;
   fWeightMatrix1to2[3][11] = 2.2220029898284;
   fWeightMatrix1to2[4][11] = -1.8731813329713;
   fWeightMatrix1to2[5][11] = 0.238330382476622;
   fWeightMatrix1to2[6][11] = -1.49958136828894;
   fWeightMatrix1to2[7][11] = 0.315523791981762;
   fWeightMatrix1to2[8][11] = -1.40683710124806;
   fWeightMatrix1to2[9][11] = -0.320340179956246;
   fWeightMatrix1to2[10][11] = -0.817170557119883;
   fWeightMatrix1to2[11][11] = -1.64624791413049;
   fWeightMatrix1to2[12][11] = 2.02006857793406;
   fWeightMatrix1to2[0][12] = 0.797616051548403;
   fWeightMatrix1to2[1][12] = 0.710802815242879;
   fWeightMatrix1to2[2][12] = -0.0209466695848185;
   fWeightMatrix1to2[3][12] = -1.80459110842718;
   fWeightMatrix1to2[4][12] = -1.86084227250274;
   fWeightMatrix1to2[5][12] = 0.401878296621188;
   fWeightMatrix1to2[6][12] = -1.31697998108788;
   fWeightMatrix1to2[7][12] = -3.04701495683608;
   fWeightMatrix1to2[8][12] = -1.89222903939438;
   fWeightMatrix1to2[9][12] = -1.28472920650409;
   fWeightMatrix1to2[10][12] = -1.27865202115827;
   fWeightMatrix1to2[11][12] = -2.88538797918452;
   fWeightMatrix1to2[12][12] = 0.842703437997866;
   fWeightMatrix1to2[0][13] = -1.31049227843191;
   fWeightMatrix1to2[1][13] = -2.45074027013175;
   fWeightMatrix1to2[2][13] = -0.0237392934881857;
   fWeightMatrix1to2[3][13] = -0.796799099898946;
   fWeightMatrix1to2[4][13] = -1.27027274422673;
   fWeightMatrix1to2[5][13] = 0.60181353748174;
   fWeightMatrix1to2[6][13] = -2.40574184907986;
   fWeightMatrix1to2[7][13] = -3.98876606059846;
   fWeightMatrix1to2[8][13] = -1.26375392883466;
   fWeightMatrix1to2[9][13] = 0.0886189801117391;
   fWeightMatrix1to2[10][13] = 0.783121325184957;
   fWeightMatrix1to2[11][13] = -3.93576737232152;
   fWeightMatrix1to2[12][13] = 0.837046840679438;
   fWeightMatrix1to2[0][14] = 2.12956263719217;
   fWeightMatrix1to2[1][14] = 0.99830624840424;
   fWeightMatrix1to2[2][14] = -0.347011577295585;
   fWeightMatrix1to2[3][14] = -1.90270207324448;
   fWeightMatrix1to2[4][14] = -1.59738590273302;
   fWeightMatrix1to2[5][14] = 1.0404117419673;
   fWeightMatrix1to2[6][14] = 0.543881955877435;
   fWeightMatrix1to2[7][14] = -0.603166217374948;
   fWeightMatrix1to2[8][14] = 0.378236439778439;
   fWeightMatrix1to2[9][14] = 0.226580723392413;
   fWeightMatrix1to2[10][14] = 1.79888235145848;
   fWeightMatrix1to2[11][14] = -2.30441161639921;
   fWeightMatrix1to2[12][14] = 2.27866715731405;
   // weight matrix from layer 2 to 3
   fWeightMatrix2to3[0][0] = 0.310649010266336;
   fWeightMatrix2to3[0][1] = -1.34406791513403;
   fWeightMatrix2to3[0][2] = 0.0762192444652466;
   fWeightMatrix2to3[0][3] = 0.216595607720861;
   fWeightMatrix2to3[0][4] = 0.289159556789949;
   fWeightMatrix2to3[0][5] = 0.036403591498546;
   fWeightMatrix2to3[0][6] = 0.174814294521475;
   fWeightMatrix2to3[0][7] = 0.303414240698448;
   fWeightMatrix2to3[0][8] = 0.0410689307938969;
   fWeightMatrix2to3[0][9] = 1.33985823544773;
   fWeightMatrix2to3[0][10] = 1.49391185736948;
   fWeightMatrix2to3[0][11] = 0.373392689704547;
   fWeightMatrix2to3[0][12] = -0.398121702301575;
   fWeightMatrix2to3[0][13] = 1.66378542408365;
}

inline double ReadMLP0_25_B_1x1::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   if (inputValues.size() != (unsigned int)fLayerSize[0]-1) {
      std::cout << "Input vector needs to be of size " << fLayerSize[0]-1 << std::endl;
      return 0;
   }

   for (int l=0; l<fLayers; l++)
      for (int i=0; i<fLayerSize[l]; i++) fWeights[l][i]=0;

   for (int l=0; l<fLayers-1; l++)
      fWeights[l][fLayerSize[l]-1]=1;

   for (int i=0; i<fLayerSize[0]-1; i++)
      fWeights[0][i]=inputValues[i];

   // layer 0 to 1
   for (int o=0; o<fLayerSize[1]-1; o++) {
      for (int i=0; i<fLayerSize[0]; i++) {
         double inputVal = fWeightMatrix0to1[o][i] * fWeights[0][i];
         fWeights[1][o] += inputVal;
      }
      fWeights[1][o] = ActivationFnc(fWeights[1][o]);
   }
   // layer 1 to 2
   for (int o=0; o<fLayerSize[2]-1; o++) {
      for (int i=0; i<fLayerSize[1]; i++) {
         double inputVal = fWeightMatrix1to2[o][i] * fWeights[1][i];
         fWeights[2][o] += inputVal;
      }
      fWeights[2][o] = ActivationFnc(fWeights[2][o]);
   }
   // layer 2 to 3
   for (int o=0; o<fLayerSize[3]; o++) {
      for (int i=0; i<fLayerSize[2]; i++) {
         double inputVal = fWeightMatrix2to3[o][i] * fWeights[2][i];
         fWeights[3][o] += inputVal;
      }
   }

   return fWeights[3][0];
}

double ReadMLP0_25_B_1x1::ActivationFnc(double x) const
{
   // hyperbolic tan
   return tanh(x);
}
 
   
// Clean up
inline void ReadMLP0_25_B_1x1::Clear() 
{
   // nothing to clear
}
inline double ReadMLP0_25_B_1x1::GetMvaValue( const std::vector<double>& inputValues ) const
{
   // classifier response value
   double retval = 0;

   // classifier response, sanity check first
   if (!fStatusIsClean) {
      std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
      retval = 0;
   }
   else {
      if (IsNormalised()) {
         // normalise variables
         std::vector<double> iV;
         int ivar = 0;
         for (std::vector<double>::const_iterator varIt = inputValues.begin();
              varIt != inputValues.end(); varIt++, ivar++) {
            iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
         }
         retval = GetMvaValue__( iV );
      }
      else {
         retval = GetMvaValue__( inputValues );
      }
   }

   return retval;
}

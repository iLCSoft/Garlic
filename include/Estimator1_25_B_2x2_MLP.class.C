// Class: ReadMLP1_25_B_2x2
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : MLP::MLP
TMVA Release   : 3.9.6         [198918]
ROOT Release   : 5.16/00       [331776]
Creator        : reinhard
Date           : Tue Aug 11 12:36:08 2009
Host           : Linux polui02.in2p3.fr 2.6.9-67.0.4.ELsmp #1 SMP Thu Jan 31 16:30:09 CST 2008 i686 i686 i386 GNU/Linux
Dir            : /grid_mnt/data2__polgrid/llr/ilc/reinhard/ILCSoft/TMVA/macros
Training events: 6825


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
Normalise: "True" [Normalise input variables]
V: "False" [Verbose mode]
H: "True" [Print classifier-specific help message]
NCycles: "500" [Number of training cycles]
HiddenLayers: "N+1,N" [Specification of hidden layer architecture (N stands for number of variables; any integers may also be used)]
NeuronType: "tanh" [Neuron activation function type]
TestRate: "5" [Test for overtraining performed at each #th epochs]
# Default:
D: "False" [Use-decorrelated-variables flag (depreciated)]
VarTransform: "None" [Variable transformation method]
VarTransformType: "Signal" [Use signal or background events to derive for variable transformation (the transformation is applied on both types of, course)]
NbinsMVAPdf: "60" [Number of bins used for the PDFs of classifier outputs]
NsmoothMVAPdf: "2" [Number of smoothing iterations for classifier PDFs]
VerboseLevel: "Default" [Verbosity level]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
TxtWeightFilesOnly: "True" [If True: write all training results (weights) as text files (False: some are written in ROOT format)]
NeuronInputType: "sum" [Neuron input function type]
TrainingMethod: "BP" [Train with Back-Propagation (BP - default) or Genetic Algorithm (GA - slower and worse)]
LearningRate: "0.02" [ANN learning rate parameter]
DecayRate: "0.01" [Decay rate for learning parameter]
BPMode: "sequential" [Back-propagation learning mode: sequential or batch]
BatchSize: "-1" [Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 13
ClusterParameters.start       ClusterParameters.start           'F'    [0,10.4493722916]
ClusterParameters.end         ClusterParameters.end             'F'    [1.00448131561,42.3592071533]
ClusterParameters.depth       ClusterParameters.depth           'F'    [0,32.3530502319]
ClusterParameters.E1C/ClusterParameters.Etot_g   ClusterParameters.E1C_D_ClusterParameters.Etot_g     'F'    [0,0.975909113884]
ClusterParameters.E4C/ClusterParameters.Etot_g   ClusterParameters.E4C_D_ClusterParameters.Etot_g     'F'    [0.0486153177917,1]
ClusterParameters.E9C/ClusterParameters.Etot_g   ClusterParameters.E9C_D_ClusterParameters.Etot_g     'F'    [0.627634048462,1]
ClusterParameters.dirErr      ClusterParameters.dirErr          'F'    [0.00739368144423,0.999999701977]
ClusterParameters.seedDirErr  ClusterParameters.seedDirErr      'F'    [0,0.999983966351]
ClusterParameters.Width       ClusterParameters.Width           'F'    [1.69761300087,51.8667030334]
ClusterParameters.Eccentricity ClusterParameters.Eccentricity     'F'    [0.114878006279,0.874837517738]
ClusterParameters.nHits       ClusterParameters.nHits           'F'    [5,61]
ClusterParameters.Volume      ClusterParameters.Volume          'F'    [187.734802246,3805524]
ClusterParameters.depth-ClusterParameters.start   ClusterParameters.depth_M_ClusterParameters.start     'F'    [-6.69123601913,29.9705848694]


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;
};

#endif

class ReadMLP1_25_B_2x2 : public IClassifierReader {

 public:

   // constructor
   ReadMLP1_25_B_2x2( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadMLP1_25_B_2x2" ),
        fStatusIsClean( true ),
        fNvars( 13 ),
        fIsNormalised( true )
   {      
      // the training input variables
      const char* inputVars[] = { "ClusterParameters.start", "ClusterParameters.end", "ClusterParameters.depth", "ClusterParameters.E1C/ClusterParameters.Etot_g", "ClusterParameters.E4C/ClusterParameters.Etot_g", "ClusterParameters.E9C/ClusterParameters.Etot_g", "ClusterParameters.dirErr", "ClusterParameters.seedDirErr", "ClusterParameters.Width", "ClusterParameters.Eccentricity", "ClusterParameters.nHits", "ClusterParameters.Volume", "ClusterParameters.depth-ClusterParameters.start" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 10.4493722915649;
      fVmin[1] = 1.00448131561279;
      fVmax[1] = 42.3592071533203;
      fVmin[2] = 0;
      fVmax[2] = 32.3530502319336;
      fVmin[3] = 0;
      fVmax[3] = 0.975909113883972;
      fVmin[4] = 0.0486153177917004;
      fVmax[4] = 1;
      fVmin[5] = 0.627634048461914;
      fVmax[5] = 1;
      fVmin[6] = 0.0073936814442277;
      fVmax[6] = 0.999999701976776;
      fVmin[7] = 0;
      fVmax[7] = 0.999983966350555;
      fVmin[8] = 1.69761300086975;
      fVmax[8] = 51.8667030334473;
      fVmin[9] = 0.114878006279469;
      fVmax[9] = 0.874837517738342;
      fVmin[10] = 5;
      fVmax[10] = 61;
      fVmin[11] = 187.734802246094;
      fVmax[11] = 3805524;
      fVmin[12] = -6.69123601913452;
      fVmax[12] = 29.9705848693848;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';
      fType[10] = 'F';
      fType[11] = 'F';
      fType[12] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadMLP1_25_B_2x2() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;
   bool fStatusIsClean;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[13];
   double fVmax[13];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[13];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)

   double ActivationFnc(double x) const;

   int fLayers;
   int fLayerSize[4];
   double fWeightMatrix0to1[15][14];   // weight matrix from layer 0 to 1
   double fWeightMatrix1to2[14][15];   // weight matrix from layer 1 to 2
   double fWeightMatrix2to3[1][14];   // weight matrix from layer 2 to 3

   double * fWeights[4];
};

inline void ReadMLP1_25_B_2x2::Initialize()
{
   // build network structure
   fLayers = 4;
   fLayerSize[0] = 14; fWeights[0] = new double[14]; 
   fLayerSize[1] = 15; fWeights[1] = new double[15]; 
   fLayerSize[2] = 14; fWeights[2] = new double[14]; 
   fLayerSize[3] = 1; fWeights[3] = new double[1]; 
   // weight matrix from layer 0 to 1
   fWeightMatrix0to1[0][0] = 0.345077584026174;
   fWeightMatrix0to1[1][0] = 2.01765749557837;
   fWeightMatrix0to1[2][0] = 0.701757138035332;
   fWeightMatrix0to1[3][0] = 2.59577445887162;
   fWeightMatrix0to1[4][0] = -0.0435234464438839;
   fWeightMatrix0to1[5][0] = -1.52621208247494;
   fWeightMatrix0to1[6][0] = -0.806834825264473;
   fWeightMatrix0to1[7][0] = 1.51059937055715;
   fWeightMatrix0to1[8][0] = -1.57734673286582;
   fWeightMatrix0to1[9][0] = -1.03495652700463;
   fWeightMatrix0to1[10][0] = -1.60674856756791;
   fWeightMatrix0to1[11][0] = -0.174643038968399;
   fWeightMatrix0to1[12][0] = -1.79033159371941;
   fWeightMatrix0to1[13][0] = -0.364786983829601;
   fWeightMatrix0to1[0][1] = -1.0412386018346;
   fWeightMatrix0to1[1][1] = 0.661410875216257;
   fWeightMatrix0to1[2][1] = -0.804750275037284;
   fWeightMatrix0to1[3][1] = 1.68835654534719;
   fWeightMatrix0to1[4][1] = -0.135030082820973;
   fWeightMatrix0to1[5][1] = 1.18493142999685;
   fWeightMatrix0to1[6][1] = -0.34294083339906;
   fWeightMatrix0to1[7][1] = -0.96868064716216;
   fWeightMatrix0to1[8][1] = 0.662752240537176;
   fWeightMatrix0to1[9][1] = 0.959036643013315;
   fWeightMatrix0to1[10][1] = -1.18223410388532;
   fWeightMatrix0to1[11][1] = 0.119361929836;
   fWeightMatrix0to1[12][1] = 0.775652363226844;
   fWeightMatrix0to1[13][1] = -1.03171600984307;
   fWeightMatrix0to1[0][2] = -2.0171698720084;
   fWeightMatrix0to1[1][2] = 0.172157728248897;
   fWeightMatrix0to1[2][2] = -0.10945863485227;
   fWeightMatrix0to1[3][2] = 1.81488297170523;
   fWeightMatrix0to1[4][2] = 0.627312288282373;
   fWeightMatrix0to1[5][2] = -0.401895188085624;
   fWeightMatrix0to1[6][2] = 0.216215115812107;
   fWeightMatrix0to1[7][2] = -1.09422030464139;
   fWeightMatrix0to1[8][2] = -1.74468776785079;
   fWeightMatrix0to1[9][2] = 2.72556243098692;
   fWeightMatrix0to1[10][2] = -1.32005503450851;
   fWeightMatrix0to1[11][2] = 1.31665928362855;
   fWeightMatrix0to1[12][2] = 1.63560386815953;
   fWeightMatrix0to1[13][2] = 0.909302622716229;
   fWeightMatrix0to1[0][3] = 3.04341340510955;
   fWeightMatrix0to1[1][3] = 1.27991830209252;
   fWeightMatrix0to1[2][3] = -0.104185226789539;
   fWeightMatrix0to1[3][3] = -1.45541760691521;
   fWeightMatrix0to1[4][3] = -0.612185745217153;
   fWeightMatrix0to1[5][3] = 0.308665337034913;
   fWeightMatrix0to1[6][3] = 1.47908900342443;
   fWeightMatrix0to1[7][3] = 1.15544509833475;
   fWeightMatrix0to1[8][3] = 1.06160460173363;
   fWeightMatrix0to1[9][3] = 1.61281600764864;
   fWeightMatrix0to1[10][3] = -1.39300282766817;
   fWeightMatrix0to1[11][3] = 1.81233030497557;
   fWeightMatrix0to1[12][3] = -1.4397327552244;
   fWeightMatrix0to1[13][3] = -0.897967714847002;
   fWeightMatrix0to1[0][4] = -1.13114967172212;
   fWeightMatrix0to1[1][4] = -1.71677928813401;
   fWeightMatrix0to1[2][4] = 2.00625481146497;
   fWeightMatrix0to1[3][4] = 0.450713382707636;
   fWeightMatrix0to1[4][4] = -1.19809996844286;
   fWeightMatrix0to1[5][4] = 0.814322947110775;
   fWeightMatrix0to1[6][4] = -0.314707180952076;
   fWeightMatrix0to1[7][4] = 0.213980933001361;
   fWeightMatrix0to1[8][4] = 1.86294398163841;
   fWeightMatrix0to1[9][4] = 0.40403072715762;
   fWeightMatrix0to1[10][4] = 0.260362010012304;
   fWeightMatrix0to1[11][4] = -1.18520997447877;
   fWeightMatrix0to1[12][4] = -1.26607294140633;
   fWeightMatrix0to1[13][4] = -0.872654770202986;
   fWeightMatrix0to1[0][5] = -1.29961717380431;
   fWeightMatrix0to1[1][5] = -1.40994792206384;
   fWeightMatrix0to1[2][5] = 1.06086273694459;
   fWeightMatrix0to1[3][5] = 1.17346371160222;
   fWeightMatrix0to1[4][5] = 1.95049843634826;
   fWeightMatrix0to1[5][5] = 0.223147219714359;
   fWeightMatrix0to1[6][5] = -1.98358758443141;
   fWeightMatrix0to1[7][5] = -2.15854798644672;
   fWeightMatrix0to1[8][5] = 1.33635771758545;
   fWeightMatrix0to1[9][5] = 0.5397988882991;
   fWeightMatrix0to1[10][5] = 1.95681127170386;
   fWeightMatrix0to1[11][5] = 0.472200105469616;
   fWeightMatrix0to1[12][5] = 1.57276856461216;
   fWeightMatrix0to1[13][5] = -0.859535419725249;
   fWeightMatrix0to1[0][6] = -0.856770913462984;
   fWeightMatrix0to1[1][6] = -0.286848355289586;
   fWeightMatrix0to1[2][6] = 1.20185737595615;
   fWeightMatrix0to1[3][6] = -1.26053908076267;
   fWeightMatrix0to1[4][6] = -2.4780151305014;
   fWeightMatrix0to1[5][6] = -1.22737035250695;
   fWeightMatrix0to1[6][6] = -0.176083612394388;
   fWeightMatrix0to1[7][6] = -0.568122897740177;
   fWeightMatrix0to1[8][6] = 2.00353901553157;
   fWeightMatrix0to1[9][6] = -1.37803059003225;
   fWeightMatrix0to1[10][6] = -0.785231598992939;
   fWeightMatrix0to1[11][6] = 1.63444990898259;
   fWeightMatrix0to1[12][6] = -2.00082688399755;
   fWeightMatrix0to1[13][6] = -1.48279800066926;
   fWeightMatrix0to1[0][7] = -0.496280204750988;
   fWeightMatrix0to1[1][7] = 0.034224514893939;
   fWeightMatrix0to1[2][7] = -1.72829995731891;
   fWeightMatrix0to1[3][7] = -0.964050793574165;
   fWeightMatrix0to1[4][7] = -0.512366615554515;
   fWeightMatrix0to1[5][7] = 1.52121876779377;
   fWeightMatrix0to1[6][7] = -1.11969924515326;
   fWeightMatrix0to1[7][7] = 0.758485216047856;
   fWeightMatrix0to1[8][7] = -0.623076955505497;
   fWeightMatrix0to1[9][7] = -0.561995973863625;
   fWeightMatrix0to1[10][7] = -0.0318026121041619;
   fWeightMatrix0to1[11][7] = 0.632383722268233;
   fWeightMatrix0to1[12][7] = -0.123271377504322;
   fWeightMatrix0to1[13][7] = 0.277118331416048;
   fWeightMatrix0to1[0][8] = -0.410726345574876;
   fWeightMatrix0to1[1][8] = 0.401531154997146;
   fWeightMatrix0to1[2][8] = -1.81863703875655;
   fWeightMatrix0to1[3][8] = 1.80883702321695;
   fWeightMatrix0to1[4][8] = 2.79758631584946;
   fWeightMatrix0to1[5][8] = -1.18815983681203;
   fWeightMatrix0to1[6][8] = 0.833023680688008;
   fWeightMatrix0to1[7][8] = -0.994517697556317;
   fWeightMatrix0to1[8][8] = -1.58489713905591;
   fWeightMatrix0to1[9][8] = 0.404255922100221;
   fWeightMatrix0to1[10][8] = -0.45910816734647;
   fWeightMatrix0to1[11][8] = 1.9674085178925;
   fWeightMatrix0to1[12][8] = 2.93473762322692;
   fWeightMatrix0to1[13][8] = -0.00555025304564453;
   fWeightMatrix0to1[0][9] = 0.597160441949239;
   fWeightMatrix0to1[1][9] = 0.180320325506263;
   fWeightMatrix0to1[2][9] = -1.89276125259861;
   fWeightMatrix0to1[3][9] = 0.375182831845274;
   fWeightMatrix0to1[4][9] = -0.189581481303349;
   fWeightMatrix0to1[5][9] = -1.45969439611779;
   fWeightMatrix0to1[6][9] = 0.649383469348013;
   fWeightMatrix0to1[7][9] = -1.66001087382698;
   fWeightMatrix0to1[8][9] = 0.0573833090070727;
   fWeightMatrix0to1[9][9] = 0.558543118316826;
   fWeightMatrix0to1[10][9] = 1.70187211445895;
   fWeightMatrix0to1[11][9] = -1.73357828764362;
   fWeightMatrix0to1[12][9] = -0.0612095035241447;
   fWeightMatrix0to1[13][9] = 1.48907402944371;
   fWeightMatrix0to1[0][10] = 1.25482931317497;
   fWeightMatrix0to1[1][10] = 0.127356247290393;
   fWeightMatrix0to1[2][10] = -2.11768304127821;
   fWeightMatrix0to1[3][10] = -0.207905391771101;
   fWeightMatrix0to1[4][10] = -4.02922417874531;
   fWeightMatrix0to1[5][10] = 1.12405020849447;
   fWeightMatrix0to1[6][10] = 1.25664516850306;
   fWeightMatrix0to1[7][10] = -1.26315148808162;
   fWeightMatrix0to1[8][10] = -0.324639558941855;
   fWeightMatrix0to1[9][10] = -0.738705431843062;
   fWeightMatrix0to1[10][10] = -1.5012844359016;
   fWeightMatrix0to1[11][10] = -0.134091866069466;
   fWeightMatrix0to1[12][10] = 2.19892541278251;
   fWeightMatrix0to1[13][10] = -0.541500825296463;
   fWeightMatrix0to1[0][11] = -0.468956359042839;
   fWeightMatrix0to1[1][11] = 0.256038476696142;
   fWeightMatrix0to1[2][11] = 0.603241692259229;
   fWeightMatrix0to1[3][11] = 0.593432116429005;
   fWeightMatrix0to1[4][11] = 0.150504898699859;
   fWeightMatrix0to1[5][11] = -2.10270103269749;
   fWeightMatrix0to1[6][11] = 1.51889781489101;
   fWeightMatrix0to1[7][11] = 1.11915524975464;
   fWeightMatrix0to1[8][11] = 0.103984377556304;
   fWeightMatrix0to1[9][11] = 0.459585946547126;
   fWeightMatrix0to1[10][11] = 0.949120220291262;
   fWeightMatrix0to1[11][11] = -0.484947568578836;
   fWeightMatrix0to1[12][11] = -0.0682308325763365;
   fWeightMatrix0to1[13][11] = 1.14748518083602;
   fWeightMatrix0to1[0][12] = -1.20153910712983;
   fWeightMatrix0to1[1][12] = -0.548626918410274;
   fWeightMatrix0to1[2][12] = 0.922826401373283;
   fWeightMatrix0to1[3][12] = 0.902831301155563;
   fWeightMatrix0to1[4][12] = -0.0522869248505631;
   fWeightMatrix0to1[5][12] = 1.30781184932973;
   fWeightMatrix0to1[6][12] = 1.84582099163479;
   fWeightMatrix0to1[7][12] = -2.52892149836142;
   fWeightMatrix0to1[8][12] = 0.405118588966565;
   fWeightMatrix0to1[9][12] = 0.836749996424607;
   fWeightMatrix0to1[10][12] = 0.379637018791156;
   fWeightMatrix0to1[11][12] = -1.59098853221278;
   fWeightMatrix0to1[12][12] = -1.02910061208158;
   fWeightMatrix0to1[13][12] = 1.16778655595853;
   fWeightMatrix0to1[0][13] = 1.17081885350476;
   fWeightMatrix0to1[1][13] = -1.82478330474878;
   fWeightMatrix0to1[2][13] = 0.161169553174615;
   fWeightMatrix0to1[3][13] = -0.5263145812779;
   fWeightMatrix0to1[4][13] = 1.71632311571289;
   fWeightMatrix0to1[5][13] = 2.43331963637863;
   fWeightMatrix0to1[6][13] = -0.319966288919369;
   fWeightMatrix0to1[7][13] = -0.667320578007662;
   fWeightMatrix0to1[8][13] = -0.378925983409894;
   fWeightMatrix0to1[9][13] = 1.18362109024842;
   fWeightMatrix0to1[10][13] = 1.64259343468458;
   fWeightMatrix0to1[11][13] = 1.01333714795746;
   fWeightMatrix0to1[12][13] = 0.893198506929576;
   fWeightMatrix0to1[13][13] = -0.893628058633534;
   // weight matrix from layer 1 to 2
   fWeightMatrix1to2[0][0] = -1.80713058886554;
   fWeightMatrix1to2[1][0] = 1.07073219581959;
   fWeightMatrix1to2[2][0] = 0.20178389833731;
   fWeightMatrix1to2[3][0] = -1.38128365339042;
   fWeightMatrix1to2[4][0] = -0.295895335031456;
   fWeightMatrix1to2[5][0] = 0.274408477047437;
   fWeightMatrix1to2[6][0] = 0.15394950176411;
   fWeightMatrix1to2[7][0] = -1.93395034720445;
   fWeightMatrix1to2[8][0] = 1.50841330544451;
   fWeightMatrix1to2[9][0] = 1.49741397780158;
   fWeightMatrix1to2[10][0] = -0.476296861526865;
   fWeightMatrix1to2[11][0] = -0.145955431598533;
   fWeightMatrix1to2[12][0] = 1.3658858360649;
   fWeightMatrix1to2[0][1] = 1.16185575540777;
   fWeightMatrix1to2[1][1] = 0.362067972763493;
   fWeightMatrix1to2[2][1] = -0.289710972297822;
   fWeightMatrix1to2[3][1] = -1.91192709893205;
   fWeightMatrix1to2[4][1] = -1.06332423983038;
   fWeightMatrix1to2[5][1] = 1.66166327360088;
   fWeightMatrix1to2[6][1] = 1.50994633649987;
   fWeightMatrix1to2[7][1] = 0.300519209448397;
   fWeightMatrix1to2[8][1] = 0.248378830760268;
   fWeightMatrix1to2[9][1] = 2.61002505695852;
   fWeightMatrix1to2[10][1] = -1.80565512495604;
   fWeightMatrix1to2[11][1] = -1.27267291532606;
   fWeightMatrix1to2[12][1] = -0.451420322045106;
   fWeightMatrix1to2[0][2] = -1.56082746477128;
   fWeightMatrix1to2[1][2] = 1.12293476882165;
   fWeightMatrix1to2[2][2] = 1.84422335123503;
   fWeightMatrix1to2[3][2] = -1.34885838225511;
   fWeightMatrix1to2[4][2] = 0.984909196206532;
   fWeightMatrix1to2[5][2] = -0.215763198956251;
   fWeightMatrix1to2[6][2] = -1.61233473332633;
   fWeightMatrix1to2[7][2] = -0.705328887334103;
   fWeightMatrix1to2[8][2] = 0.952381945642225;
   fWeightMatrix1to2[9][2] = 0.918740107129416;
   fWeightMatrix1to2[10][2] = 0.903984946143278;
   fWeightMatrix1to2[11][2] = -1.16280699618435;
   fWeightMatrix1to2[12][2] = 1.99090423405122;
   fWeightMatrix1to2[0][3] = -1.70419145778061;
   fWeightMatrix1to2[1][3] = 0.670555560355274;
   fWeightMatrix1to2[2][3] = -0.0851557870205176;
   fWeightMatrix1to2[3][3] = -1.56930240347318;
   fWeightMatrix1to2[4][3] = -1.49357546079273;
   fWeightMatrix1to2[5][3] = -1.91810486589833;
   fWeightMatrix1to2[6][3] = -0.234043862692415;
   fWeightMatrix1to2[7][3] = -2.09752679057637;
   fWeightMatrix1to2[8][3] = -1.45383655958361;
   fWeightMatrix1to2[9][3] = -1.76094707995657;
   fWeightMatrix1to2[10][3] = -0.0142617542811893;
   fWeightMatrix1to2[11][3] = -0.962997668174365;
   fWeightMatrix1to2[12][3] = -1.65131694896558;
   fWeightMatrix1to2[0][4] = 1.57779639687074;
   fWeightMatrix1to2[1][4] = -0.879262158082183;
   fWeightMatrix1to2[2][4] = 0.0194410948110176;
   fWeightMatrix1to2[3][4] = -1.15810310201513;
   fWeightMatrix1to2[4][4] = 0.0639420321335188;
   fWeightMatrix1to2[5][4] = 1.86301868117844;
   fWeightMatrix1to2[6][4] = 1.2520127222279;
   fWeightMatrix1to2[7][4] = -1.20047408871057;
   fWeightMatrix1to2[8][4] = -1.50032265371495;
   fWeightMatrix1to2[9][4] = -3.43415800857661;
   fWeightMatrix1to2[10][4] = -0.861033528166055;
   fWeightMatrix1to2[11][4] = -1.67833862662684;
   fWeightMatrix1to2[12][4] = 0.374274005714965;
   fWeightMatrix1to2[0][5] = 0.087116231329365;
   fWeightMatrix1to2[1][5] = 1.99033794940727;
   fWeightMatrix1to2[2][5] = -0.141954699978819;
   fWeightMatrix1to2[3][5] = 0.275760783420816;
   fWeightMatrix1to2[4][5] = -0.372880394041546;
   fWeightMatrix1to2[5][5] = -1.85333193949524;
   fWeightMatrix1to2[6][5] = 1.06623796134181;
   fWeightMatrix1to2[7][5] = 1.48438123325557;
   fWeightMatrix1to2[8][5] = -0.878275304578639;
   fWeightMatrix1to2[9][5] = -1.55044023036577;
   fWeightMatrix1to2[10][5] = 0.979885803668042;
   fWeightMatrix1to2[11][5] = 1.17312940672563;
   fWeightMatrix1to2[12][5] = 0.662837733616384;
   fWeightMatrix1to2[0][6] = -0.348315522899867;
   fWeightMatrix1to2[1][6] = -0.461177564926601;
   fWeightMatrix1to2[2][6] = 1.29485207931036;
   fWeightMatrix1to2[3][6] = 1.03206361850763;
   fWeightMatrix1to2[4][6] = 0.851941437462236;
   fWeightMatrix1to2[5][6] = -0.346418450525132;
   fWeightMatrix1to2[6][6] = 0.4102128417354;
   fWeightMatrix1to2[7][6] = -0.748118791037858;
   fWeightMatrix1to2[8][6] = -1.40314758295508;
   fWeightMatrix1to2[9][6] = 0.0527106219965443;
   fWeightMatrix1to2[10][6] = -1.71281068549527;
   fWeightMatrix1to2[11][6] = -1.34851155832561;
   fWeightMatrix1to2[12][6] = -1.93282535735594;
   fWeightMatrix1to2[0][7] = 1.64868141545663;
   fWeightMatrix1to2[1][7] = -1.60102059817163;
   fWeightMatrix1to2[2][7] = 1.53352563150117;
   fWeightMatrix1to2[3][7] = -1.50282821454188;
   fWeightMatrix1to2[4][7] = 0.941448470676157;
   fWeightMatrix1to2[5][7] = -1.19575219012179;
   fWeightMatrix1to2[6][7] = 0.516107635057523;
   fWeightMatrix1to2[7][7] = 0.417603645211021;
   fWeightMatrix1to2[8][7] = -1.92330575974016;
   fWeightMatrix1to2[9][7] = -1.82630452557076;
   fWeightMatrix1to2[10][7] = 0.531067114046344;
   fWeightMatrix1to2[11][7] = -1.93216766366047;
   fWeightMatrix1to2[12][7] = -1.47630985751759;
   fWeightMatrix1to2[0][8] = -1.82216158095115;
   fWeightMatrix1to2[1][8] = -0.663522700407601;
   fWeightMatrix1to2[2][8] = 1.97971564671148;
   fWeightMatrix1to2[3][8] = -0.63050048158064;
   fWeightMatrix1to2[4][8] = 0.454350099820602;
   fWeightMatrix1to2[5][8] = -0.82587909176366;
   fWeightMatrix1to2[6][8] = -1.23399804569968;
   fWeightMatrix1to2[7][8] = -1.33102079687834;
   fWeightMatrix1to2[8][8] = -1.01779578096091;
   fWeightMatrix1to2[9][8] = -1.28610980424442;
   fWeightMatrix1to2[10][8] = 0.912063282869672;
   fWeightMatrix1to2[11][8] = -1.3783869333246;
   fWeightMatrix1to2[12][8] = -0.821196002213208;
   fWeightMatrix1to2[0][9] = 1.95958668775792;
   fWeightMatrix1to2[1][9] = 0.227848758977691;
   fWeightMatrix1to2[2][9] = -0.576128366039466;
   fWeightMatrix1to2[3][9] = 1.75359402746738;
   fWeightMatrix1to2[4][9] = -1.9375667568051;
   fWeightMatrix1to2[5][9] = 1.25967243002319;
   fWeightMatrix1to2[6][9] = 1.08944974537522;
   fWeightMatrix1to2[7][9] = -1.25324991842275;
   fWeightMatrix1to2[8][9] = -0.812539931728971;
   fWeightMatrix1to2[9][9] = -1.92203433304641;
   fWeightMatrix1to2[10][9] = -1.21849079327641;
   fWeightMatrix1to2[11][9] = 0.487427669320508;
   fWeightMatrix1to2[12][9] = 1.67210219483138;
   fWeightMatrix1to2[0][10] = 1.21661090317507;
   fWeightMatrix1to2[1][10] = 1.60643508868695;
   fWeightMatrix1to2[2][10] = -1.21757116992373;
   fWeightMatrix1to2[3][10] = 1.00630622276712;
   fWeightMatrix1to2[4][10] = -1.78049938773909;
   fWeightMatrix1to2[5][10] = 0.661348256843245;
   fWeightMatrix1to2[6][10] = -1.90207010465192;
   fWeightMatrix1to2[7][10] = -1.38690417763401;
   fWeightMatrix1to2[8][10] = -0.0767558363230863;
   fWeightMatrix1to2[9][10] = 0.680367602598989;
   fWeightMatrix1to2[10][10] = 0.451161495376718;
   fWeightMatrix1to2[11][10] = 1.01290170708992;
   fWeightMatrix1to2[12][10] = 0.642020784447491;
   fWeightMatrix1to2[0][11] = -0.233632617364457;
   fWeightMatrix1to2[1][11] = -0.624661581755402;
   fWeightMatrix1to2[2][11] = 0.340560181441937;
   fWeightMatrix1to2[3][11] = 1.85194154457162;
   fWeightMatrix1to2[4][11] = -1.30577166873586;
   fWeightMatrix1to2[5][11] = 0.406269592781289;
   fWeightMatrix1to2[6][11] = -1.44533049710222;
   fWeightMatrix1to2[7][11] = -0.0552670940254809;
   fWeightMatrix1to2[8][11] = -0.0204173788556473;
   fWeightMatrix1to2[9][11] = -1.23226124233816;
   fWeightMatrix1to2[10][11] = -1.01862747728713;
   fWeightMatrix1to2[11][11] = 1.03292248956888;
   fWeightMatrix1to2[12][11] = 1.63088170031753;
   fWeightMatrix1to2[0][12] = 0.847346491279301;
   fWeightMatrix1to2[1][12] = -0.395385346623576;
   fWeightMatrix1to2[2][12] = -1.06849451555375;
   fWeightMatrix1to2[3][12] = -1.49874726253069;
   fWeightMatrix1to2[4][12] = -1.80257038287317;
   fWeightMatrix1to2[5][12] = 1.19894715352011;
   fWeightMatrix1to2[6][12] = -0.523700254830092;
   fWeightMatrix1to2[7][12] = -1.01811150781185;
   fWeightMatrix1to2[8][12] = 0.636286795103597;
   fWeightMatrix1to2[9][12] = -2.91304848614807;
   fWeightMatrix1to2[10][12] = -1.03601636165752;
   fWeightMatrix1to2[11][12] = -1.64004910298392;
   fWeightMatrix1to2[12][12] = 0.774994256816224;
   fWeightMatrix1to2[0][13] = -1.23729227726662;
   fWeightMatrix1to2[1][13] = -1.87731124565408;
   fWeightMatrix1to2[2][13] = -0.725578028918364;
   fWeightMatrix1to2[3][13] = -0.890607859448464;
   fWeightMatrix1to2[4][13] = -1.76702877187762;
   fWeightMatrix1to2[5][13] = 1.15886561305509;
   fWeightMatrix1to2[6][13] = -1.27669234198836;
   fWeightMatrix1to2[7][13] = -1.66186503917224;
   fWeightMatrix1to2[8][13] = 1.77507779402896;
   fWeightMatrix1to2[9][13] = 1.1150057678634;
   fWeightMatrix1to2[10][13] = 0.24668385527094;
   fWeightMatrix1to2[11][13] = 0.11783501955013;
   fWeightMatrix1to2[12][13] = 0.985084999694882;
   fWeightMatrix1to2[0][14] = 1.59499789796994;
   fWeightMatrix1to2[1][14] = 0.617887652406135;
   fWeightMatrix1to2[2][14] = -0.787387312973081;
   fWeightMatrix1to2[3][14] = -0.726643629907314;
   fWeightMatrix1to2[4][14] = -1.59639620842051;
   fWeightMatrix1to2[5][14] = 0.967854467184075;
   fWeightMatrix1to2[6][14] = 0.757639957099778;
   fWeightMatrix1to2[7][14] = 0.553911506147906;
   fWeightMatrix1to2[8][14] = 1.0474009554837;
   fWeightMatrix1to2[9][14] = 0.3299987020826;
   fWeightMatrix1to2[10][14] = 1.74691524650042;
   fWeightMatrix1to2[11][14] = -1.37616815009514;
   fWeightMatrix1to2[12][14] = 2.05479080447621;
   // weight matrix from layer 2 to 3
   fWeightMatrix2to3[0][0] = 0.0374714904131058;
   fWeightMatrix2to3[0][1] = -1.95782315194791;
   fWeightMatrix2to3[0][2] = -0.0381625923727954;
   fWeightMatrix2to3[0][3] = -0.0277848331742573;
   fWeightMatrix2to3[0][4] = 0.0222074129248547;
   fWeightMatrix2to3[0][5] = -0.00220069159011195;
   fWeightMatrix2to3[0][6] = -0.00149853350001564;
   fWeightMatrix2to3[0][7] = -0.00775119697423857;
   fWeightMatrix2to3[0][8] = -0.0113358310558873;
   fWeightMatrix2to3[0][9] = 1.04211363337544;
   fWeightMatrix2to3[0][10] = 1.36591737197365;
   fWeightMatrix2to3[0][11] = 0.0469310928291816;
   fWeightMatrix2to3[0][12] = -1.00758146057256;
   fWeightMatrix2to3[0][13] = 1.60828051926844;
}

inline double ReadMLP1_25_B_2x2::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   if (inputValues.size() != (unsigned int)fLayerSize[0]-1) {
      std::cout << "Input vector needs to be of size " << fLayerSize[0]-1 << std::endl;
      return 0;
   }

   for (int l=0; l<fLayers; l++)
      for (int i=0; i<fLayerSize[l]; i++) fWeights[l][i]=0;

   for (int l=0; l<fLayers-1; l++)
      fWeights[l][fLayerSize[l]-1]=1;

   for (int i=0; i<fLayerSize[0]-1; i++)
      fWeights[0][i]=inputValues[i];

   // layer 0 to 1
   for (int o=0; o<fLayerSize[1]-1; o++) {
      for (int i=0; i<fLayerSize[0]; i++) {
         double inputVal = fWeightMatrix0to1[o][i] * fWeights[0][i];
         fWeights[1][o] += inputVal;
      }
      fWeights[1][o] = ActivationFnc(fWeights[1][o]);
   }
   // layer 1 to 2
   for (int o=0; o<fLayerSize[2]-1; o++) {
      for (int i=0; i<fLayerSize[1]; i++) {
         double inputVal = fWeightMatrix1to2[o][i] * fWeights[1][i];
         fWeights[2][o] += inputVal;
      }
      fWeights[2][o] = ActivationFnc(fWeights[2][o]);
   }
   // layer 2 to 3
   for (int o=0; o<fLayerSize[3]; o++) {
      for (int i=0; i<fLayerSize[2]; i++) {
         double inputVal = fWeightMatrix2to3[o][i] * fWeights[2][i];
         fWeights[3][o] += inputVal;
      }
   }

   return fWeights[3][0];
}

double ReadMLP1_25_B_2x2::ActivationFnc(double x) const
{
   // hyperbolic tan
   return tanh(x);
}
 
   
// Clean up
inline void ReadMLP1_25_B_2x2::Clear() 
{
   // nothing to clear
}
inline double ReadMLP1_25_B_2x2::GetMvaValue( const std::vector<double>& inputValues ) const
{
   // classifier response value
   double retval = 0;

   // classifier response, sanity check first
   if (!fStatusIsClean) {
      std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
      retval = 0;
   }
   else {
      if (IsNormalised()) {
         // normalise variables
         std::vector<double> iV;
         int ivar = 0;
         for (std::vector<double>::const_iterator varIt = inputValues.begin();
              varIt != inputValues.end(); varIt++, ivar++) {
            iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
         }
         retval = GetMvaValue__( iV );
      }
      else {
         retval = GetMvaValue__( inputValues );
      }
   }

   return retval;
}

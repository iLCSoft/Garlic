// Class: ReadMLP1_25_EC
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : MLP::MLP
TMVA Release   : 3.9.6         [198918]
ROOT Release   : 5.16/00       [331776]
Creator        : reinhard
Date           : Fri Aug  7 10:00:58 2009
Host           : Linux polui02.in2p3.fr 2.6.9-67.0.4.ELsmp #1 SMP Thu Jan 31 16:30:09 CST 2008 i686 i686 i386 GNU/Linux
Dir            : /grid_mnt/data2__polgrid/llr/ilc/reinhard/ILCSoft/TMVA/macros
Training events: 4375


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
Normalise: "True" [Normalise input variables]
V: "False" [Verbose mode]
H: "True" [Print classifier-specific help message]
NCycles: "500" [Number of training cycles]
HiddenLayers: "N+1,N" [Specification of hidden layer architecture (N stands for number of variables; any integers may also be used)]
NeuronType: "tanh" [Neuron activation function type]
TestRate: "5" [Test for overtraining performed at each #th epochs]
# Default:
D: "False" [Use-decorrelated-variables flag (depreciated)]
VarTransform: "None" [Variable transformation method]
VarTransformType: "Signal" [Use signal or background events to derive for variable transformation (the transformation is applied on both types of, course)]
NbinsMVAPdf: "60" [Number of bins used for the PDFs of classifier outputs]
NsmoothMVAPdf: "2" [Number of smoothing iterations for classifier PDFs]
VerboseLevel: "Default" [Verbosity level]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
TxtWeightFilesOnly: "True" [If True: write all training results (weights) as text files (False: some are written in ROOT format)]
NeuronInputType: "sum" [Neuron input function type]
TrainingMethod: "BP" [Train with Back-Propagation (BP - default) or Genetic Algorithm (GA - slower and worse)]
LearningRate: "0.02" [ANN learning rate parameter]
DecayRate: "0.01" [Decay rate for learning parameter]
BPMode: "sequential" [Back-propagation learning mode: sequential or batch]
BatchSize: "-1" [Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 13
ClusterParameters.start       ClusterParameters.start           'F'    [0,9.89999771118]
ClusterParameters.end         ClusterParameters.end             'F'    [2.92393922806,38.9429664612]
ClusterParameters.depth       ClusterParameters.depth           'F'    [0,24.6780548096]
ClusterParameters.E1C/ClusterParameters.Etot_g   ClusterParameters.E1C_D_ClusterParameters.Etot_g     'F'    [0,0.972354531288]
ClusterParameters.E4C/ClusterParameters.Etot_g   ClusterParameters.E4C_D_ClusterParameters.Etot_g     'F'    [0.00631833588704,1]
ClusterParameters.E9C/ClusterParameters.Etot_g   ClusterParameters.E9C_D_ClusterParameters.Etot_g     'F'    [0.17862983048,1]
ClusterParameters.dirErr      ClusterParameters.dirErr          'F'    [0.00697532435879,0.999999701977]
ClusterParameters.seedDirErr  ClusterParameters.seedDirErr      'F'    [0,0.999998509884]
ClusterParameters.Width       ClusterParameters.Width           'F'    [0.538923442364,20.4335174561]
ClusterParameters.Eccentricity ClusterParameters.Eccentricity     'F'    [0.0458266586065,0.85490912199]
ClusterParameters.nHits       ClusterParameters.nHits           'F'    [5,108]
ClusterParameters.Volume      ClusterParameters.Volume          'F'    [22.505361557,720532.5625]
ClusterParameters.depth-ClusterParameters.start   ClusterParameters.depth_M_ClusterParameters.start     'F'    [-1.98724400997,24.6780548096]


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;
};

#endif

class ReadMLP1_25_EC : public IClassifierReader {

 public:

   // constructor
   ReadMLP1_25_EC( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadMLP1_25_EC" ),
        fStatusIsClean( true ),
        fNvars( 13 ),
        fIsNormalised( true )
   {      
      // the training input variables
      const char* inputVars[] = { "ClusterParameters.start", "ClusterParameters.end", "ClusterParameters.depth", "ClusterParameters.E1C/ClusterParameters.Etot_g", "ClusterParameters.E4C/ClusterParameters.Etot_g", "ClusterParameters.E9C/ClusterParameters.Etot_g", "ClusterParameters.dirErr", "ClusterParameters.seedDirErr", "ClusterParameters.Width", "ClusterParameters.Eccentricity", "ClusterParameters.nHits", "ClusterParameters.Volume", "ClusterParameters.depth-ClusterParameters.start" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 9.89999771118164;
      fVmin[1] = 2.92393922805786;
      fVmax[1] = 38.9429664611816;
      fVmin[2] = 0;
      fVmax[2] = 24.6780548095703;
      fVmin[3] = 0;
      fVmax[3] = 0.972354531288147;
      fVmin[4] = 0.00631833588704467;
      fVmax[4] = 1;
      fVmin[5] = 0.178629830479622;
      fVmax[5] = 1;
      fVmin[6] = 0.00697532435879111;
      fVmax[6] = 0.999999701976776;
      fVmin[7] = 0;
      fVmax[7] = 0.999998509883881;
      fVmin[8] = 0.538923442363739;
      fVmax[8] = 20.4335174560547;
      fVmin[9] = 0.0458266586065292;
      fVmax[9] = 0.854909121990204;
      fVmin[10] = 5;
      fVmax[10] = 108;
      fVmin[11] = 22.5053615570068;
      fVmax[11] = 720532.5625;
      fVmin[12] = -1.98724400997162;
      fVmax[12] = 24.6780548095703;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';
      fType[10] = 'F';
      fType[11] = 'F';
      fType[12] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadMLP1_25_EC() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;
   bool fStatusIsClean;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[13];
   double fVmax[13];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[13];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)

   double ActivationFnc(double x) const;

   int fLayers;
   int fLayerSize[4];
   double fWeightMatrix0to1[15][14];   // weight matrix from layer 0 to 1
   double fWeightMatrix1to2[14][15];   // weight matrix from layer 1 to 2
   double fWeightMatrix2to3[1][14];   // weight matrix from layer 2 to 3

   double * fWeights[4];
};

inline void ReadMLP1_25_EC::Initialize()
{
   // build network structure
   fLayers = 4;
   fLayerSize[0] = 14; fWeights[0] = new double[14]; 
   fLayerSize[1] = 15; fWeights[1] = new double[15]; 
   fLayerSize[2] = 14; fWeights[2] = new double[14]; 
   fLayerSize[3] = 1; fWeights[3] = new double[1]; 
   // weight matrix from layer 0 to 1
   fWeightMatrix0to1[0][0] = 0.0146178903408263;
   fWeightMatrix0to1[1][0] = 1.84705997397983;
   fWeightMatrix0to1[2][0] = 1.39690068520639;
   fWeightMatrix0to1[3][0] = 1.52660571495071;
   fWeightMatrix0to1[4][0] = -1.15902429440456;
   fWeightMatrix0to1[5][0] = -1.60451063598613;
   fWeightMatrix0to1[6][0] = -0.665385475230654;
   fWeightMatrix0to1[7][0] = 1.74312368123407;
   fWeightMatrix0to1[8][0] = -1.89209430449131;
   fWeightMatrix0to1[9][0] = -0.907729779146331;
   fWeightMatrix0to1[10][0] = -1.51558773597931;
   fWeightMatrix0to1[11][0] = -0.515810741121777;
   fWeightMatrix0to1[12][0] = -1.01339173883262;
   fWeightMatrix0to1[13][0] = -0.245743185964958;
   fWeightMatrix0to1[0][1] = -0.521594595448709;
   fWeightMatrix0to1[1][1] = 0.718711724916537;
   fWeightMatrix0to1[2][1] = -0.472558326104253;
   fWeightMatrix0to1[3][1] = 1.7595863023678;
   fWeightMatrix0to1[4][1] = 0.729227505597577;
   fWeightMatrix0to1[5][1] = 1.02796464783031;
   fWeightMatrix0to1[6][1] = -0.253468598311969;
   fWeightMatrix0to1[7][1] = -0.621753136534584;
   fWeightMatrix0to1[8][1] = 2.64452376691892;
   fWeightMatrix0to1[9][1] = 1.08937228666755;
   fWeightMatrix0to1[10][1] = -1.17055143128146;
   fWeightMatrix0to1[11][1] = -0.485231045431994;
   fWeightMatrix0to1[12][1] = 2.66598713995615;
   fWeightMatrix0to1[13][1] = -1.10867124347901;
   fWeightMatrix0to1[0][2] = -1.64578552499782;
   fWeightMatrix0to1[1][2] = 0.157410004566525;
   fWeightMatrix0to1[2][2] = 0.316086883872389;
   fWeightMatrix0to1[3][2] = 1.5351186010769;
   fWeightMatrix0to1[4][2] = -0.308843971874916;
   fWeightMatrix0to1[5][2] = -0.280773155773874;
   fWeightMatrix0to1[6][2] = 0.32947163108969;
   fWeightMatrix0to1[7][2] = -0.155113806944726;
   fWeightMatrix0to1[8][2] = -1.15911456112594;
   fWeightMatrix0to1[9][2] = 1.73075636042864;
   fWeightMatrix0to1[10][2] = -1.10175799393222;
   fWeightMatrix0to1[11][2] = 0.978706932385172;
   fWeightMatrix0to1[12][2] = 2.09653704363173;
   fWeightMatrix0to1[13][2] = 0.88987031939483;
   fWeightMatrix0to1[0][3] = 2.45426581411113;
   fWeightMatrix0to1[1][3] = 1.46364348983485;
   fWeightMatrix0to1[2][3] = 0.149165288611082;
   fWeightMatrix0to1[3][3] = -1.15361563003138;
   fWeightMatrix0to1[4][3] = 1.60953903934738;
   fWeightMatrix0to1[5][3] = 0.292873637974827;
   fWeightMatrix0to1[6][3] = 1.64678564004404;
   fWeightMatrix0to1[7][3] = 2.299974645037;
   fWeightMatrix0to1[8][3] = 2.02630015872386;
   fWeightMatrix0to1[9][3] = 0.156300685654208;
   fWeightMatrix0to1[10][3] = -1.75338748336669;
   fWeightMatrix0to1[11][3] = 0.989393894805288;
   fWeightMatrix0to1[12][3] = -2.12076907538497;
   fWeightMatrix0to1[13][3] = -1.03620176691785;
   fWeightMatrix0to1[0][4] = -0.872091515152782;
   fWeightMatrix0to1[1][4] = -1.556130362596;
   fWeightMatrix0to1[2][4] = 2.05315861058281;
   fWeightMatrix0to1[3][4] = 0.586848087267679;
   fWeightMatrix0to1[4][4] = -0.981281718894358;
   fWeightMatrix0to1[5][4] = 0.162905940709884;
   fWeightMatrix0to1[6][4] = -0.200099738344778;
   fWeightMatrix0to1[7][4] = 0.516270606270441;
   fWeightMatrix0to1[8][4] = 3.30786063642169;
   fWeightMatrix0to1[9][4] = -0.394280187430398;
   fWeightMatrix0to1[10][4] = 0.000900906953216564;
   fWeightMatrix0to1[11][4] = -1.12250414601397;
   fWeightMatrix0to1[12][4] = 0.329995086668332;
   fWeightMatrix0to1[13][4] = -1.04955167025712;
   fWeightMatrix0to1[0][5] = -1.05500918595221;
   fWeightMatrix0to1[1][5] = -1.29778496943341;
   fWeightMatrix0to1[2][5] = 0.711681716335447;
   fWeightMatrix0to1[3][5] = 0.778005745726989;
   fWeightMatrix0to1[4][5] = 0.416428935238315;
   fWeightMatrix0to1[5][5] = -0.35260470325544;
   fWeightMatrix0to1[6][5] = -1.85546295177359;
   fWeightMatrix0to1[7][5] = -2.40501970584124;
   fWeightMatrix0to1[8][5] = 0.227244586872289;
   fWeightMatrix0to1[9][5] = -0.670287933671059;
   fWeightMatrix0to1[10][5] = 1.948820239492;
   fWeightMatrix0to1[11][5] = 0.939674790030861;
   fWeightMatrix0to1[12][5] = 0.129787294600739;
   fWeightMatrix0to1[13][5] = -0.776225685280167;
   fWeightMatrix0to1[0][6] = -0.254259972633421;
   fWeightMatrix0to1[1][6] = -0.402593526932142;
   fWeightMatrix0to1[2][6] = 1.81124960067107;
   fWeightMatrix0to1[3][6] = -1.513327797348;
   fWeightMatrix0to1[4][6] = -1.65690169698651;
   fWeightMatrix0to1[5][6] = -1.69004483574294;
   fWeightMatrix0to1[6][6] = -0.275355530736992;
   fWeightMatrix0to1[7][6] = -0.740964113683389;
   fWeightMatrix0to1[8][6] = 3.70814764730848;
   fWeightMatrix0to1[9][6] = -2.0219617682811;
   fWeightMatrix0to1[10][6] = -0.504890736803345;
   fWeightMatrix0to1[11][6] = 1.52934490467383;
   fWeightMatrix0to1[12][6] = -1.15350476952591;
   fWeightMatrix0to1[13][6] = -1.36126652903375;
   fWeightMatrix0to1[0][7] = -1.02884917712658;
   fWeightMatrix0to1[1][7] = 0.256570542970979;
   fWeightMatrix0to1[2][7] = -1.57853577804385;
   fWeightMatrix0to1[3][7] = -1.31273509210975;
   fWeightMatrix0to1[4][7] = 0.110840974704084;
   fWeightMatrix0to1[5][7] = 2.3640103698074;
   fWeightMatrix0to1[6][7] = -1.10032921752148;
   fWeightMatrix0to1[7][7] = 1.24032740390067;
   fWeightMatrix0to1[8][7] = 0.0159084449572222;
   fWeightMatrix0to1[9][7] = -0.535058324634156;
   fWeightMatrix0to1[10][7] = 0.0329796754811006;
   fWeightMatrix0to1[11][7] = 0.336808306370747;
   fWeightMatrix0to1[12][7] = -1.07999959129272;
   fWeightMatrix0to1[13][7] = 0.336275066237428;
   fWeightMatrix0to1[0][8] = 0.144508745212525;
   fWeightMatrix0to1[1][8] = 0.366066104822414;
   fWeightMatrix0to1[2][8] = -1.7106852676628;
   fWeightMatrix0to1[3][8] = 1.92966341555662;
   fWeightMatrix0to1[4][8] = 0.601074331841058;
   fWeightMatrix0to1[5][8] = -0.889087961570485;
   fWeightMatrix0to1[6][8] = 0.706114916294556;
   fWeightMatrix0to1[7][8] = -1.04837051731928;
   fWeightMatrix0to1[8][8] = -0.445099637157081;
   fWeightMatrix0to1[9][8] = 0.0558119496482876;
   fWeightMatrix0to1[10][8] = -0.353524458779246;
   fWeightMatrix0to1[11][8] = 1.57048331552421;
   fWeightMatrix0to1[12][8] = 1.6820981184316;
   fWeightMatrix0to1[13][8] = -0.0104977236663076;
   fWeightMatrix0to1[0][9] = -0.590821512211657;
   fWeightMatrix0to1[1][9] = 0.12216966378934;
   fWeightMatrix0to1[2][9] = -1.47816576785154;
   fWeightMatrix0to1[3][9] = 1.1198768943278;
   fWeightMatrix0to1[4][9] = -0.173252794197309;
   fWeightMatrix0to1[5][9] = -1.10305256702725;
   fWeightMatrix0to1[6][9] = 0.559290477002585;
   fWeightMatrix0to1[7][9] = -1.23205140521281;
   fWeightMatrix0to1[8][9] = 0.855593909848534;
   fWeightMatrix0to1[9][9] = -0.049070539964665;
   fWeightMatrix0to1[10][9] = 1.77419963155962;
   fWeightMatrix0to1[11][9] = -1.78737430265354;
   fWeightMatrix0to1[12][9] = 0.0687212019111156;
   fWeightMatrix0to1[13][9] = 1.56891301310003;
   fWeightMatrix0to1[0][10] = 1.03596312516023;
   fWeightMatrix0to1[1][10] = 0.225394631238592;
   fWeightMatrix0to1[2][10] = -1.74836923460675;
   fWeightMatrix0to1[3][10] = 0.0427737726238573;
   fWeightMatrix0to1[4][10] = -3.04921707378258;
   fWeightMatrix0to1[5][10] = 1.39911158232544;
   fWeightMatrix0to1[6][10] = 1.12703440364828;
   fWeightMatrix0to1[7][10] = -0.311463173946406;
   fWeightMatrix0to1[8][10] = 2.41099340095567;
   fWeightMatrix0to1[9][10] = -4.82557405160176;
   fWeightMatrix0to1[10][10] = -1.53211159742455;
   fWeightMatrix0to1[11][10] = 0.286705575244885;
   fWeightMatrix0to1[12][10] = 1.67403699378851;
   fWeightMatrix0to1[13][10] = -0.664443167094717;
   fWeightMatrix0to1[0][11] = -1.10931841440355;
   fWeightMatrix0to1[1][11] = 0.509829851972565;
   fWeightMatrix0to1[2][11] = 0.731281227734413;
   fWeightMatrix0to1[3][11] = 1.12161467482764;
   fWeightMatrix0to1[4][11] = 0.702416713465061;
   fWeightMatrix0to1[5][11] = -1.70669062250923;
   fWeightMatrix0to1[6][11] = 1.65671284791114;
   fWeightMatrix0to1[7][11] = 0.962722971372997;
   fWeightMatrix0to1[8][11] = 0.648979022874443;
   fWeightMatrix0to1[9][11] = 0.704905708418655;
   fWeightMatrix0to1[10][11] = 0.717287959939891;
   fWeightMatrix0to1[11][11] = -0.962969384911191;
   fWeightMatrix0to1[12][11] = -0.459538097617069;
   fWeightMatrix0to1[13][11] = 0.849152817384052;
   fWeightMatrix0to1[0][12] = -1.007168590513;
   fWeightMatrix0to1[1][12] = -0.426026521017139;
   fWeightMatrix0to1[2][12] = 0.890290210447436;
   fWeightMatrix0to1[3][12] = 1.16090848975579;
   fWeightMatrix0to1[4][12] = -0.473788962668052;
   fWeightMatrix0to1[5][12] = 1.41280798850716;
   fWeightMatrix0to1[6][12] = 1.94235161955949;
   fWeightMatrix0to1[7][12] = -1.52253319437188;
   fWeightMatrix0to1[8][12] = 1.07856763511419;
   fWeightMatrix0to1[9][12] = -0.226747347715131;
   fWeightMatrix0to1[10][12] = 0.434093822012528;
   fWeightMatrix0to1[11][12] = -1.9039191429507;
   fWeightMatrix0to1[12][12] = -0.910421044568314;
   fWeightMatrix0to1[13][12] = 1.02701227862011;
   fWeightMatrix0to1[0][13] = 2.4202276824662;
   fWeightMatrix0to1[1][13] = -2.00309048581648;
   fWeightMatrix0to1[2][13] = 0.349969860488035;
   fWeightMatrix0to1[3][13] = -1.20518505970735;
   fWeightMatrix0to1[4][13] = -0.0423133243191889;
   fWeightMatrix0to1[5][13] = 1.95126405664806;
   fWeightMatrix0to1[6][13] = -0.508489531477052;
   fWeightMatrix0to1[7][13] = -1.2351480390814;
   fWeightMatrix0to1[8][13] = -1.01280181292714;
   fWeightMatrix0to1[9][13] = 1.52492441006385;
   fWeightMatrix0to1[10][13] = 1.97719992703108;
   fWeightMatrix0to1[11][13] = 1.46450450421376;
   fWeightMatrix0to1[12][13] = 0.654235741734409;
   fWeightMatrix0to1[13][13] = -0.559941667611054;
   // weight matrix from layer 1 to 2
   fWeightMatrix1to2[0][0] = -1.11903101800432;
   fWeightMatrix1to2[1][0] = 1.03187039062108;
   fWeightMatrix1to2[2][0] = 0.354996174842918;
   fWeightMatrix1to2[3][0] = -1.09738159195558;
   fWeightMatrix1to2[4][0] = -1.28444874886094;
   fWeightMatrix1to2[5][0] = 0.261698583966995;
   fWeightMatrix1to2[6][0] = -0.0599491645933609;
   fWeightMatrix1to2[7][0] = -2.10684771760749;
   fWeightMatrix1to2[8][0] = 1.3285984250682;
   fWeightMatrix1to2[9][0] = 0.635763930227065;
   fWeightMatrix1to2[10][0] = -0.248289576022556;
   fWeightMatrix1to2[11][0] = -0.118915972352035;
   fWeightMatrix1to2[12][0] = 1.57844105038682;
   fWeightMatrix1to2[0][1] = 0.599933441083235;
   fWeightMatrix1to2[1][1] = 0.224955142775941;
   fWeightMatrix1to2[2][1] = 0.0941009790897765;
   fWeightMatrix1to2[3][1] = -1.93648790053273;
   fWeightMatrix1to2[4][1] = -0.875471566646097;
   fWeightMatrix1to2[5][1] = 1.39513849841927;
   fWeightMatrix1to2[6][1] = 1.67726770906501;
   fWeightMatrix1to2[7][1] = 0.92686340553817;
   fWeightMatrix1to2[8][1] = 0.153529847087437;
   fWeightMatrix1to2[9][1] = 1.53793588563692;
   fWeightMatrix1to2[10][1] = -1.95407415355997;
   fWeightMatrix1to2[11][1] = -1.3073961322854;
   fWeightMatrix1to2[12][1] = -0.164928367874303;
   fWeightMatrix1to2[0][2] = -1.8669187168894;
   fWeightMatrix1to2[1][2] = 1.08319218388516;
   fWeightMatrix1to2[2][2] = 1.5066900778942;
   fWeightMatrix1to2[3][2] = -1.31692426916384;
   fWeightMatrix1to2[4][2] = -0.56754798900206;
   fWeightMatrix1to2[5][2] = 0.218257417631333;
   fWeightMatrix1to2[6][2] = -1.49027015845059;
   fWeightMatrix1to2[7][2] = -1.17032874786326;
   fWeightMatrix1to2[8][2] = 1.09743921116813;
   fWeightMatrix1to2[9][2] = 0.252137023667114;
   fWeightMatrix1to2[10][2] = 0.779484003736478;
   fWeightMatrix1to2[11][2] = -1.16890170878171;
   fWeightMatrix1to2[12][2] = 1.78112514590762;
   fWeightMatrix1to2[0][3] = -2.16925718993902;
   fWeightMatrix1to2[1][3] = 0.573461718730645;
   fWeightMatrix1to2[2][3] = 0.297787595396771;
   fWeightMatrix1to2[3][3] = -1.71370370395128;
   fWeightMatrix1to2[4][3] = -1.25436202132589;
   fWeightMatrix1to2[5][3] = -2.23439946057309;
   fWeightMatrix1to2[6][3] = 0.0265909846420458;
   fWeightMatrix1to2[7][3] = -1.63104775281341;
   fWeightMatrix1to2[8][3] = -1.62301082957311;
   fWeightMatrix1to2[9][3] = -1.79333503217932;
   fWeightMatrix1to2[10][3] = -0.0778756855921634;
   fWeightMatrix1to2[11][3] = -1.0124997823014;
   fWeightMatrix1to2[12][3] = -1.64741749126839;
   fWeightMatrix1to2[0][4] = 1.45719440527962;
   fWeightMatrix1to2[1][4] = -1.05039109411768;
   fWeightMatrix1to2[2][4] = 0.264640271649764;
   fWeightMatrix1to2[3][4] = -0.946894415749107;
   fWeightMatrix1to2[4][4] = -0.419733202885206;
   fWeightMatrix1to2[5][4] = 1.53184612323105;
   fWeightMatrix1to2[6][4] = 1.24540392500146;
   fWeightMatrix1to2[7][4] = -0.712821099378627;
   fWeightMatrix1to2[8][4] = -1.5199013016889;
   fWeightMatrix1to2[9][4] = -1.39121711404503;
   fWeightMatrix1to2[10][4] = -1.05081834683263;
   fWeightMatrix1to2[11][4] = -1.63249247704022;
   fWeightMatrix1to2[12][4] = 0.289362614079715;
   fWeightMatrix1to2[0][5] = 1.10579036360998;
   fWeightMatrix1to2[1][5] = 1.80065202445282;
   fWeightMatrix1to2[2][5] = -0.475736334519223;
   fWeightMatrix1to2[3][5] = 0.301562413909295;
   fWeightMatrix1to2[4][5] = -0.257787731305217;
   fWeightMatrix1to2[5][5] = -1.5589318093795;
   fWeightMatrix1to2[6][5] = 0.912980121203114;
   fWeightMatrix1to2[7][5] = 0.978920823251251;
   fWeightMatrix1to2[8][5] = -0.798001286344332;
   fWeightMatrix1to2[9][5] = -0.874672781067384;
   fWeightMatrix1to2[10][5] = 0.77626868015037;
   fWeightMatrix1to2[11][5] = 1.22809377512085;
   fWeightMatrix1to2[12][5] = 0.488713933885347;
   fWeightMatrix1to2[0][6] = -0.888138449426775;
   fWeightMatrix1to2[1][6] = -0.560027558288887;
   fWeightMatrix1to2[2][6] = 1.67833392219346;
   fWeightMatrix1to2[3][6] = 0.976737150253984;
   fWeightMatrix1to2[4][6] = 1.04606684362371;
   fWeightMatrix1to2[5][6] = -0.599231242626954;
   fWeightMatrix1to2[6][6] = 0.591791325092358;
   fWeightMatrix1to2[7][6] = -0.102938027052768;
   fWeightMatrix1to2[8][6] = -1.5060108064945;
   fWeightMatrix1to2[9][6] = -1.01942066524021;
   fWeightMatrix1to2[10][6] = -2.01313344426666;
   fWeightMatrix1to2[11][6] = -1.38367818937167;
   fWeightMatrix1to2[12][6] = -1.56953819043674;
   fWeightMatrix1to2[0][7] = 1.40924999453909;
   fWeightMatrix1to2[1][7] = -1.70637955490101;
   fWeightMatrix1to2[2][7] = 1.99102711979533;
   fWeightMatrix1to2[3][7] = -1.45790328314839;
   fWeightMatrix1to2[4][7] = 0.924840088783911;
   fWeightMatrix1to2[5][7] = -1.39168897706519;
   fWeightMatrix1to2[6][7] = 0.797177990488742;
   fWeightMatrix1to2[7][7] = 0.943519306723547;
   fWeightMatrix1to2[8][7] = -1.90393645673721;
   fWeightMatrix1to2[9][7] = -0.19361798628445;
   fWeightMatrix1to2[10][7] = 0.300607567385536;
   fWeightMatrix1to2[11][7] = -1.9512658209673;
   fWeightMatrix1to2[12][7] = -1.32512502601402;
   fWeightMatrix1to2[0][8] = -3.27786053887845;
   fWeightMatrix1to2[1][8] = -0.720871350303797;
   fWeightMatrix1to2[2][8] = 1.62461475200438;
   fWeightMatrix1to2[3][8] = -0.693769970506218;
   fWeightMatrix1to2[4][8] = 1.58453555251062;
   fWeightMatrix1to2[5][8] = -1.00953104790441;
   fWeightMatrix1to2[6][8] = -0.7682545965768;
   fWeightMatrix1to2[7][8] = -1.62540157567424;
   fWeightMatrix1to2[8][8] = -0.946647065052605;
   fWeightMatrix1to2[9][8] = -1.38484897875641;
   fWeightMatrix1to2[10][8] = 0.659046689060986;
   fWeightMatrix1to2[11][8] = -1.35456178011705;
   fWeightMatrix1to2[12][8] = -1.17773544312955;
   fWeightMatrix1to2[0][9] = 2.27335572133993;
   fWeightMatrix1to2[1][9] = 0.314469896362061;
   fWeightMatrix1to2[2][9] = -0.705177579599322;
   fWeightMatrix1to2[3][9] = 1.99409346060611;
   fWeightMatrix1to2[4][9] = -2.87162273399935;
   fWeightMatrix1to2[5][9] = 1.35619518201411;
   fWeightMatrix1to2[6][9] = 0.971924261833978;
   fWeightMatrix1to2[7][9] = -0.897967892110121;
   fWeightMatrix1to2[8][9] = -0.882402471417222;
   fWeightMatrix1to2[9][9] = -0.180289319476379;
   fWeightMatrix1to2[10][9] = -1.16965096347269;
   fWeightMatrix1to2[11][9] = 0.48122327622307;
   fWeightMatrix1to2[12][9] = 1.87788540368219;
   fWeightMatrix1to2[0][10] = 1.75303495026901;
   fWeightMatrix1to2[1][10] = 1.74298804320075;
   fWeightMatrix1to2[2][10] = -1.55527243163014;
   fWeightMatrix1to2[3][10] = 1.10136094396418;
   fWeightMatrix1to2[4][10] = -2.01408575180653;
   fWeightMatrix1to2[5][10] = 0.912796541236599;
   fWeightMatrix1to2[6][10] = -2.06037590236306;
   fWeightMatrix1to2[7][10] = -1.98648111533391;
   fWeightMatrix1to2[8][10] = 0.00791008160304616;
   fWeightMatrix1to2[9][10] = 1.67117156729694;
   fWeightMatrix1to2[10][10] = 0.716962177746195;
   fWeightMatrix1to2[11][10] = 1.04735054901268;
   fWeightMatrix1to2[12][10] = 0.324703848628958;
   fWeightMatrix1to2[0][11] = 0.260546531410768;
   fWeightMatrix1to2[1][11] = -0.476088554394502;
   fWeightMatrix1to2[2][11] = -0.0969750953598417;
   fWeightMatrix1to2[3][11] = 1.81553201144476;
   fWeightMatrix1to2[4][11] = -1.52867287970324;
   fWeightMatrix1to2[5][11] = 0.64516598693781;
   fWeightMatrix1to2[6][11] = -1.60939130070772;
   fWeightMatrix1to2[7][11] = -0.677535062056566;
   fWeightMatrix1to2[8][11] = 0.0866164375838481;
   fWeightMatrix1to2[9][11] = 0.56202227255094;
   fWeightMatrix1to2[10][11] = -0.847778845135806;
   fWeightMatrix1to2[11][11] = 0.978874124596028;
   fWeightMatrix1to2[12][11] = 1.71784381672087;
   fWeightMatrix1to2[0][12] = 1.37297514378029;
   fWeightMatrix1to2[1][12] = -0.297908541876368;
   fWeightMatrix1to2[2][12] = -0.72506244996681;
   fWeightMatrix1to2[3][12] = -1.54138344132874;
   fWeightMatrix1to2[4][12] = -2.42512196051747;
   fWeightMatrix1to2[5][12] = 1.02728347606833;
   fWeightMatrix1to2[6][12] = -0.518992992915869;
   fWeightMatrix1to2[7][12] = -0.797285499053282;
   fWeightMatrix1to2[8][12] = 0.458512244644476;
   fWeightMatrix1to2[9][12] = -1.33284083284989;
   fWeightMatrix1to2[10][12] = -0.844811575824792;
   fWeightMatrix1to2[11][12] = -1.61684518749597;
   fWeightMatrix1to2[12][12] = 0.957320349524908;
   fWeightMatrix1to2[0][13] = -1.65293354098652;
   fWeightMatrix1to2[1][13] = -1.86882980803857;
   fWeightMatrix1to2[2][13] = -0.349198604030123;
   fWeightMatrix1to2[3][13] = -0.811523168175557;
   fWeightMatrix1to2[4][13] = -1.74177648909156;
   fWeightMatrix1to2[5][13] = 0.82179128671162;
   fWeightMatrix1to2[6][13] = -1.29210492371228;
   fWeightMatrix1to2[7][13] = -0.977695682622877;
   fWeightMatrix1to2[8][13] = 1.67238253593547;
   fWeightMatrix1to2[9][13] = 0.205389783470358;
   fWeightMatrix1to2[10][13] = 0.320179119349734;
   fWeightMatrix1to2[11][13] = 0.101296027052077;
   fWeightMatrix1to2[12][13] = 1.30401773500492;
   fWeightMatrix1to2[0][14] = 2.14066673705523;
   fWeightMatrix1to2[1][14] = 0.762301514898357;
   fWeightMatrix1to2[2][14] = -1.1709861887335;
   fWeightMatrix1to2[3][14] = -0.67200496588039;
   fWeightMatrix1to2[4][14] = -1.7948960370799;
   fWeightMatrix1to2[5][14] = 1.22466741952095;
   fWeightMatrix1to2[6][14] = 0.580230368033818;
   fWeightMatrix1to2[7][14] = -0.0566877097441249;
   fWeightMatrix1to2[8][14] = 1.14053914477733;
   fWeightMatrix1to2[9][14] = 1.41192438474688;
   fWeightMatrix1to2[10][14] = 1.94997257994708;
   fWeightMatrix1to2[11][14] = -1.34134344228552;
   fWeightMatrix1to2[12][14] = 1.78281785601245;
   // weight matrix from layer 2 to 3
   fWeightMatrix2to3[0][0] = -0.61172759204299;
   fWeightMatrix2to3[0][1] = -2.04959877206786;
   fWeightMatrix2to3[0][2] = -0.400966241936375;
   fWeightMatrix2to3[0][3] = 0.272558319475644;
   fWeightMatrix2to3[0][4] = 0.628051041190123;
   fWeightMatrix2to3[0][5] = 0.248041342434725;
   fWeightMatrix2to3[0][6] = 0.249954041435775;
   fWeightMatrix2to3[0][7] = 0.0140759108599026;
   fWeightMatrix2to3[0][8] = -0.409521630667543;
   fWeightMatrix2to3[0][9] = 0.826712696954228;
   fWeightMatrix2to3[0][10] = 1.28280126855282;
   fWeightMatrix2to3[0][11] = -0.0383651666477764;
   fWeightMatrix2to3[0][12] = -1.42748546165594;
   fWeightMatrix2to3[0][13] = 1.38351760617997;
}

inline double ReadMLP1_25_EC::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   if (inputValues.size() != (unsigned int)fLayerSize[0]-1) {
      std::cout << "Input vector needs to be of size " << fLayerSize[0]-1 << std::endl;
      return 0;
   }

   for (int l=0; l<fLayers; l++)
      for (int i=0; i<fLayerSize[l]; i++) fWeights[l][i]=0;

   for (int l=0; l<fLayers-1; l++)
      fWeights[l][fLayerSize[l]-1]=1;

   for (int i=0; i<fLayerSize[0]-1; i++)
      fWeights[0][i]=inputValues[i];

   // layer 0 to 1
   for (int o=0; o<fLayerSize[1]-1; o++) {
      for (int i=0; i<fLayerSize[0]; i++) {
         double inputVal = fWeightMatrix0to1[o][i] * fWeights[0][i];
         fWeights[1][o] += inputVal;
      }
      fWeights[1][o] = ActivationFnc(fWeights[1][o]);
   }
   // layer 1 to 2
   for (int o=0; o<fLayerSize[2]-1; o++) {
      for (int i=0; i<fLayerSize[1]; i++) {
         double inputVal = fWeightMatrix1to2[o][i] * fWeights[1][i];
         fWeights[2][o] += inputVal;
      }
      fWeights[2][o] = ActivationFnc(fWeights[2][o]);
   }
   // layer 2 to 3
   for (int o=0; o<fLayerSize[3]; o++) {
      for (int i=0; i<fLayerSize[2]; i++) {
         double inputVal = fWeightMatrix2to3[o][i] * fWeights[2][i];
         fWeights[3][o] += inputVal;
      }
   }

   return fWeights[3][0];
}

double ReadMLP1_25_EC::ActivationFnc(double x) const
{
   // hyperbolic tan
   return tanh(x);
}
 
   
// Clean up
inline void ReadMLP1_25_EC::Clear() 
{
   // nothing to clear
}
inline double ReadMLP1_25_EC::GetMvaValue( const std::vector<double>& inputValues ) const
{
   // classifier response value
   double retval = 0;

   // classifier response, sanity check first
   if (!fStatusIsClean) {
      std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
      retval = 0;
   }
   else {
      if (IsNormalised()) {
         // normalise variables
         std::vector<double> iV;
         int ivar = 0;
         for (std::vector<double>::const_iterator varIt = inputValues.begin();
              varIt != inputValues.end(); varIt++, ivar++) {
            iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
         }
         retval = GetMvaValue__( iV );
      }
      else {
         retval = GetMvaValue__( inputValues );
      }
   }

   return retval;
}

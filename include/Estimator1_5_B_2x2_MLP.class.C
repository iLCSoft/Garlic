// Class: ReadMLP1_5_B_2x2
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : MLP::MLP
TMVA Release   : 3.9.6         [198918]
ROOT Release   : 5.16/00       [331776]
Creator        : reinhard
Date           : Tue Aug 11 15:32:22 2009
Host           : Linux polui02.in2p3.fr 2.6.9-67.0.4.ELsmp #1 SMP Thu Jan 31 16:30:09 CST 2008 i686 i686 i386 GNU/Linux
Dir            : /grid_mnt/data2__polgrid/llr/ilc/reinhard/ILCSoft/TMVA/macros
Training events: 7480


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
Normalise: "True" [Normalise input variables]
V: "False" [Verbose mode]
H: "True" [Print classifier-specific help message]
NCycles: "500" [Number of training cycles]
HiddenLayers: "N+1,N" [Specification of hidden layer architecture (N stands for number of variables; any integers may also be used)]
NeuronType: "tanh" [Neuron activation function type]
TestRate: "5" [Test for overtraining performed at each #th epochs]
# Default:
D: "False" [Use-decorrelated-variables flag (depreciated)]
VarTransform: "None" [Variable transformation method]
VarTransformType: "Signal" [Use signal or background events to derive for variable transformation (the transformation is applied on both types of, course)]
NbinsMVAPdf: "60" [Number of bins used for the PDFs of classifier outputs]
NsmoothMVAPdf: "2" [Number of smoothing iterations for classifier PDFs]
VerboseLevel: "Default" [Verbosity level]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
TxtWeightFilesOnly: "True" [If True: write all training results (weights) as text files (False: some are written in ROOT format)]
NeuronInputType: "sum" [Neuron input function type]
TrainingMethod: "BP" [Train with Back-Propagation (BP - default) or Genetic Algorithm (GA - slower and worse)]
LearningRate: "0.02" [ANN learning rate parameter]
DecayRate: "0.01" [Decay rate for learning parameter]
BPMode: "sequential" [Back-propagation learning mode: sequential or batch]
BatchSize: "-1" [Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 13
ClusterParameters.start       ClusterParameters.start           'F'    [0,10.8584003448]
ClusterParameters.end         ClusterParameters.end             'F'    [2.02683949471,37.0919189453]
ClusterParameters.depth       ClusterParameters.depth           'F'    [0,27.1935138702]
ClusterParameters.E1C/ClusterParameters.Etot_g   ClusterParameters.E1C_D_ClusterParameters.Etot_g     'F'    [0,0.966458976269]
ClusterParameters.E4C/ClusterParameters.Etot_g   ClusterParameters.E4C_D_ClusterParameters.Etot_g     'F'    [0.119802489877,1]
ClusterParameters.E9C/ClusterParameters.Etot_g   ClusterParameters.E9C_D_ClusterParameters.Etot_g     'F'    [0.673230469227,1]
ClusterParameters.dirErr      ClusterParameters.dirErr          'F'    [0.00623560138047,0.999999642372]
ClusterParameters.seedDirErr  ClusterParameters.seedDirErr      'F'    [0,0.999998450279]
ClusterParameters.Width       ClusterParameters.Width           'F'    [3.93501639366,57.5245780945]
ClusterParameters.Eccentricity ClusterParameters.Eccentricity     'F'    [0.109000213444,0.919470131397]
ClusterParameters.nHits       ClusterParameters.nHits           'F'    [5,74]
ClusterParameters.Volume      ClusterParameters.Volume          'F'    [563.485229492,4186785.25]
ClusterParameters.depth-ClusterParameters.start   ClusterParameters.depth_M_ClusterParameters.start     'F'    [-8.39325618744,27.1935138702]


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;
};

#endif

class ReadMLP1_5_B_2x2 : public IClassifierReader {

 public:

   // constructor
   ReadMLP1_5_B_2x2( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadMLP1_5_B_2x2" ),
        fStatusIsClean( true ),
        fNvars( 13 ),
        fIsNormalised( true )
   {      
      // the training input variables
      const char* inputVars[] = { "ClusterParameters.start", "ClusterParameters.end", "ClusterParameters.depth", "ClusterParameters.E1C/ClusterParameters.Etot_g", "ClusterParameters.E4C/ClusterParameters.Etot_g", "ClusterParameters.E9C/ClusterParameters.Etot_g", "ClusterParameters.dirErr", "ClusterParameters.seedDirErr", "ClusterParameters.Width", "ClusterParameters.Eccentricity", "ClusterParameters.nHits", "ClusterParameters.Volume", "ClusterParameters.depth-ClusterParameters.start" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 10.8584003448486;
      fVmin[1] = 2.0268394947052;
      fVmax[1] = 37.0919189453125;
      fVmin[2] = 0;
      fVmax[2] = 27.1935138702393;
      fVmin[3] = 0;
      fVmax[3] = 0.966458976268768;
      fVmin[4] = 0.119802489876747;
      fVmax[4] = 1;
      fVmin[5] = 0.673230469226837;
      fVmax[5] = 1;
      fVmin[6] = 0.00623560138046741;
      fVmax[6] = 0.999999642372131;
      fVmin[7] = 0;
      fVmax[7] = 0.999998450279236;
      fVmin[8] = 3.9350163936615;
      fVmax[8] = 57.5245780944824;
      fVmin[9] = 0.109000213444233;
      fVmax[9] = 0.919470131397247;
      fVmin[10] = 5;
      fVmax[10] = 74;
      fVmin[11] = 563.485229492188;
      fVmax[11] = 4186785.25;
      fVmin[12] = -8.39325618743896;
      fVmax[12] = 27.1935138702393;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';
      fType[10] = 'F';
      fType[11] = 'F';
      fType[12] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadMLP1_5_B_2x2() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;
   bool fStatusIsClean;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[13];
   double fVmax[13];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[13];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)

   double ActivationFnc(double x) const;

   int fLayers;
   int fLayerSize[4];
   double fWeightMatrix0to1[15][14];   // weight matrix from layer 0 to 1
   double fWeightMatrix1to2[14][15];   // weight matrix from layer 1 to 2
   double fWeightMatrix2to3[1][14];   // weight matrix from layer 2 to 3

   double * fWeights[4];
};

inline void ReadMLP1_5_B_2x2::Initialize()
{
   // build network structure
   fLayers = 4;
   fLayerSize[0] = 14; fWeights[0] = new double[14]; 
   fLayerSize[1] = 15; fWeights[1] = new double[15]; 
   fLayerSize[2] = 14; fWeights[2] = new double[14]; 
   fLayerSize[3] = 1; fWeights[3] = new double[1]; 
   // weight matrix from layer 0 to 1
   fWeightMatrix0to1[0][0] = 0.46080154489632;
   fWeightMatrix0to1[1][0] = 2.04206778946853;
   fWeightMatrix0to1[2][0] = 0.676918646538447;
   fWeightMatrix0to1[3][0] = 0.979587061096713;
   fWeightMatrix0to1[4][0] = -1.64511471392113;
   fWeightMatrix0to1[5][0] = -1.46047576570634;
   fWeightMatrix0to1[6][0] = -0.648993054738296;
   fWeightMatrix0to1[7][0] = 1.91450483396531;
   fWeightMatrix0to1[8][0] = -1.66372902552513;
   fWeightMatrix0to1[9][0] = -0.344969403178803;
   fWeightMatrix0to1[10][0] = -1.4861560368037;
   fWeightMatrix0to1[11][0] = -0.847590294144449;
   fWeightMatrix0to1[12][0] = 0.398073942834202;
   fWeightMatrix0to1[13][0] = -0.401206557282151;
   fWeightMatrix0to1[0][1] = -0.50903799657666;
   fWeightMatrix0to1[1][1] = 0.594756958125049;
   fWeightMatrix0to1[2][1] = -0.343245878522121;
   fWeightMatrix0to1[3][1] = 1.38428063016246;
   fWeightMatrix0to1[4][1] = -0.523138005123653;
   fWeightMatrix0to1[5][1] = 1.29189949246831;
   fWeightMatrix0to1[6][1] = -0.490392311953346;
   fWeightMatrix0to1[7][1] = -0.777238296743766;
   fWeightMatrix0to1[8][1] = 0.892063666252871;
   fWeightMatrix0to1[9][1] = -0.128921922368064;
   fWeightMatrix0to1[10][1] = -1.10854714694655;
   fWeightMatrix0to1[11][1] = -0.454317302874374;
   fWeightMatrix0to1[12][1] = 0.965985767204431;
   fWeightMatrix0to1[13][1] = -0.990136855337498;
   fWeightMatrix0to1[0][2] = -1.5399542329393;
   fWeightMatrix0to1[1][2] = 0.123599598195295;
   fWeightMatrix0to1[2][2] = 0.440342509092501;
   fWeightMatrix0to1[3][2] = 1.79074972915946;
   fWeightMatrix0to1[4][2] = 0.165164025263208;
   fWeightMatrix0to1[5][2] = -0.224957795334717;
   fWeightMatrix0to1[6][2] = 0.238700742405298;
   fWeightMatrix0to1[7][2] = -0.0350044380179255;
   fWeightMatrix0to1[8][2] = -1.31870425683048;
   fWeightMatrix0to1[9][2] = 1.18386483051908;
   fWeightMatrix0to1[10][2] = -1.16741697255929;
   fWeightMatrix0to1[11][2] = 2.1241702469646;
   fWeightMatrix0to1[12][2] = 2.55996409169012;
   fWeightMatrix0to1[13][2] = 0.952008224414642;
   fWeightMatrix0to1[0][3] = 2.05484996997234;
   fWeightMatrix0to1[1][3] = 1.3456281117157;
   fWeightMatrix0to1[2][3] = -0.601319087899053;
   fWeightMatrix0to1[3][3] = -1.9864690888639;
   fWeightMatrix0to1[4][3] = 1.12442422109847;
   fWeightMatrix0to1[5][3] = 0.0600310458082312;
   fWeightMatrix0to1[6][3] = 1.77359739750559;
   fWeightMatrix0to1[7][3] = 1.46381757372719;
   fWeightMatrix0to1[8][3] = 1.45419100791363;
   fWeightMatrix0to1[9][3] = 0.0203439840572114;
   fWeightMatrix0to1[10][3] = -1.62229230163463;
   fWeightMatrix0to1[11][3] = 1.47522519279549;
   fWeightMatrix0to1[12][3] = -3.45337851328231;
   fWeightMatrix0to1[13][3] = -0.729048966015169;
   fWeightMatrix0to1[0][4] = -1.58362777844679;
   fWeightMatrix0to1[1][4] = -1.69078812773268;
   fWeightMatrix0to1[2][4] = 1.82381272865966;
   fWeightMatrix0to1[3][4] = 0.794202224486812;
   fWeightMatrix0to1[4][4] = -1.48287572742037;
   fWeightMatrix0to1[5][4] = 0.643743057421745;
   fWeightMatrix0to1[6][4] = -0.15411762035056;
   fWeightMatrix0to1[7][4] = 0.300673360634173;
   fWeightMatrix0to1[8][4] = 1.45256183868894;
   fWeightMatrix0to1[9][4] = -2.09200934565581;
   fWeightMatrix0to1[10][4] = 0.267483240493581;
   fWeightMatrix0to1[11][4] = -1.37492948726876;
   fWeightMatrix0to1[12][4] = -0.126648118055477;
   fWeightMatrix0to1[13][4] = -0.572587322323602;
   fWeightMatrix0to1[0][5] = -1.22866916846602;
   fWeightMatrix0to1[1][5] = -1.32943940545217;
   fWeightMatrix0to1[2][5] = 1.07667602522562;
   fWeightMatrix0to1[3][5] = 1.32104201675079;
   fWeightMatrix0to1[4][5] = 2.06284842514459;
   fWeightMatrix0to1[5][5] = 0.082567987270136;
   fWeightMatrix0to1[6][5] = -1.82008874834998;
   fWeightMatrix0to1[7][5] = -2.3818490886919;
   fWeightMatrix0to1[8][5] = 0.573840943111919;
   fWeightMatrix0to1[9][5] = 0.320954196837812;
   fWeightMatrix0to1[10][5] = 2.12162882669604;
   fWeightMatrix0to1[11][5] = 0.458750285896885;
   fWeightMatrix0to1[12][5] = 1.24509912901611;
   fWeightMatrix0to1[13][5] = -0.555371783337019;
   fWeightMatrix0to1[0][6] = -1.43830036895447;
   fWeightMatrix0to1[1][6] = -0.337746134341348;
   fWeightMatrix0to1[2][6] = 1.60676066519743;
   fWeightMatrix0to1[3][6] = -1.0824394030688;
   fWeightMatrix0to1[4][6] = -1.30810606967254;
   fWeightMatrix0to1[5][6] = -1.33854201576918;
   fWeightMatrix0to1[6][6] = -0.438054279530757;
   fWeightMatrix0to1[7][6] = -0.839437269562522;
   fWeightMatrix0to1[8][6] = 1.24288662009473;
   fWeightMatrix0to1[9][6] = -1.69411389780535;
   fWeightMatrix0to1[10][6] = -0.448699092273819;
   fWeightMatrix0to1[11][6] = 1.69170045351084;
   fWeightMatrix0to1[12][6] = -0.314010634036331;
   fWeightMatrix0to1[13][6] = -1.37435384372535;
   fWeightMatrix0to1[0][7] = -1.49402212777594;
   fWeightMatrix0to1[1][7] = -0.0302112500831267;
   fWeightMatrix0to1[2][7] = -1.35422514214228;
   fWeightMatrix0to1[3][7] = -0.877012813432824;
   fWeightMatrix0to1[4][7] = 0.888148005131801;
   fWeightMatrix0to1[5][7] = 1.58285113117297;
   fWeightMatrix0to1[6][7] = -1.37152806230622;
   fWeightMatrix0to1[7][7] = 0.964623843367;
   fWeightMatrix0to1[8][7] = -1.25086772815731;
   fWeightMatrix0to1[9][7] = -0.466203056733736;
   fWeightMatrix0to1[10][7] = 0.0563968156984631;
   fWeightMatrix0to1[11][7] = 0.706395149035933;
   fWeightMatrix0to1[12][7] = -0.388685680745623;
   fWeightMatrix0to1[13][7] = 0.42898303812595;
   fWeightMatrix0to1[0][8] = 0.455525117622952;
   fWeightMatrix0to1[1][8] = 0.344421127211205;
   fWeightMatrix0to1[2][8] = -1.50806416233489;
   fWeightMatrix0to1[3][8] = 2.10686011420472;
   fWeightMatrix0to1[4][8] = 0.641121430069165;
   fWeightMatrix0to1[5][8] = -1.13592600934388;
   fWeightMatrix0to1[6][8] = 0.599931540068401;
   fWeightMatrix0to1[7][8] = -0.76408398060083;
   fWeightMatrix0to1[8][8] = -1.45470143310816;
   fWeightMatrix0to1[9][8] = 1.34747275260865;
   fWeightMatrix0to1[10][8] = -0.469815509562641;
   fWeightMatrix0to1[11][8] = 2.78295524708098;
   fWeightMatrix0to1[12][8] = 2.78988171646337;
   fWeightMatrix0to1[13][8] = -0.0920637510251926;
   fWeightMatrix0to1[0][9] = -0.310687137960874;
   fWeightMatrix0to1[1][9] = 0.206544557960353;
   fWeightMatrix0to1[2][9] = -1.9006903205931;
   fWeightMatrix0to1[3][9] = 1.38289322087601;
   fWeightMatrix0to1[4][9] = -0.0235882872685744;
   fWeightMatrix0to1[5][9] = -1.69867548411048;
   fWeightMatrix0to1[6][9] = 0.701951105980593;
   fWeightMatrix0to1[7][9] = -1.28041616855859;
   fWeightMatrix0to1[8][9] = -0.0618015095592247;
   fWeightMatrix0to1[9][9] = -0.47754529829583;
   fWeightMatrix0to1[10][9] = 1.57030512117896;
   fWeightMatrix0to1[11][9] = -0.883991214945159;
   fWeightMatrix0to1[12][9] = -0.00666838098623804;
   fWeightMatrix0to1[13][9] = 1.72511827829506;
   fWeightMatrix0to1[0][10] = 1.4678866614144;
   fWeightMatrix0to1[1][10] = 0.204876119665118;
   fWeightMatrix0to1[2][10] = -1.69492149612343;
   fWeightMatrix0to1[3][10] = -0.236515628053375;
   fWeightMatrix0to1[4][10] = -1.90233409773293;
   fWeightMatrix0to1[5][10] = 1.36862385500584;
   fWeightMatrix0to1[6][10] = 1.18646641275247;
   fWeightMatrix0to1[7][10] = -0.274098420210867;
   fWeightMatrix0to1[8][10] = -0.377354895197684;
   fWeightMatrix0to1[9][10] = -3.70109386623133;
   fWeightMatrix0to1[10][10] = -1.5127613555026;
   fWeightMatrix0to1[11][10] = 0.189620079193305;
   fWeightMatrix0to1[12][10] = -0.4551610778509;
   fWeightMatrix0to1[13][10] = -0.629614655899242;
   fWeightMatrix0to1[0][11] = -0.141434853848508;
   fWeightMatrix0to1[1][11] = 0.13711492661706;
   fWeightMatrix0to1[2][11] = 0.702760192959028;
   fWeightMatrix0to1[3][11] = 0.242318827283302;
   fWeightMatrix0to1[4][11] = 0.446668164630796;
   fWeightMatrix0to1[5][11] = -1.91568612784277;
   fWeightMatrix0to1[6][11] = 1.35203975119251;
   fWeightMatrix0to1[7][11] = 1.30333128693635;
   fWeightMatrix0to1[8][11] = 0.902904845313088;
   fWeightMatrix0to1[9][11] = 0.0513977023778059;
   fWeightMatrix0to1[10][11] = 0.853890815264942;
   fWeightMatrix0to1[11][11] = -0.134809622406164;
   fWeightMatrix0to1[12][11] = 0.304892397964924;
   fWeightMatrix0to1[13][11] = 0.888541488265681;
   fWeightMatrix0to1[0][12] = -0.858071575327632;
   fWeightMatrix0to1[1][12] = -0.591497098870492;
   fWeightMatrix0to1[2][12] = 1.42478033555592;
   fWeightMatrix0to1[3][12] = 1.30956525188407;
   fWeightMatrix0to1[4][12] = -0.0703353789486856;
   fWeightMatrix0to1[5][12] = 1.44170328668529;
   fWeightMatrix0to1[6][12] = 1.83997658065663;
   fWeightMatrix0to1[7][12] = -1.67303358058572;
   fWeightMatrix0to1[8][12] = 0.849861806769434;
   fWeightMatrix0to1[9][12] = -0.703376307523972;
   fWeightMatrix0to1[10][12] = 0.442982213915376;
   fWeightMatrix0to1[11][12] = -0.808022182073668;
   fWeightMatrix0to1[12][12] = -1.03892357068591;
   fWeightMatrix0to1[13][12] = 1.19911898196157;
   fWeightMatrix0to1[0][13] = 1.27445950564606;
   fWeightMatrix0to1[1][13] = -1.87926682554326;
   fWeightMatrix0to1[2][13] = 0.327474364949535;
   fWeightMatrix0to1[3][13] = -0.0920894743764778;
   fWeightMatrix0to1[4][13] = 1.08631793380157;
   fWeightMatrix0to1[5][13] = 2.26284909010995;
   fWeightMatrix0to1[6][13] = -0.668206258381806;
   fWeightMatrix0to1[7][13] = -1.49558853248061;
   fWeightMatrix0to1[8][13] = -1.45725390540664;
   fWeightMatrix0to1[9][13] = 1.64907504577909;
   fWeightMatrix0to1[10][13] = 2.05258168099435;
   fWeightMatrix0to1[11][13] = 1.19962490022949;
   fWeightMatrix0to1[12][13] = 0.73447485680466;
   fWeightMatrix0to1[13][13] = -0.77086188921957;
   // weight matrix from layer 1 to 2
   fWeightMatrix1to2[0][0] = -1.98943408307415;
   fWeightMatrix1to2[1][0] = 0.966197229319009;
   fWeightMatrix1to2[2][0] = 0.0833637003930222;
   fWeightMatrix1to2[3][0] = -1.40075555823875;
   fWeightMatrix1to2[4][0] = -0.549544194545583;
   fWeightMatrix1to2[5][0] = 0.396636186207506;
   fWeightMatrix1to2[6][0] = 0.0967465512120484;
   fWeightMatrix1to2[7][0] = -1.98447402470965;
   fWeightMatrix1to2[8][0] = 1.54315629084507;
   fWeightMatrix1to2[9][0] = 0.984384131097426;
   fWeightMatrix1to2[10][0] = -0.579809660776846;
   fWeightMatrix1to2[11][0] = -0.253523438585425;
   fWeightMatrix1to2[12][0] = 1.32571330076064;
   fWeightMatrix1to2[0][1] = 0.961858745106971;
   fWeightMatrix1to2[1][1] = 0.394409013059452;
   fWeightMatrix1to2[2][1] = -0.309986001032285;
   fWeightMatrix1to2[3][1] = -2.11496442444877;
   fWeightMatrix1to2[4][1] = -0.760149186641917;
   fWeightMatrix1to2[5][1] = 1.75028950646989;
   fWeightMatrix1to2[6][1] = 1.51051077855854;
   fWeightMatrix1to2[7][1] = 0.59961298668409;
   fWeightMatrix1to2[8][1] = 0.265349269397381;
   fWeightMatrix1to2[9][1] = 2.53953718050481;
   fWeightMatrix1to2[10][1] = -1.93407890683877;
   fWeightMatrix1to2[11][1] = -1.36198870615766;
   fWeightMatrix1to2[12][1] = -0.40359083568687;
   fWeightMatrix1to2[0][2] = -1.36193000626986;
   fWeightMatrix1to2[1][2] = 0.971499910985538;
   fWeightMatrix1to2[2][2] = 1.86406703851006;
   fWeightMatrix1to2[3][2] = -1.12486331007421;
   fWeightMatrix1to2[4][2] = 0.812697041043359;
   fWeightMatrix1to2[5][2] = -0.121777144320703;
   fWeightMatrix1to2[6][2] = -1.81165875815631;
   fWeightMatrix1to2[7][2] = -0.840852229531046;
   fWeightMatrix1to2[8][2] = 0.999566969079687;
   fWeightMatrix1to2[9][2] = -0.0141354521886765;
   fWeightMatrix1to2[10][2] = 0.892924839642587;
   fWeightMatrix1to2[11][2] = -1.09858702515516;
   fWeightMatrix1to2[12][2] = 1.73516288189679;
   fWeightMatrix1to2[0][3] = -1.8153848721875;
   fWeightMatrix1to2[1][3] = 0.736677548250147;
   fWeightMatrix1to2[2][3] = -0.251825779233743;
   fWeightMatrix1to2[3][3] = -1.48223732507322;
   fWeightMatrix1to2[4][3] = -1.64629834949269;
   fWeightMatrix1to2[5][3] = -1.99145743183014;
   fWeightMatrix1to2[6][3] = -0.217302471118644;
   fWeightMatrix1to2[7][3] = -1.98296118875028;
   fWeightMatrix1to2[8][3] = -1.56879291827587;
   fWeightMatrix1to2[9][3] = -1.34037924584593;
   fWeightMatrix1to2[10][3] = 0.166720566547216;
   fWeightMatrix1to2[11][3] = -1.01316302250338;
   fWeightMatrix1to2[12][3] = -1.78396376488791;
   fWeightMatrix1to2[0][4] = 1.45191409230786;
   fWeightMatrix1to2[1][4] = -0.865221859979018;
   fWeightMatrix1to2[2][4] = 0.314874474413334;
   fWeightMatrix1to2[3][4] = -1.10450611396071;
   fWeightMatrix1to2[4][4] = -1.65784726662313;
   fWeightMatrix1to2[5][4] = 1.81199260458946;
   fWeightMatrix1to2[6][4] = 1.27664666316544;
   fWeightMatrix1to2[7][4] = -0.961822707328993;
   fWeightMatrix1to2[8][4] = -1.39057905202114;
   fWeightMatrix1to2[9][4] = -0.880178217324546;
   fWeightMatrix1to2[10][4] = -0.657345765787802;
   fWeightMatrix1to2[11][4] = -1.61484438284076;
   fWeightMatrix1to2[12][4] = 0.334433302565765;
   fWeightMatrix1to2[0][5] = 0.387741095299593;
   fWeightMatrix1to2[1][5] = 2.0225382475465;
   fWeightMatrix1to2[2][5] = -0.154768783492035;
   fWeightMatrix1to2[3][5] = 0.407769561869319;
   fWeightMatrix1to2[4][5] = -0.72824038491416;
   fWeightMatrix1to2[5][5] = -2.00932252453787;
   fWeightMatrix1to2[6][5] = 1.08574605438429;
   fWeightMatrix1to2[7][5] = 1.33027403082093;
   fWeightMatrix1to2[8][5] = -0.900383878372461;
   fWeightMatrix1to2[9][5] = -1.40905400864917;
   fWeightMatrix1to2[10][5] = 1.00675693559867;
   fWeightMatrix1to2[11][5] = 1.26167903649182;
   fWeightMatrix1to2[12][5] = 0.695342128061775;
   fWeightMatrix1to2[0][6] = -0.544118606697589;
   fWeightMatrix1to2[1][6] = -0.359822194367759;
   fWeightMatrix1to2[2][6] = 1.27434285714879;
   fWeightMatrix1to2[3][6] = 0.805651760634541;
   fWeightMatrix1to2[4][6] = 1.14969097191805;
   fWeightMatrix1to2[5][6] = -0.26529749051549;
   fWeightMatrix1to2[6][6] = 0.445191031191441;
   fWeightMatrix1to2[7][6] = -0.445863914303728;
   fWeightMatrix1to2[8][6] = -1.39143239998756;
   fWeightMatrix1to2[9][6] = -0.0119196120916025;
   fWeightMatrix1to2[10][6] = -1.87843207763069;
   fWeightMatrix1to2[11][6] = -1.43736498571517;
   fWeightMatrix1to2[12][6] = -1.80514503796859;
   fWeightMatrix1to2[0][7] = 1.66713344980468;
   fWeightMatrix1to2[1][7] = -1.73150098382678;
   fWeightMatrix1to2[2][7] = 1.6207239212345;
   fWeightMatrix1to2[3][7] = -1.7492112094993;
   fWeightMatrix1to2[4][7] = 0.70129122393837;
   fWeightMatrix1to2[5][7] = -0.995460499050174;
   fWeightMatrix1to2[6][7] = 0.532533714856921;
   fWeightMatrix1to2[7][7] = 0.734080498805014;
   fWeightMatrix1to2[8][7] = -1.77953819101341;
   fWeightMatrix1to2[9][7] = 0.260471894147055;
   fWeightMatrix1to2[10][7] = 0.36813781946742;
   fWeightMatrix1to2[11][7] = -2.04265780981985;
   fWeightMatrix1to2[12][7] = -1.56227869014698;
   fWeightMatrix1to2[0][8] = -1.62274228241441;
   fWeightMatrix1to2[1][8] = -0.785340520543137;
   fWeightMatrix1to2[2][8] = 2.02242053799459;
   fWeightMatrix1to2[3][8] = -0.638254422204348;
   fWeightMatrix1to2[4][8] = 1.16707760724508;
   fWeightMatrix1to2[5][8] = -0.800535276517979;
   fWeightMatrix1to2[6][8] = -1.17119006882479;
   fWeightMatrix1to2[7][8] = -1.29583036485352;
   fWeightMatrix1to2[8][8] = -1.11800061900218;
   fWeightMatrix1to2[9][8] = -1.42251952360916;
   fWeightMatrix1to2[10][8] = 0.8049048384598;
   fWeightMatrix1to2[11][8] = -1.23728805470878;
   fWeightMatrix1to2[12][8] = -0.98719226107953;
   fWeightMatrix1to2[0][9] = 1.7062491359795;
   fWeightMatrix1to2[1][9] = 0.184228176653525;
   fWeightMatrix1to2[2][9] = -0.561001564689496;
   fWeightMatrix1to2[3][9] = 1.82211463823223;
   fWeightMatrix1to2[4][9] = -4.1051641931814;
   fWeightMatrix1to2[5][9] = 1.37163999785796;
   fWeightMatrix1to2[6][9] = 1.04418655875226;
   fWeightMatrix1to2[7][9] = -1.30167058251468;
   fWeightMatrix1to2[8][9] = -0.728035805267344;
   fWeightMatrix1to2[9][9] = 0.131857873315911;
   fWeightMatrix1to2[10][9] = -1.05285206868784;
   fWeightMatrix1to2[11][9] = 0.580652367813766;
   fWeightMatrix1to2[12][9] = 1.63078766451128;
   fWeightMatrix1to2[0][10] = 1.41411510255076;
   fWeightMatrix1to2[1][10] = 1.64883898299731;
   fWeightMatrix1to2[2][10] = -1.14211974228669;
   fWeightMatrix1to2[3][10] = 1.19270429589632;
   fWeightMatrix1to2[4][10] = -1.98240141522312;
   fWeightMatrix1to2[5][10] = 0.56910759446553;
   fWeightMatrix1to2[6][10] = -1.89745210257549;
   fWeightMatrix1to2[7][10] = -1.67900784531398;
   fWeightMatrix1to2[8][10] = -0.106120266444122;
   fWeightMatrix1to2[9][10] = 0.765945282042794;
   fWeightMatrix1to2[10][10] = 0.725330533697764;
   fWeightMatrix1to2[11][10] = 1.1043575742778;
   fWeightMatrix1to2[12][10] = 0.544328609888703;
   fWeightMatrix1to2[0][11] = -0.099475968420094;
   fWeightMatrix1to2[1][11] = -0.577733416055411;
   fWeightMatrix1to2[2][11] = 0.234822559750987;
   fWeightMatrix1to2[3][11] = 1.80945804807966;
   fWeightMatrix1to2[4][11] = -2.23043726246344;
   fWeightMatrix1to2[5][11] = 0.247847526209767;
   fWeightMatrix1to2[6][11] = -1.43949584488486;
   fWeightMatrix1to2[7][11] = -0.0516365888324711;
   fWeightMatrix1to2[8][11] = -0.113121016231484;
   fWeightMatrix1to2[9][11] = 0.00764833476079494;
   fWeightMatrix1to2[10][11] = -0.977677517922994;
   fWeightMatrix1to2[11][11] = 0.988487404515098;
   fWeightMatrix1to2[12][11] = 1.74124366298747;
   fWeightMatrix1to2[0][12] = 0.736416079521524;
   fWeightMatrix1to2[1][12] = -0.257709353428545;
   fWeightMatrix1to2[2][12] = -1.0300965239323;
   fWeightMatrix1to2[3][12] = -1.29236408421622;
   fWeightMatrix1to2[4][12] = -2.7272434281644;
   fWeightMatrix1to2[5][12] = 1.02862469317039;
   fWeightMatrix1to2[6][12] = -0.442893618296268;
   fWeightMatrix1to2[7][12] = -1.17720635580798;
   fWeightMatrix1to2[8][12] = 0.558638049583186;
   fWeightMatrix1to2[9][12] = -1.41453585281748;
   fWeightMatrix1to2[10][12] = -0.915007782153251;
   fWeightMatrix1to2[11][12] = -1.50995427648673;
   fWeightMatrix1to2[12][12] = 0.922730823053254;
   fWeightMatrix1to2[0][13] = -1.4467479024872;
   fWeightMatrix1to2[1][13] = -1.84106239652588;
   fWeightMatrix1to2[2][13] = -0.75686369184446;
   fWeightMatrix1to2[3][13] = -1.01169518385739;
   fWeightMatrix1to2[4][13] = -1.49596963226038;
   fWeightMatrix1to2[5][13] = 1.26377886801605;
   fWeightMatrix1to2[6][13] = -1.25968919556427;
   fWeightMatrix1to2[7][13] = -1.43092732126068;
   fWeightMatrix1to2[8][13] = 1.79469362743747;
   fWeightMatrix1to2[9][13] = 0.93710206693449;
   fWeightMatrix1to2[10][13] = 0.267010848830409;
   fWeightMatrix1to2[11][13] = -0.0145580573235623;
   fWeightMatrix1to2[12][13] = 1.06427330804472;
   fWeightMatrix1to2[0][14] = 1.79524089921549;
   fWeightMatrix1to2[1][14] = 0.652768957298534;
   fWeightMatrix1to2[2][14] = -0.767043621028383;
   fWeightMatrix1to2[3][14] = -0.50025104957111;
   fWeightMatrix1to2[4][14] = -1.90537906289651;
   fWeightMatrix1to2[5][14] = 0.855877987967632;
   fWeightMatrix1to2[6][14] = 0.762224262452194;
   fWeightMatrix1to2[7][14] = 0.254691618845618;
   fWeightMatrix1to2[8][14] = 1.03185766906844;
   fWeightMatrix1to2[9][14] = 0.374842278305493;
   fWeightMatrix1to2[10][14] = 1.82896630665249;
   fWeightMatrix1to2[11][14] = -1.28726594282398;
   fWeightMatrix1to2[12][14] = 2.06943301361716;
   // weight matrix from layer 2 to 3
   fWeightMatrix2to3[0][0] = 0.0111691460642112;
   fWeightMatrix2to3[0][1] = -1.87954423751836;
   fWeightMatrix2to3[0][2] = -0.10591017469324;
   fWeightMatrix2to3[0][3] = 0.00276327779348836;
   fWeightMatrix2to3[0][4] = 1.09044273178608;
   fWeightMatrix2to3[0][5] = 0.0462682456677882;
   fWeightMatrix2to3[0][6] = -0.0284322627435758;
   fWeightMatrix2to3[0][7] = 0.0247550350332545;
   fWeightMatrix2to3[0][8] = -0.0234420385125058;
   fWeightMatrix2to3[0][9] = 0.24412123258844;
   fWeightMatrix2to3[0][10] = 1.42436878095552;
   fWeightMatrix2to3[0][11] = -0.0261061520910526;
   fWeightMatrix2to3[0][12] = -0.960717414476238;
   fWeightMatrix2to3[0][13] = 1.67330266324416;
}

inline double ReadMLP1_5_B_2x2::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   if (inputValues.size() != (unsigned int)fLayerSize[0]-1) {
      std::cout << "Input vector needs to be of size " << fLayerSize[0]-1 << std::endl;
      return 0;
   }

   for (int l=0; l<fLayers; l++)
      for (int i=0; i<fLayerSize[l]; i++) fWeights[l][i]=0;

   for (int l=0; l<fLayers-1; l++)
      fWeights[l][fLayerSize[l]-1]=1;

   for (int i=0; i<fLayerSize[0]-1; i++)
      fWeights[0][i]=inputValues[i];

   // layer 0 to 1
   for (int o=0; o<fLayerSize[1]-1; o++) {
      for (int i=0; i<fLayerSize[0]; i++) {
         double inputVal = fWeightMatrix0to1[o][i] * fWeights[0][i];
         fWeights[1][o] += inputVal;
      }
      fWeights[1][o] = ActivationFnc(fWeights[1][o]);
   }
   // layer 1 to 2
   for (int o=0; o<fLayerSize[2]-1; o++) {
      for (int i=0; i<fLayerSize[1]; i++) {
         double inputVal = fWeightMatrix1to2[o][i] * fWeights[1][i];
         fWeights[2][o] += inputVal;
      }
      fWeights[2][o] = ActivationFnc(fWeights[2][o]);
   }
   // layer 2 to 3
   for (int o=0; o<fLayerSize[3]; o++) {
      for (int i=0; i<fLayerSize[2]; i++) {
         double inputVal = fWeightMatrix2to3[o][i] * fWeights[2][i];
         fWeights[3][o] += inputVal;
      }
   }

   return fWeights[3][0];
}

double ReadMLP1_5_B_2x2::ActivationFnc(double x) const
{
   // hyperbolic tan
   return tanh(x);
}
 
   
// Clean up
inline void ReadMLP1_5_B_2x2::Clear() 
{
   // nothing to clear
}
inline double ReadMLP1_5_B_2x2::GetMvaValue( const std::vector<double>& inputValues ) const
{
   // classifier response value
   double retval = 0;

   // classifier response, sanity check first
   if (!fStatusIsClean) {
      std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
      retval = 0;
   }
   else {
      if (IsNormalised()) {
         // normalise variables
         std::vector<double> iV;
         int ivar = 0;
         for (std::vector<double>::const_iterator varIt = inputValues.begin();
              varIt != inputValues.end(); varIt++, ivar++) {
            iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
         }
         retval = GetMvaValue__( iV );
      }
      else {
         retval = GetMvaValue__( inputValues );
      }
   }

   return retval;
}

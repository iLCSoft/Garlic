// Class: ReadMLP0_35_B
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : MLP::MLP
TMVA Release   : 3.9.6         [198918]
ROOT Release   : 5.16/00       [331776]
Creator        : reinhard
Date           : Fri Aug  7 08:36:10 2009
Host           : Linux polui02.in2p3.fr 2.6.9-67.0.4.ELsmp #1 SMP Thu Jan 31 16:30:09 CST 2008 i686 i686 i386 GNU/Linux
Dir            : /grid_mnt/data2__polgrid/llr/ilc/reinhard/ILCSoft/TMVA/macros
Training events: 16800


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
Normalise: "True" [Normalise input variables]
V: "False" [Verbose mode]
H: "True" [Print classifier-specific help message]
NCycles: "500" [Number of training cycles]
HiddenLayers: "N+1,N" [Specification of hidden layer architecture (N stands for number of variables; any integers may also be used)]
NeuronType: "tanh" [Neuron activation function type]
TestRate: "5" [Test for overtraining performed at each #th epochs]
# Default:
D: "False" [Use-decorrelated-variables flag (depreciated)]
VarTransform: "None" [Variable transformation method]
VarTransformType: "Signal" [Use signal or background events to derive for variable transformation (the transformation is applied on both types of, course)]
NbinsMVAPdf: "60" [Number of bins used for the PDFs of classifier outputs]
NsmoothMVAPdf: "2" [Number of smoothing iterations for classifier PDFs]
VerboseLevel: "Default" [Verbosity level]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
TxtWeightFilesOnly: "True" [If True: write all training results (weights) as text files (False: some are written in ROOT format)]
NeuronInputType: "sum" [Neuron input function type]
TrainingMethod: "BP" [Train with Back-Propagation (BP - default) or Genetic Algorithm (GA - slower and worse)]
LearningRate: "0.02" [ANN learning rate parameter]
DecayRate: "0.01" [Decay rate for learning parameter]
BPMode: "sequential" [Back-propagation learning mode: sequential or batch]
BatchSize: "-1" [Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 13
ClusterParameters.start       ClusterParameters.start           'F'    [0,27.0523986816]
ClusterParameters.end         ClusterParameters.end             'F'    [0.906250238419,34.5725059509]
ClusterParameters.depth       ClusterParameters.depth           'F'    [0,28.5744152069]
ClusterParameters.E1C/ClusterParameters.Etot_g   ClusterParameters.E1C_D_ClusterParameters.Etot_g     'F'    [0,1]
ClusterParameters.E4C/ClusterParameters.Etot_g   ClusterParameters.E4C_D_ClusterParameters.Etot_g     'F'    [0,1]
ClusterParameters.E9C/ClusterParameters.Etot_g   ClusterParameters.E9C_D_ClusterParameters.Etot_g     'F'    [0.265016496181,1]
ClusterParameters.dirErr      ClusterParameters.dirErr          'F'    [0.00215157400817,0.999999403954]
ClusterParameters.seedDirErr  ClusterParameters.seedDirErr      'F'    [0,0.999999761581]
ClusterParameters.Width       ClusterParameters.Width           'F'    [0.323219060898,17.4902324677]
ClusterParameters.Eccentricity ClusterParameters.Eccentricity     'F'    [0.00856297370046,0.927810490131]
ClusterParameters.nHits       ClusterParameters.nHits           'F'    [5,48]
ClusterParameters.Volume      ClusterParameters.Volume          'F'    [9.60728168488,1042241.125]
ClusterParameters.depth-ClusterParameters.start   ClusterParameters.depth_M_ClusterParameters.start     'F'    [-10.4086112976,21.2250728607]


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;
};

#endif

class ReadMLP0_35_B : public IClassifierReader {

 public:

   // constructor
   ReadMLP0_35_B( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadMLP0_35_B" ),
        fStatusIsClean( true ),
        fNvars( 13 ),
        fIsNormalised( true )
   {      
      // the training input variables
      const char* inputVars[] = { "ClusterParameters.start", "ClusterParameters.end", "ClusterParameters.depth", "ClusterParameters.E1C/ClusterParameters.Etot_g", "ClusterParameters.E4C/ClusterParameters.Etot_g", "ClusterParameters.E9C/ClusterParameters.Etot_g", "ClusterParameters.dirErr", "ClusterParameters.seedDirErr", "ClusterParameters.Width", "ClusterParameters.Eccentricity", "ClusterParameters.nHits", "ClusterParameters.Volume", "ClusterParameters.depth-ClusterParameters.start" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 27.0523986816406;
      fVmin[1] = 0.906250238418579;
      fVmax[1] = 34.5725059509277;
      fVmin[2] = 0;
      fVmax[2] = 28.5744152069092;
      fVmin[3] = 0;
      fVmax[3] = 1;
      fVmin[4] = 0;
      fVmax[4] = 1;
      fVmin[5] = 0.265016496181488;
      fVmax[5] = 1;
      fVmin[6] = 0.00215157400816679;
      fVmax[6] = 0.999999403953552;
      fVmin[7] = 0;
      fVmax[7] = 0.999999761581421;
      fVmin[8] = 0.323219060897827;
      fVmax[8] = 17.4902324676514;
      fVmin[9] = 0.00856297370046377;
      fVmax[9] = 0.927810490131378;
      fVmin[10] = 5;
      fVmax[10] = 48;
      fVmin[11] = 9.60728168487549;
      fVmax[11] = 1042241.125;
      fVmin[12] = -10.4086112976074;
      fVmax[12] = 21.2250728607178;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';
      fType[10] = 'F';
      fType[11] = 'F';
      fType[12] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadMLP0_35_B() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;
   bool fStatusIsClean;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[13];
   double fVmax[13];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[13];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)

   double ActivationFnc(double x) const;

   int fLayers;
   int fLayerSize[4];
   double fWeightMatrix0to1[15][14];   // weight matrix from layer 0 to 1
   double fWeightMatrix1to2[14][15];   // weight matrix from layer 1 to 2
   double fWeightMatrix2to3[1][14];   // weight matrix from layer 2 to 3

   double * fWeights[4];
};

inline void ReadMLP0_35_B::Initialize()
{
   // build network structure
   fLayers = 4;
   fLayerSize[0] = 14; fWeights[0] = new double[14]; 
   fLayerSize[1] = 15; fWeights[1] = new double[15]; 
   fLayerSize[2] = 14; fWeights[2] = new double[14]; 
   fLayerSize[3] = 1; fWeights[3] = new double[1]; 
   // weight matrix from layer 0 to 1
   fWeightMatrix0to1[0][0] = -0.456242233419229;
   fWeightMatrix0to1[1][0] = 1.99684987838855;
   fWeightMatrix0to1[2][0] = 1.80316858340902;
   fWeightMatrix0to1[3][0] = 2.09002812838596;
   fWeightMatrix0to1[4][0] = -2.04823638810164;
   fWeightMatrix0to1[5][0] = -2.06790641540547;
   fWeightMatrix0to1[6][0] = -0.544129958784695;
   fWeightMatrix0to1[7][0] = 2.41238486253617;
   fWeightMatrix0to1[8][0] = -2.20986122768655;
   fWeightMatrix0to1[9][0] = -0.40108206876469;
   fWeightMatrix0to1[10][0] = -1.65968466594673;
   fWeightMatrix0to1[11][0] = -0.877890943552116;
   fWeightMatrix0to1[12][0] = 1.61398675421629;
   fWeightMatrix0to1[13][0] = 0.289718827596095;
   fWeightMatrix0to1[0][1] = 1.75744290693885;
   fWeightMatrix0to1[1][1] = 0.68539291505564;
   fWeightMatrix0to1[2][1] = 0.987141045270067;
   fWeightMatrix0to1[3][1] = 1.89720351083039;
   fWeightMatrix0to1[4][1] = 0.0738223662964033;
   fWeightMatrix0to1[5][1] = 0.775811872846391;
   fWeightMatrix0to1[6][1] = -0.210985130348167;
   fWeightMatrix0to1[7][1] = -0.630629669549171;
   fWeightMatrix0to1[8][1] = 0.225039425659454;
   fWeightMatrix0to1[9][1] = 0.227347591070949;
   fWeightMatrix0to1[10][1] = -0.990565032816933;
   fWeightMatrix0to1[11][1] = -0.679657069159098;
   fWeightMatrix0to1[12][1] = 0.581742661551439;
   fWeightMatrix0to1[13][1] = 1.72624725024946;
   fWeightMatrix0to1[0][2] = 0.0257122160892477;
   fWeightMatrix0to1[1][2] = 0.140965967962219;
   fWeightMatrix0to1[2][2] = 0.520323335039733;
   fWeightMatrix0to1[3][2] = 1.75200501207453;
   fWeightMatrix0to1[4][2] = 0.370738267936334;
   fWeightMatrix0to1[5][2] = -0.655275923010717;
   fWeightMatrix0to1[6][2] = 0.337983332282764;
   fWeightMatrix0to1[7][2] = -0.750279773989942;
   fWeightMatrix0to1[8][2] = -1.87083261242431;
   fWeightMatrix0to1[9][2] = 2.21597184916614;
   fWeightMatrix0to1[10][2] = -1.08463045508243;
   fWeightMatrix0to1[11][2] = 0.670042649098805;
   fWeightMatrix0to1[12][2] = 2.68878951541585;
   fWeightMatrix0to1[13][2] = 2.28220577686915;
   fWeightMatrix0to1[0][3] = -0.581962270353102;
   fWeightMatrix0to1[1][3] = 1.2260116897679;
   fWeightMatrix0to1[2][3] = -0.60334577719548;
   fWeightMatrix0to1[3][3] = -1.35331908412632;
   fWeightMatrix0to1[4][3] = -0.221583155127156;
   fWeightMatrix0to1[5][3] = -0.169110704415645;
   fWeightMatrix0to1[6][3] = 1.76631493333048;
   fWeightMatrix0to1[7][3] = 0.44259370275777;
   fWeightMatrix0to1[8][3] = 0.460901717388072;
   fWeightMatrix0to1[9][3] = -0.238801487038512;
   fWeightMatrix0to1[10][3] = -1.71451008514722;
   fWeightMatrix0to1[11][3] = 0.849982560839581;
   fWeightMatrix0to1[12][3] = 0.630270682652417;
   fWeightMatrix0to1[13][3] = -1.5686519433331;
   fWeightMatrix0to1[0][4] = -1.25874345555561;
   fWeightMatrix0to1[1][4] = -1.74791402141693;
   fWeightMatrix0to1[2][4] = 1.0406106756866;
   fWeightMatrix0to1[3][4] = 0.492356254995677;
   fWeightMatrix0to1[4][4] = -1.13964207926836;
   fWeightMatrix0to1[5][4] = -0.242455972014349;
   fWeightMatrix0to1[6][4] = -0.141952274721571;
   fWeightMatrix0to1[7][4] = 1.01001517549206;
   fWeightMatrix0to1[8][4] = 1.2321342144796;
   fWeightMatrix0to1[9][4] = -0.577473257710223;
   fWeightMatrix0to1[10][4] = 0.195679323916276;
   fWeightMatrix0to1[11][4] = -0.745131566503814;
   fWeightMatrix0to1[12][4] = 0.464507477611239;
   fWeightMatrix0to1[13][4] = 0.964990900189679;
   fWeightMatrix0to1[0][5] = -1.12384852432142;
   fWeightMatrix0to1[1][5] = -1.42396230910246;
   fWeightMatrix0to1[2][5] = -0.477041875843185;
   fWeightMatrix0to1[3][5] = 1.06110970838957;
   fWeightMatrix0to1[4][5] = -0.0695920808459558;
   fWeightMatrix0to1[5][5] = -0.371024979782717;
   fWeightMatrix0to1[6][5] = -1.83717538617495;
   fWeightMatrix0to1[7][5] = -2.06177800515672;
   fWeightMatrix0to1[8][5] = 1.19356123242825;
   fWeightMatrix0to1[9][5] = -1.24390161946539;
   fWeightMatrix0to1[10][5] = 2.10929373834661;
   fWeightMatrix0to1[11][5] = 1.34463250150823;
   fWeightMatrix0to1[12][5] = -0.0567871527333216;
   fWeightMatrix0to1[13][5] = 0.853388424951864;
   fWeightMatrix0to1[0][6] = -1.21019268046055;
   fWeightMatrix0to1[1][6] = -0.207088104636846;
   fWeightMatrix0to1[2][6] = 1.40745001204205;
   fWeightMatrix0to1[3][6] = -1.07589742371334;
   fWeightMatrix0to1[4][6] = -4.48304431286302;
   fWeightMatrix0to1[5][6] = -1.6377758521626;
   fWeightMatrix0to1[6][6] = -0.320670179781476;
   fWeightMatrix0to1[7][6] = -0.847157709134557;
   fWeightMatrix0to1[8][6] = 1.85249530652331;
   fWeightMatrix0to1[9][6] = -5.82820018515024;
   fWeightMatrix0to1[10][6] = -0.541050877721531;
   fWeightMatrix0to1[11][6] = 1.46935838542092;
   fWeightMatrix0to1[12][6] = -1.69938703142694;
   fWeightMatrix0to1[13][6] = -2.52858200990693;
   fWeightMatrix0to1[0][7] = 0.0656926391513374;
   fWeightMatrix0to1[1][7] = 0.0842226575126127;
   fWeightMatrix0to1[2][7] = -1.34231939871817;
   fWeightMatrix0to1[3][7] = -1.1010944655506;
   fWeightMatrix0to1[4][7] = -0.0503413152430198;
   fWeightMatrix0to1[5][7] = 0.992978368479698;
   fWeightMatrix0to1[6][7] = -1.0126626188842;
   fWeightMatrix0to1[7][7] = 0.921301881722276;
   fWeightMatrix0to1[8][7] = -0.476892217757183;
   fWeightMatrix0to1[9][7] = -0.326223747592651;
   fWeightMatrix0to1[10][7] = 0.0111200538834143;
   fWeightMatrix0to1[11][7] = 0.0229504487982758;
   fWeightMatrix0to1[12][7] = -1.70243744683576;
   fWeightMatrix0to1[13][7] = -0.128850616137796;
   fWeightMatrix0to1[0][8] = -0.891207975731757;
   fWeightMatrix0to1[1][8] = 0.455190454679639;
   fWeightMatrix0to1[2][8] = -0.800153223170539;
   fWeightMatrix0to1[3][8] = 1.72775980920616;
   fWeightMatrix0to1[4][8] = 0.538344745484834;
   fWeightMatrix0to1[5][8] = -0.834234756735735;
   fWeightMatrix0to1[6][8] = 0.662038641700713;
   fWeightMatrix0to1[7][8] = -0.77656665481558;
   fWeightMatrix0to1[8][8] = -1.75384853082805;
   fWeightMatrix0to1[9][8] = -5.86563636671606;
   fWeightMatrix0to1[10][8] = -0.558009953960196;
   fWeightMatrix0to1[11][8] = 1.43625212527766;
   fWeightMatrix0to1[12][8] = 3.45909433327074;
   fWeightMatrix0to1[13][8] = 4.09675700617904;
   fWeightMatrix0to1[0][9] = -0.584964214112897;
   fWeightMatrix0to1[1][9] = 0.158401299051759;
   fWeightMatrix0to1[2][9] = -1.33305034230668;
   fWeightMatrix0to1[3][9] = 1.03736351637606;
   fWeightMatrix0to1[4][9] = 0.48795137072631;
   fWeightMatrix0to1[5][9] = -1.32393183579291;
   fWeightMatrix0to1[6][9] = 0.624704492264818;
   fWeightMatrix0to1[7][9] = -1.42669580356658;
   fWeightMatrix0to1[8][9] = 0.00670812197780201;
   fWeightMatrix0to1[9][9] = -1.48834295647962;
   fWeightMatrix0to1[10][9] = 1.52124771990135;
   fWeightMatrix0to1[11][9] = -1.53183185215062;
   fWeightMatrix0to1[12][9] = -1.48820644031848;
   fWeightMatrix0to1[13][9] = 0.514853500879022;
   fWeightMatrix0to1[0][10] = 5.31589625999822;
   fWeightMatrix0to1[1][10] = 0.177016594945261;
   fWeightMatrix0to1[2][10] = -1.79872000417922;
   fWeightMatrix0to1[3][10] = -0.262893118149164;
   fWeightMatrix0to1[4][10] = -3.95743641587498;
   fWeightMatrix0to1[5][10] = 1.64999786180576;
   fWeightMatrix0to1[6][10] = 1.13623976065993;
   fWeightMatrix0to1[7][10] = -0.074702927660225;
   fWeightMatrix0to1[8][10] = -0.870721930918609;
   fWeightMatrix0to1[9][10] = -2.28112581901413;
   fWeightMatrix0to1[10][10] = -1.48132064950398;
   fWeightMatrix0to1[11][10] = 0.0405654523021428;
   fWeightMatrix0to1[12][10] = -5.87738394218887;
   fWeightMatrix0to1[13][10] = -2.14566291611883;
   fWeightMatrix0to1[0][11] = -0.839707259189756;
   fWeightMatrix0to1[1][11] = 0.303708733475098;
   fWeightMatrix0to1[2][11] = -0.00751261252947923;
   fWeightMatrix0to1[3][11] = 0.626937214232234;
   fWeightMatrix0to1[4][11] = -0.373907808278925;
   fWeightMatrix0to1[5][11] = -1.6351371627267;
   fWeightMatrix0to1[6][11] = 1.77108184740957;
   fWeightMatrix0to1[7][11] = 1.50574012863106;
   fWeightMatrix0to1[8][11] = -0.677389950399061;
   fWeightMatrix0to1[9][11] = -0.67056248685802;
   fWeightMatrix0to1[10][11] = 0.704660783458417;
   fWeightMatrix0to1[11][11] = -1.25043345812855;
   fWeightMatrix0to1[12][11] = -0.858584476335973;
   fWeightMatrix0to1[13][11] = -0.502465565570846;
   fWeightMatrix0to1[0][12] = 0.461713933352228;
   fWeightMatrix0to1[1][12] = -0.571631644685177;
   fWeightMatrix0to1[2][12] = 0.394071938558751;
   fWeightMatrix0to1[3][12] = 0.823064922657869;
   fWeightMatrix0to1[4][12] = -0.0845619481088063;
   fWeightMatrix0to1[5][12] = 1.54929410536037;
   fWeightMatrix0to1[6][12] = 1.82264317695769;
   fWeightMatrix0to1[7][12] = -2.48015054160765;
   fWeightMatrix0to1[8][12] = 0.593929003889102;
   fWeightMatrix0to1[9][12] = -0.208352246349003;
   fWeightMatrix0to1[10][12] = 0.53129075602031;
   fWeightMatrix0to1[11][12] = -1.90419234051271;
   fWeightMatrix0to1[12][12] = -3.15574276673372;
   fWeightMatrix0to1[13][12] = 1.0097918790946;
   fWeightMatrix0to1[0][13] = 3.34714262013445;
   fWeightMatrix0to1[1][13] = -1.76478928705599;
   fWeightMatrix0to1[2][13] = 0.668178129824171;
   fWeightMatrix0to1[3][13] = -0.690207811197952;
   fWeightMatrix0to1[4][13] = 1.92084650944071;
   fWeightMatrix0to1[5][13] = 1.88695648132454;
   fWeightMatrix0to1[6][13] = -0.642717368308086;
   fWeightMatrix0to1[7][13] = -1.35358251033309;
   fWeightMatrix0to1[8][13] = 0.14188479813318;
   fWeightMatrix0to1[9][13] = 1.24244599828917;
   fWeightMatrix0to1[10][13] = 1.92459001660553;
   fWeightMatrix0to1[11][13] = 1.75252413337552;
   fWeightMatrix0to1[12][13] = 2.00800937541393;
   fWeightMatrix0to1[13][13] = 1.88736041483059;
   // weight matrix from layer 1 to 2
   fWeightMatrix1to2[0][0] = -1.54394401176974;
   fWeightMatrix1to2[1][0] = 0.797941240115003;
   fWeightMatrix1to2[2][0] = -1.4601417304929;
   fWeightMatrix1to2[3][0] = -3.19123999431033;
   fWeightMatrix1to2[4][0] = -1.52903536336739;
   fWeightMatrix1to2[5][0] = 2.2372078362696;
   fWeightMatrix1to2[6][0] = 0.0069483181697284;
   fWeightMatrix1to2[7][0] = -2.81162482579469;
   fWeightMatrix1to2[8][0] = 1.30185547803667;
   fWeightMatrix1to2[9][0] = -0.917494038577259;
   fWeightMatrix1to2[10][0] = -0.525307659488112;
   fWeightMatrix1to2[11][0] = -0.386891805741225;
   fWeightMatrix1to2[12][0] = 1.66349518844882;
   fWeightMatrix1to2[0][1] = 1.33036785770005;
   fWeightMatrix1to2[1][1] = 0.0976048179948091;
   fWeightMatrix1to2[2][1] = -0.0776969195422795;
   fWeightMatrix1to2[3][1] = -1.10375995239776;
   fWeightMatrix1to2[4][1] = -0.697878649089727;
   fWeightMatrix1to2[5][1] = 1.2246059992041;
   fWeightMatrix1to2[6][1] = 1.75203107172216;
   fWeightMatrix1to2[7][1] = 0.997829020839314;
   fWeightMatrix1to2[8][1] = 0.272034869851857;
   fWeightMatrix1to2[9][1] = 2.36865780350397;
   fWeightMatrix1to2[10][1] = -1.80859693919833;
   fWeightMatrix1to2[11][1] = -0.668174485296981;
   fWeightMatrix1to2[12][1] = -0.199619091301113;
   fWeightMatrix1to2[0][2] = -0.196128779886641;
   fWeightMatrix1to2[1][2] = 1.54148706821961;
   fWeightMatrix1to2[2][2] = 1.61349020080052;
   fWeightMatrix1to2[3][2] = -1.47033478198363;
   fWeightMatrix1to2[4][2] = 1.45315953684274;
   fWeightMatrix1to2[5][2] = -1.50620739491663;
   fWeightMatrix1to2[6][2] = -1.53731018105994;
   fWeightMatrix1to2[7][2] = 0.46221234220563;
   fWeightMatrix1to2[8][2] = -0.116514990848;
   fWeightMatrix1to2[9][2] = -0.171353963437545;
   fWeightMatrix1to2[10][2] = 0.826934322202426;
   fWeightMatrix1to2[11][2] = -0.989514388261134;
   fWeightMatrix1to2[12][2] = 1.75673505199282;
   fWeightMatrix1to2[0][3] = -1.44907968406618;
   fWeightMatrix1to2[1][3] = 0.609796993392278;
   fWeightMatrix1to2[2][3] = 0.0944023620215812;
   fWeightMatrix1to2[3][3] = -0.969737836975996;
   fWeightMatrix1to2[4][3] = -1.11071283904493;
   fWeightMatrix1to2[5][3] = -1.60039198154433;
   fWeightMatrix1to2[6][3] = -0.0811738775743184;
   fWeightMatrix1to2[7][3] = -1.68427865159082;
   fWeightMatrix1to2[8][3] = -1.40902678875469;
   fWeightMatrix1to2[9][3] = -1.52108042262146;
   fWeightMatrix1to2[10][3] = -0.0404023183923254;
   fWeightMatrix1to2[11][3] = -0.532196310374305;
   fWeightMatrix1to2[12][3] = -1.68436072608221;
   fWeightMatrix1to2[0][4] = -0.0511935293379425;
   fWeightMatrix1to2[1][4] = -0.510811656033585;
   fWeightMatrix1to2[2][4] = -1.05325949382776;
   fWeightMatrix1to2[3][4] = -2.22962345717048;
   fWeightMatrix1to2[4][4] = -0.0517088895484682;
   fWeightMatrix1to2[5][4] = 1.2787938143386;
   fWeightMatrix1to2[6][4] = 0.98078563346951;
   fWeightMatrix1to2[7][4] = -1.53698238402008;
   fWeightMatrix1to2[8][4] = -0.890276231591164;
   fWeightMatrix1to2[9][4] = -0.956738549923489;
   fWeightMatrix1to2[10][4] = -0.808169263484669;
   fWeightMatrix1to2[11][4] = -1.20465761920131;
   fWeightMatrix1to2[12][4] = 0.484130989520431;
   fWeightMatrix1to2[0][5] = -0.167193871794842;
   fWeightMatrix1to2[1][5] = 1.70882900751675;
   fWeightMatrix1to2[2][5] = -0.27289139689062;
   fWeightMatrix1to2[3][5] = -0.155678969830199;
   fWeightMatrix1to2[4][5] = -0.672821167286119;
   fWeightMatrix1to2[5][5] = -1.74119753762035;
   fWeightMatrix1to2[6][5] = 0.825481524586108;
   fWeightMatrix1to2[7][5] = 0.948077135345382;
   fWeightMatrix1to2[8][5] = -0.907582257195646;
   fWeightMatrix1to2[9][5] = -1.16941270420325;
   fWeightMatrix1to2[10][5] = 0.901462144150286;
   fWeightMatrix1to2[11][5] = 0.61168930804719;
   fWeightMatrix1to2[12][5] = 0.53781291189952;
   fWeightMatrix1to2[0][6] = -0.170311559377791;
   fWeightMatrix1to2[1][6] = -0.688181511349096;
   fWeightMatrix1to2[2][6] = 1.50755161879021;
   fWeightMatrix1to2[3][6] = 1.78790061063692;
   fWeightMatrix1to2[4][6] = 1.21684289003658;
   fWeightMatrix1to2[5][6] = -0.765855707335678;
   fWeightMatrix1to2[6][6] = 0.680825926502039;
   fWeightMatrix1to2[7][6] = -0.0396941236786789;
   fWeightMatrix1to2[8][6] = -1.38950322429288;
   fWeightMatrix1to2[9][6] = -0.148265730675594;
   fWeightMatrix1to2[10][6] = -1.77130375282562;
   fWeightMatrix1to2[11][6] = -0.742030178236497;
   fWeightMatrix1to2[12][6] = -1.60413328897949;
   fWeightMatrix1to2[0][7] = 1.8975980254855;
   fWeightMatrix1to2[1][7] = -2.02750740120838;
   fWeightMatrix1to2[2][7] = 2.90954599751897;
   fWeightMatrix1to2[3][7] = -0.702928298519062;
   fWeightMatrix1to2[4][7] = 0.688184854798488;
   fWeightMatrix1to2[5][7] = -0.733536457910802;
   fWeightMatrix1to2[6][7] = 0.872480151880922;
   fWeightMatrix1to2[7][7] = 0.483848822203553;
   fWeightMatrix1to2[8][7] = -1.68852638069713;
   fWeightMatrix1to2[9][7] = -0.168316098875642;
   fWeightMatrix1to2[10][7] = 0.526481841418437;
   fWeightMatrix1to2[11][7] = -1.55717387925966;
   fWeightMatrix1to2[12][7] = -1.45095692101276;
   fWeightMatrix1to2[0][8] = -1.97056993973634;
   fWeightMatrix1to2[1][8] = -0.527568724746996;
   fWeightMatrix1to2[2][8] = 1.80341703069124;
   fWeightMatrix1to2[3][8] = -1.22917521934384;
   fWeightMatrix1to2[4][8] = 0.25393177062052;
   fWeightMatrix1to2[5][8] = -0.404514407196068;
   fWeightMatrix1to2[6][8] = -1.16421210344607;
   fWeightMatrix1to2[7][8] = -1.66945378507294;
   fWeightMatrix1to2[8][8] = -1.14099793081617;
   fWeightMatrix1to2[9][8] = -1.01910216469537;
   fWeightMatrix1to2[10][8] = 0.565929018138509;
   fWeightMatrix1to2[11][8] = -1.86016689850889;
   fWeightMatrix1to2[12][8] = -1.13124970734417;
   fWeightMatrix1to2[0][9] = 0.128317465289229;
   fWeightMatrix1to2[1][9] = -0.35760457928651;
   fWeightMatrix1to2[2][9] = 2.23977500486321;
   fWeightMatrix1to2[3][9] = 1.02718812294156;
   fWeightMatrix1to2[4][9] = -1.46365818802528;
   fWeightMatrix1to2[5][9] = 1.59002916530806;
   fWeightMatrix1to2[6][9] = 1.02356209899399;
   fWeightMatrix1to2[7][9] = -0.631210328109899;
   fWeightMatrix1to2[8][9] = -0.0843534233678832;
   fWeightMatrix1to2[9][9] = -0.345294028698086;
   fWeightMatrix1to2[10][9] = -1.07374318219863;
   fWeightMatrix1to2[11][9] = 0.113425587085557;
   fWeightMatrix1to2[12][9] = 1.87284172550728;
   fWeightMatrix1to2[0][10] = 1.05015596171763;
   fWeightMatrix1to2[1][10] = 1.96621139723147;
   fWeightMatrix1to2[2][10] = -1.28161316669137;
   fWeightMatrix1to2[3][10] = 0.174775128965201;
   fWeightMatrix1to2[4][10] = -2.08807230344391;
   fWeightMatrix1to2[5][10] = 1.05875914054541;
   fWeightMatrix1to2[6][10] = -2.10760108310807;
   fWeightMatrix1to2[7][10] = -2.04148599430164;
   fWeightMatrix1to2[8][10] = -0.137545752606485;
   fWeightMatrix1to2[9][10] = 0.890883626638337;
   fWeightMatrix1to2[10][10] = 0.519776083168852;
   fWeightMatrix1to2[11][10] = 0.433984718047641;
   fWeightMatrix1to2[12][10] = 0.364089329010299;
   fWeightMatrix1to2[0][11] = -0.450303345507363;
   fWeightMatrix1to2[1][11] = -0.360471950484476;
   fWeightMatrix1to2[2][11] = 0.123432791153627;
   fWeightMatrix1to2[3][11] = 0.935139783862061;
   fWeightMatrix1to2[4][11] = -1.55647729411299;
   fWeightMatrix1to2[5][11] = 0.816384319465184;
   fWeightMatrix1to2[6][11] = -1.58076722411793;
   fWeightMatrix1to2[7][11] = -0.524702704251777;
   fWeightMatrix1to2[8][11] = -0.0972799799807965;
   fWeightMatrix1to2[9][11] = 0.0253829639249858;
   fWeightMatrix1to2[10][11] = -1.05105385308937;
   fWeightMatrix1to2[11][11] = 0.0612482342820986;
   fWeightMatrix1to2[12][11] = 1.72002360399545;
   fWeightMatrix1to2[0][12] = 0.0674116618998887;
   fWeightMatrix1to2[1][12] = -0.366794268013174;
   fWeightMatrix1to2[2][12] = -0.855401647218217;
   fWeightMatrix1to2[3][12] = -1.67707745692977;
   fWeightMatrix1to2[4][12] = -1.85376029500211;
   fWeightMatrix1to2[5][12] = 1.88541588308742;
   fWeightMatrix1to2[6][12] = -0.49117721283669;
   fWeightMatrix1to2[7][12] = -1.16961120192719;
   fWeightMatrix1to2[8][12] = 0.581430951529816;
   fWeightMatrix1to2[9][12] = -1.92022614224703;
   fWeightMatrix1to2[10][12] = -1.03419413428326;
   fWeightMatrix1to2[11][12] = -0.922327520684436;
   fWeightMatrix1to2[12][12] = 0.887435213866307;
   fWeightMatrix1to2[0][13] = -0.522534766842142;
   fWeightMatrix1to2[1][13] = -1.67543227255438;
   fWeightMatrix1to2[2][13] = -0.58117791198016;
   fWeightMatrix1to2[3][13] = -0.672968828331005;
   fWeightMatrix1to2[4][13] = -2.16227150099819;
   fWeightMatrix1to2[5][13] = 0.740156751099325;
   fWeightMatrix1to2[6][13] = -1.28187466361461;
   fWeightMatrix1to2[7][13] = -1.0478029944485;
   fWeightMatrix1to2[8][13] = 0.63368948735225;
   fWeightMatrix1to2[9][13] = 0.237551790509162;
   fWeightMatrix1to2[10][13] = 0.384136007002823;
   fWeightMatrix1to2[11][13] = -0.0957657561604944;
   fWeightMatrix1to2[12][13] = 1.35862263687401;
   fWeightMatrix1to2[0][14] = 1.42611064971025;
   fWeightMatrix1to2[1][14] = 0.889309001928108;
   fWeightMatrix1to2[2][14] = -0.999438994293714;
   fWeightMatrix1to2[3][14] = -1.53430010143002;
   fWeightMatrix1to2[4][14] = -1.96506878894557;
   fWeightMatrix1to2[5][14] = 1.40775035903255;
   fWeightMatrix1to2[6][14] = 0.512622216760486;
   fWeightMatrix1to2[7][14] = -0.146060588683089;
   fWeightMatrix1to2[8][14] = 1.02246618906009;
   fWeightMatrix1to2[9][14] = 0.565164108227465;
   fWeightMatrix1to2[10][14] = 1.72300583104183;
   fWeightMatrix1to2[11][14] = -1.98306384895377;
   fWeightMatrix1to2[12][14] = 1.81741981471706;
   // weight matrix from layer 2 to 3
   fWeightMatrix2to3[0][0] = 0.0431046360834669;
   fWeightMatrix2to3[0][1] = -1.99137794132389;
   fWeightMatrix2to3[0][2] = -1.04103409829756;
   fWeightMatrix2to3[0][3] = 0.353654925440171;
   fWeightMatrix2to3[0][4] = 0.0969352551572482;
   fWeightMatrix2to3[0][5] = -0.287604167726062;
   fWeightMatrix2to3[0][6] = 0.398073019557413;
   fWeightMatrix2to3[0][7] = 0.337215732830008;
   fWeightMatrix2to3[0][8] = -0.0621323363915902;
   fWeightMatrix2to3[0][9] = -0.209778432046335;
   fWeightMatrix2to3[0][10] = 1.3020184698297;
   fWeightMatrix2to3[0][11] = 0.105787296371344;
   fWeightMatrix2to3[0][12] = -1.34349631197874;
   fWeightMatrix2to3[0][13] = 1.45560274584311;
}

inline double ReadMLP0_35_B::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   if (inputValues.size() != (unsigned int)fLayerSize[0]-1) {
      std::cout << "Input vector needs to be of size " << fLayerSize[0]-1 << std::endl;
      return 0;
   }

   for (int l=0; l<fLayers; l++)
      for (int i=0; i<fLayerSize[l]; i++) fWeights[l][i]=0;

   for (int l=0; l<fLayers-1; l++)
      fWeights[l][fLayerSize[l]-1]=1;

   for (int i=0; i<fLayerSize[0]-1; i++)
      fWeights[0][i]=inputValues[i];

   // layer 0 to 1
   for (int o=0; o<fLayerSize[1]-1; o++) {
      for (int i=0; i<fLayerSize[0]; i++) {
         double inputVal = fWeightMatrix0to1[o][i] * fWeights[0][i];
         fWeights[1][o] += inputVal;
      }
      fWeights[1][o] = ActivationFnc(fWeights[1][o]);
   }
   // layer 1 to 2
   for (int o=0; o<fLayerSize[2]-1; o++) {
      for (int i=0; i<fLayerSize[1]; i++) {
         double inputVal = fWeightMatrix1to2[o][i] * fWeights[1][i];
         fWeights[2][o] += inputVal;
      }
      fWeights[2][o] = ActivationFnc(fWeights[2][o]);
   }
   // layer 2 to 3
   for (int o=0; o<fLayerSize[3]; o++) {
      for (int i=0; i<fLayerSize[2]; i++) {
         double inputVal = fWeightMatrix2to3[o][i] * fWeights[2][i];
         fWeights[3][o] += inputVal;
      }
   }

   return fWeights[3][0];
}

double ReadMLP0_35_B::ActivationFnc(double x) const
{
   // hyperbolic tan
   return tanh(x);
}
 
   
// Clean up
inline void ReadMLP0_35_B::Clear() 
{
   // nothing to clear
}
inline double ReadMLP0_35_B::GetMvaValue( const std::vector<double>& inputValues ) const
{
   // classifier response value
   double retval = 0;

   // classifier response, sanity check first
   if (!fStatusIsClean) {
      std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
      retval = 0;
   }
   else {
      if (IsNormalised()) {
         // normalise variables
         std::vector<double> iV;
         int ivar = 0;
         for (std::vector<double>::const_iterator varIt = inputValues.begin();
              varIt != inputValues.end(); varIt++, ivar++) {
            iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
         }
         retval = GetMvaValue__( iV );
      }
      else {
         retval = GetMvaValue__( inputValues );
      }
   }

   return retval;
}
